{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7b4d07",
   "metadata": {},
   "source": [
    "# Explainability Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4c737",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98ebc13e",
   "metadata": {},
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8084b2ae",
   "metadata": {},
   "source": [
    "1. A Llava Llama 8B model was trained and used for the detection of concepts and the captions of each image. Then, for this explainability task, Llama 3.1 was used to merge the concepts and the captions to generate a more complete explanation to relate with the image.\n",
    "\n",
    "2. The list of concepts was translated into natural language. From those files, the rows corresponding to the test set of images for the task were extracted and renamed as caption-csv and ref_mini_concepts_natural_.csv.\n",
    "\n",
    "3. The list of concepts in natural language and the subtitles of the test set were provided as part of a prompt to Open AI APIs to obtain approximate location coordinates, which were saved in the file sam_coord.csv.\n",
    "\n",
    "4. Natural Language Processing integration with NER extraction and others techniques were used to have good candidate labels for SAM.\n",
    "\n",
    "5. The file with the coordinates was sent to Segment Anything Model (SAM) to create the bounding boxes. Precision was added using heat maps. Specifically, the following was done:\n",
    "\n",
    "    - Generates multiple segmentation candidates and automatically selects the best one per anatomical structure\n",
    "    - Provides quantified quality metrics (0-1 scale) for each segmentation based on anatomical likelihood\n",
    "    - Uses probability maps to identify most likely anatomical locations from approximate coordinates\n",
    "    - Fine-tuned parameters specifically for medical imaging precision\n",
    "\n",
    "6. Enhancement was done with YOLO (You Only Look Once) for automatic detection of missed anatomical structures.\n",
    "\n",
    "7. Arrow detection and following, and keypoint detection algorithms (SIFT, FAST, LoG) were used.\n",
    "\n",
    "8. Computer vision preprocessing (Canny edge detection and adaptive thresholding) and geometric & spatial analysis were also used.\n",
    "\n",
    "9. Concepts, captions and explanations are printed below the bounding box images for clarity. Also some statistical analysis & confidence scoring.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2524f",
   "metadata": {},
   "source": [
    "### 1. Getting aproximate location coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84e15e",
   "metadata": {},
   "source": [
    "The objective is to get approximate coordinates to SAM. This script:\n",
    "\n",
    "- Correctly extract and group compound medical terms (e.g., “small intestine” not “Intestines;Small”).\n",
    "\n",
    "- Omit generic modality terms (X-ray, MRI, PET, etc.).\n",
    "\n",
    "- Identify bounding boxes for medical structures/findings based on visual and textual cues.\n",
    "\n",
    "- Detect arrow tips and link them to the relevant terms/regions.\n",
    "\n",
    "- Leverage GPT-4V for visual reasoning and GPT-4.1 for text refinement, merging, and error correction.\n",
    "\n",
    "- Produce CSV/JSON output with ImageID, Label, x, y, width, height.\n",
    "\n",
    "- Collaborate between models for better accuracy and compound term preservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d6160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== LIBRARIES ==========\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import base64\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27ef12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIGURATION ==========\n",
    "\n",
    "load_dotenv() # Load environment variables from the .env file into the environment\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "IMAGE_FOLDER = \"./data/test_set_explain/\"\n",
    "CONCEPTS_FILE = \"./data/ref_mini_concepts_natural_.csv\"\n",
    "CAPTIONS_FILE = \"./data/3_submission_explainability.csv\"\n",
    "CSV_OUTPUT = \"./results_explain-3/sam_coord.csv\"\n",
    "JSON_OUTPUT = \"./results_explain-3/sam_coord.json\"\n",
    "VISION_MODEL = \"gpt-4o\"\n",
    "LANG_MODEL = \"gpt-4.1\"\n",
    "MAX_VISION_TOKENS = 800\n",
    "MAX_LANG_TOKENS = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== UTILITIES ==========\n",
    "\n",
    "def get_image_path(image_id):\n",
    "    for ext in ['.jpeg', '.jpg', '.png']:\n",
    "        img_path = os.path.join(IMAGE_FOLDER, f\"{image_id}{ext}\")\n",
    "        if os.path.exists(img_path):\n",
    "            return img_path\n",
    "    return None\n",
    "\n",
    "def is_modality(term):\n",
    "    modalities = [\n",
    "        \"plain x-ray\", \"x-ray\", \"ct\", \"mri\", \"ultrasound\", \"pet\", \"ct-scan\", \"computed tomography\",\n",
    "        \"magnetic resonance imaging\", \"positron-emission tomography\", \"ultrasonography\", \"angiogram\"\n",
    "    ]\n",
    "    return term.strip().lower() in [m.lower() for m in modalities]\n",
    "\n",
    "def clean_term(term):\n",
    "    return re.sub(r\"^(Structure of |structure of )\", \"\", term).strip()\n",
    "\n",
    "def group_compound_terms(term_list):\n",
    "    known_compounds = [\n",
    "        \"small intestine\", \"large intestine\", \"left axillary region\", \"right lower lobe\",\n",
    "        \"lower lobe\", \"upper lobe\", \"anterior chamber\", \"posterior chamber\", \"right kidney\",\n",
    "        \"left kidney\", \"left atrium\", \"right atrium\", \"left ventricle\", \"right ventricle\",\n",
    "        \"biliary tree\", \"pulmonary artery\", \"coronary artery\", \"saphenous vein\"\n",
    "    ]\n",
    "    clean_terms = [clean_term(t).lower() for t in term_list if t and not is_modality(t)]\n",
    "    final_terms = set()\n",
    "    used = set()\n",
    "    for comp in known_compounds:\n",
    "        parts = comp.split()\n",
    "        if all(any(part == t or part in t for t in clean_terms) for part in parts):\n",
    "            final_terms.add(comp)\n",
    "            used.update(parts)\n",
    "    for t in clean_terms:\n",
    "        if not any(t == u or t in u for u in used):\n",
    "            final_terms.add(t)\n",
    "    return [t if \" \" not in t else \" \".join([w.capitalize() for w in t.split()]) for t in final_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "568477d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== PROMPTS ==========\n",
    "\n",
    "def gpt4v_prompt(terms, caption):\n",
    "    return f\"\"\"\n",
    "You are an expert radiologist. Analyze the provided medical image together with these terms: {terms}, and caption: \"{caption}\".\n",
    "\n",
    "Important: In radiology, \"left\" and \"right\" always refer to the patient's left and right (the patient's perspective), which is the opposite of the observer's (radiologist's) view. Always reason and answer using the patient's perspective.\n",
    "\n",
    "Your tasks:\n",
    "1. Compound terms like \"small intestine\", \"left axillary region\", etc., must be treated as unique, unsplit entities. Never split such terms.\n",
    "2. Omit general modality terms such as X-ray, MRI, PET, CT, etc.; focus on anatomical structures, findings, or pathologies.\n",
    "3. For each medical term, estimate the most probable bounding box (x, y, width, height) in the image. Use both the image and the caption to reason location.\n",
    "4. If there are any arrows, lines, or visual pointers, detect their tip coordinates (x, y) and, if possible, assign the pointed term or region.\n",
    "5. For ambiguous terms, return your best-guess bounding box or arrow tip, and flag as \"uncertain\" in the label.\n",
    "6. Return your results ONLY as a JSON list:\n",
    "    [\n",
    "        {{\"label\": \"<compound_term>\", \"box\": {{\"x\": ..., \"y\": ..., \"width\": ..., \"height\": ...}}}},\n",
    "        {{\"label\": \"<compound_term>\", \"arrow_tip\": {{\"x\": ..., \"y\": ...}}}},\n",
    "        ...\n",
    "    ]\n",
    "Do not include modality labels. Never split compound terms. Do not return any explanation, only the JSON array.\n",
    "\"\"\"\n",
    "\n",
    "def gpt41_prompt(detections_json, terms, caption, image_id):\n",
    "    return f\"\"\"\n",
    "You are an expert radiologist data curator. Here are the vision detections from a medical image: {json.dumps(detections_json)}.\n",
    "- Original caption: \"{caption}\"\n",
    "- Medical terms to consider: {terms}\n",
    "- Image ID: {image_id}\n",
    "\n",
    "Important: In radiology, \"left\" and \"right\" always refer to the patient's left and right, not the observer's. Always use the patient's perspective.\n",
    "\n",
    "Your tasks:\n",
    "1. For each term in the medical terms list, make sure compound terms are preserved as single entities (e.g., \"small intestine\" not split).\n",
    "2. Omit general imaging modality terms (X-ray, MRI, PET, CT, ultrasound, etc.) and only keep anatomical structures, pathologies, or findings.\n",
    "3. Validate the bounding boxes and arrow tips. If a term is missing a bounding box but has an arrow tip, estimate a default box (40x40 pixels) centered at the arrow tip.\n",
    "4. Output the full data in:\n",
    "    - CSV with columns: ImageID, Label, x, y, width, height\n",
    "    - JSON list: [{{\"ImageID\":..., \"Label\":..., \"x\":..., \"y\":..., \"width\":..., \"height\":...}}, ...]\n",
    "Only include rows for valid medical terms (no modalities, no split terms).\n",
    "If any info must be inferred, do so based on your expertise. Output both the CSV and JSON (CSV first, then JSON).\n",
    "\"\"\"\n",
    "\n",
    "def extract_json_anywhere(text):\n",
    "    # Busca el primer bloque válido de JSON array (list)\n",
    "    matches = re.findall(r\"(\\[.*?\\])\", text, re.DOTALL)\n",
    "    for m in matches:\n",
    "        try:\n",
    "            parsed = json.loads(m)\n",
    "            return m\n",
    "        except Exception:\n",
    "            continue\n",
    "    # Busca dentro de bloques markdown\n",
    "    match = re.search(r\"```json(.*?)```\", text, re.DOTALL)\n",
    "    if match:\n",
    "        inner = match.group(1).strip()\n",
    "        try:\n",
    "            parsed = json.loads(inner)\n",
    "            return inner\n",
    "        except Exception:\n",
    "            pass\n",
    "    return \"\"\n",
    "\n",
    "def call_gpt4v_vision(image_path, terms, caption, retries=2):\n",
    "    prompt = gpt4v_prompt(terms, caption)\n",
    "    with open(image_path, \"rb\") as imgf:\n",
    "        img_b64 = base64.b64encode(imgf.read()).decode()\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            print(\"Prompt:\\n\", prompt[:400], \"...\")\n",
    "            print(\"Image exists?\", os.path.exists(image_path))\n",
    "            response = openai.chat.completions.create(\n",
    "                model=VISION_MODEL,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{img_b64}\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=MAX_VISION_TOKENS\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            if not result:\n",
    "                print(\"[Vision model] Empty response from OpenAI. Check quota, input size, or prompt.\")\n",
    "                return []\n",
    "            clean_json = extract_json_anywhere(result)\n",
    "            try:\n",
    "                return json.loads(clean_json)\n",
    "            except Exception as je:\n",
    "                print(\"Raw result (not JSON):\", result)\n",
    "                raise je\n",
    "        except Exception as e:\n",
    "            print(f\"[Vision model] Error (attempt {attempt+1}): {e}\")\n",
    "            time.sleep(3 + attempt*3)\n",
    "    print(\"[Vision model] Failed after retries.\")\n",
    "    return []\n",
    "\n",
    "def call_gpt4_1_refiner(detections_json, terms, caption, image_id, retries=2):\n",
    "    prompt = gpt41_prompt(detections_json, terms, caption, image_id)\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            completion = openai.chat.completions.create(\n",
    "                model=LANG_MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=MAX_LANG_TOKENS\n",
    "            )\n",
    "            reply = completion.choices[0].message.content.strip()\n",
    "            print(\"\\n=== GPT-4.1 RAW REPLY ===\\n\", reply, \"\\n=== END REPLY ===\\n\")\n",
    "            # Busca CSV (puedes dejar igual)\n",
    "            csv_part, json_part = \"\", \"\"\n",
    "            csv_match = re.search(r\"ImageID,.*?(\\n(?:[^\\[]|\\[)*?)\\n?\\[\", reply, re.DOTALL)\n",
    "            if csv_match:\n",
    "                csv_part = csv_match.group(0).split(\"\\n[\")[0].strip()\n",
    "            else:\n",
    "                parts = re.split(r\"\\n\\s*\\n\", reply)\n",
    "                if len(parts) >= 2 and parts[0].startswith(\"ImageID\"):\n",
    "                    csv_part = parts[0].strip()\n",
    "                else:\n",
    "                    idx = reply.find('[')\n",
    "                    if idx != -1:\n",
    "                        csv_part = reply[:idx].strip()\n",
    "            # Busca el JSON con extractor avanzado\n",
    "            json_part = extract_json_anywhere(reply)\n",
    "            if not json_part:\n",
    "                print(\"[Language model] Could not parse JSON part.\")\n",
    "                json_part = \"[]\"\n",
    "            return csv_part, json_part\n",
    "        except Exception as e:\n",
    "            print(f\"[Language model] Error (attempt {attempt+1}): {e}\")\n",
    "            time.sleep(3 + attempt*3)\n",
    "    print(\"[Language model] Failed after retries.\")\n",
    "    return \"\", \"[]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "378a6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== MAIN PIPELINE ==========\n",
    "\n",
    "def run_pipeline():\n",
    "    if not os.path.exists(CONCEPTS_FILE) or not os.path.exists(CAPTIONS_FILE):\n",
    "        print(f\"ERROR: Concepts file or captions file not found.\")\n",
    "        return\n",
    "    concepts_df = pd.read_csv(CONCEPTS_FILE)\n",
    "    captions_df = pd.read_csv(CAPTIONS_FILE)\n",
    "    cap_map = {str(row[\"ID\"]): str(row[\"Caption\"]) for _, row in captions_df.iterrows()}\n",
    "\n",
    "    all_csv_rows = []\n",
    "    all_json_objs = []\n",
    "\n",
    "    for idx, row in concepts_df.iterrows():\n",
    "        image_id = str(row[\"ID\"])\n",
    "        cuis = [c.strip() for c in str(row[\"CUIs\"]).split(';') if c.strip()]\n",
    "        caption = cap_map.get(image_id, \"\")\n",
    "        image_path = get_image_path(image_id)\n",
    "        if image_path is None:\n",
    "            print(f\"[{image_id}] Image not found, skipping.\")\n",
    "            continue\n",
    "        terms = group_compound_terms(cuis)\n",
    "        print(f\"\\n=== Processing {image_id} ===\")\n",
    "        print(f\"Terms: {terms}\")\n",
    "        vision_results = call_gpt4v_vision(image_path, terms, caption)\n",
    "        if not vision_results:\n",
    "            print(f\"[{image_id}] No vision results, skipping.\")\n",
    "            continue\n",
    "        csv_out, json_out = call_gpt4_1_refiner(vision_results, terms, caption, image_id)\n",
    "        if csv_out:\n",
    "            if not all_csv_rows and \"ImageID\" in csv_out:\n",
    "                header, *rest = csv_out.splitlines()\n",
    "                all_csv_rows.append(header)\n",
    "                all_csv_rows.extend(rest)\n",
    "            else:\n",
    "                lines = [line for line in csv_out.splitlines() if not line.lower().startswith(\"imageid\")]\n",
    "                all_csv_rows.extend(lines)\n",
    "        if json_out and json_out != \"[]\":\n",
    "            try:\n",
    "                data = json.loads(json_out)\n",
    "                if isinstance(data, list):\n",
    "                    all_json_objs.extend(data)\n",
    "            except Exception as e:\n",
    "                print(f\"[{image_id}] Error parsing JSON output: {e}\")\n",
    "        time.sleep(2.5)\n",
    "\n",
    "    print(f\"\\nWriting outputs to {CSV_OUTPUT} and {JSON_OUTPUT} ...\")\n",
    "    with open(CSV_OUTPUT, \"w\") as f:\n",
    "        for row in all_csv_rows:\n",
    "            f.write(row + \"\\n\")\n",
    "    with open(JSON_OUTPUT, \"w\") as f:\n",
    "        json.dump(all_json_objs, f, indent=2)\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1bc8eff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_118 ===\n",
      "Terms: ['anterior-posterior', 'Bone Structure Of Ilium', 'pelvis', 'abdomen', 'Bone Structure Of Pubis']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['anterior-posterior', 'Bone Structure Of Ilium', 'pelvis', 'abdomen', 'Bone Structure Of Pubis'], and caption: \"Plain radiograph of the abdomen, taken in the anterior-posterior projection, shows multiple air-fluid levels within the bowel loops, extending into the pelvis. The bone structure of the ilium a ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV Output:**\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_118,Bone Structure Of Ilium,200,450,150,100\n",
      "ImageCLEFmedical_Caption_2025_test_118,pelvis,220,500,160,120\n",
      "ImageCLEFmedical_Caption_2025_test_118,abdomen,150,100,300,350\n",
      "ImageCLEFmedical_Caption_2025_test_118,Bone Structure Of Pubis,230,580,140,60\n",
      "ImageCLEFmedical_Caption_2025_test_118,air-fluid levels,230,180,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_118,air-fluid levels,280,200,40,40\n",
      "```\n",
      "\n",
      "**JSON Output:**\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_118\",\n",
      "    \"Label\": \"Bone Structure Of Ilium\",\n",
      "    \"x\": 200,\n",
      "    \"y\": 450,\n",
      "    \"width\": 150,\n",
      "    \"height\": 100\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_118\",\n",
      "    \"Label\": \"pelvis\",\n",
      "    \"x\": 220,\n",
      "    \"y\": 500,\n",
      "    \"width\": 160,\n",
      "    \"height\": 120\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_118\",\n",
      "    \"Label\": \"abdomen\",\n",
      "    \"x\": 150,\n",
      "    \"y\": 100,\n",
      "    \"width\": 300,\n",
      "    \"height\": 350\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_118\",\n",
      "    \"Label\": \"Bone Structure Of Pubis\",\n",
      "    \"x\": 230,\n",
      "    \"y\": 580,\n",
      "    \"width\": 140,\n",
      "    \"height\": 60\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_118\",\n",
      "    \"Label\": \"air-fluid levels\",\n",
      "    \"x\": 230,\n",
      "    \"y\": 180,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_118\",\n",
      "    \"Label\": \"air-fluid levels\",\n",
      "    \"x\": 280,\n",
      "    \"y\": 200,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "```\n",
      "**Notes on processing:**\n",
      "- \"anterior-posterior\" is an imaging modality/projection, so it has been excluded per instructions.\n",
      "- All compound terms are kept intact.\n",
      "- The \"air-fluid levels\" have been assigned default bounding boxes (40x40) centered at their arrow tips.\n",
      "- No term has been split. All entries reflect anatomical structures or findings only. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_1251 ===\n",
      "Terms: ['thrombus', 'Heart Ventricle', 'Right Ventricle', 'Right Ventricular Structure']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['thrombus', 'Heart Ventricle', 'Right Ventricle', 'Right Ventricular Structure'], and caption: \"Transthoracic ultrasonography echocardiogram showing a large vegetation on the mitral valve involving the heart ventricle, with possible thrombus formation affecting the right ventricular structure.\".\n",
      "\n",
      "Importa ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **Step 1: Mapping Detections to Medical Terms**\n",
      "\n",
      "**Medical terms from the list:**  \n",
      "- thrombus  \n",
      "- Heart Ventricle  \n",
      "- Right Ventricle  \n",
      "- Right Ventricular Structure  \n",
      "\n",
      "**Provided Detections:**  \n",
      "- \"Heart Ventricle\", box at (180,200,100,100), uncertain  \n",
      "- \"Right Ventricle\", box at (230,250,50,50), uncertain  \n",
      "- \"Right Ventricular Structure\", box at (230,250,50,50), uncertain  \n",
      "- \"thrombus\", box at (180,220,60,60), uncertain  \n",
      "- Arrow Tip at (190, 210)  \n",
      "\n",
      "- All required medical terms have corresponding bounding boxes.  \n",
      "- No box is missing except \"Arrow Tip,\" which is not a required label.  \n",
      "\n",
      "**Step 2: Combine boxes for duplicate/overlapping labels**\n",
      "\n",
      "- \"Right Ventricle\" and \"Right Ventricular Structure\" share the same box: (230,250,50,50).\n",
      "- \"thrombus\" is at (180,220,60,60).\n",
      "- \"Heart Ventricle\" at (180,200,100,100).\n",
      "- All are included.\n",
      "\n",
      "**Step 3: Prepare Output**\n",
      "\n",
      "#### CSV\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_1251,Heart Ventricle,180,200,100,100\n",
      "ImageCLEFmedical_Caption_2025_test_1251,Right Ventricle,230,250,50,50\n",
      "ImageCLEFmedical_Caption_2025_test_1251,Right Ventricular Structure,230,250,50,50\n",
      "ImageCLEFmedical_Caption_2025_test_1251,thrombus,180,220,60,60\n",
      "```\n",
      "\n",
      "#### JSON\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1251\",\n",
      "    \"Label\": \"Heart Ventricle\",\n",
      "    \"x\": 180,\n",
      "    \"y\": 200,\n",
      "    \"width\": 100,\n",
      "    \"height\": 100\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1251\",\n",
      "    \"Label\": \"Right Ventricle\",\n",
      "    \"x\": 230,\n",
      "    \"y\": 250,\n",
      "    \"width\": 50,\n",
      "    \"height\": 50\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1251\",\n",
      "    \"Label\": \"Right Ventricular Structure\",\n",
      "    \"x\": 230,\n",
      "    \"y\": 250,\n",
      "    \"width\": 50,\n",
      "    \"height\": 50\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1251\",\n",
      "    \"Label\": \"thrombus\",\n",
      "    \"x\": 180,\n",
      "    \"y\": 220,\n",
      "    \"width\": 60,\n",
      "    \"height\": 60\n",
      "  }\n",
      "]\n",
      "``` \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_1258 ===\n",
      "Terms: ['abdomen', 'anterior-posterior', 'Small Intestine', 'intestines']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['abdomen', 'anterior-posterior', 'Small Intestine', 'intestines'], and caption: \"Plain radiograph of the abdomen, taken in the Anterior-Posterior (AP) projection, shows multiple air-fluid levels within the Intestines, specifically in the Small bowel region.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"right\"  ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV Output**\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_1258,abdomen,0,0,512,600\n",
      "ImageCLEFmedical_Caption_2025_test_1258,small intestine,100,200,300,400\n",
      "ImageCLEFmedical_Caption_2025_test_1258,intestines,100,150,300,450\n",
      "```\n",
      "\n",
      "**JSON Output**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1258\",\n",
      "    \"Label\": \"abdomen\",\n",
      "    \"x\": 0,\n",
      "    \"y\": 0,\n",
      "    \"width\": 512,\n",
      "    \"height\": 600\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1258\",\n",
      "    \"Label\": \"small intestine\",\n",
      "    \"x\": 100,\n",
      "    \"y\": 200,\n",
      "    \"width\": 300,\n",
      "    \"height\": 400\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1258\",\n",
      "    \"Label\": \"intestines\",\n",
      "    \"x\": 100,\n",
      "    \"y\": 150,\n",
      "    \"width\": 300,\n",
      "    \"height\": 450\n",
      "  }\n",
      "]\n",
      "```\n",
      "**Notes on decisions:**  \n",
      "- \"anterior-posterior\" is an imaging orientation, not an anatomy/pathology/finding, so it is omitted.\n",
      "- \"Small Intestine\" and \"small intestine\" are considered the same entity and preserved as a compound anatomical structure.\n",
      "- The detections for all valid terms are present and are anatomically mapped. There are no missing boxes nor arrow tips needing inference. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_1260 ===\n",
      "Terms: ['Cervix Uteri', 'Uterine Cavity', 'uterus', 'pelvis']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Cervix Uteri', 'Uterine Cavity', 'uterus', 'pelvis'], and caption: \"Magnetic Resonance Imaging (MRI) of the pelvis demonstrates a large mass (green arrow) in the right adnexa involving the uterus and cervix uteri, with a small amount of free fluid (blue arrow) and a small amount of blood (red arrow) wit ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV Output:**\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_1260,Cervix Uteri,160,220,50,35\n",
      "ImageCLEFmedical_Caption_2025_test_1260,Uterine Cavity,130,250,30,20\n",
      "ImageCLEFmedical_Caption_2025_test_1260,uterus,140,230,70,45\n",
      "ImageCLEFmedical_Caption_2025_test_1260,pelvis,100,200,150,120\n",
      "```\n",
      "\n",
      "**JSON Output:**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1260\",\n",
      "    \"Label\": \"Cervix Uteri\",\n",
      "    \"x\": 160,\n",
      "    \"y\": 220,\n",
      "    \"width\": 50,\n",
      "    \"height\": 35\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1260\",\n",
      "    \"Label\": \"Uterine Cavity\",\n",
      "    \"x\": 130,\n",
      "    \"y\": 250,\n",
      "    \"width\": 30,\n",
      "    \"height\": 20\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1260\",\n",
      "    \"Label\": \"uterus\",\n",
      "    \"x\": 140,\n",
      "    \"y\": 230,\n",
      "    \"width\": 70,\n",
      "    \"height\": 45\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1260\",\n",
      "    \"Label\": \"pelvis\",\n",
      "    \"x\": 100,\n",
      "    \"y\": 200,\n",
      "    \"width\": 150,\n",
      "    \"height\": 120\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "**Notes (per your criteria):**\n",
      "- All medical terms in the list are matched as single, compound entities.\n",
      "- Only anatomical structures are included (no imaging modalities, no findings or pathologies unless present as a medical term to consider).\n",
      "- For all four medical terms, explicit bounding boxes are found, so no need to estimate boxes from arrow tips.\n",
      "- Other findings like \"large mass\", \"small amount of free fluid\", and \"small amount of blood\" are not included as they are not part of the provided medical terms list. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_15167 ===\n",
      "Terms: ['Lymph Nodes', 'lymph', 'Left Axillary Region', 'Inguinal Region']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Lymph Nodes', 'lymph', 'Left Axillary Region', 'Inguinal Region'], and caption: \"Positron-Emission Tomography/Computed Tomography (PET/CT) scan of the chest, abdomen, and pelvis showing multiple metastatic lesions in the liver (blue arrow), spleen (red arrow), and lymph nodes in the left axillary region ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV**\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_15167,Lymph Nodes,140,180,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_15167,Left Axillary Region,120,150,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_15167,Inguinal Region,160,320,40,40\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**JSON**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_15167\",\n",
      "    \"Label\": \"Lymph Nodes\",\n",
      "    \"x\": 140,\n",
      "    \"y\": 180,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_15167\",\n",
      "    \"Label\": \"Left Axillary Region\",\n",
      "    \"x\": 120,\n",
      "    \"y\": 150,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_15167\",\n",
      "    \"Label\": \"Inguinal Region\",\n",
      "    \"x\": 160,\n",
      "    \"y\": 320,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Notes on choices:**\n",
      "- Each term in the list was preserved as a compound, e.g. \"Left Axillary Region\".\n",
      "- \"Lymph Nodes\" is covered by \"Mediastinal Lymph Nodes\" arrow_tip at (140,180); this was the most representative location for \"Lymph Nodes\".\n",
      "- All terms were mapped to their corresponding arrow tip locations; bounding boxes derived as a 40x40 square centered at the tip, as no original boxes were provided.\n",
      "- No modality or split/partial terms included.\n",
      "- All terms listed are valid anatomical or pathological entities, as requested. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_1776 ===\n",
      "Terms: ['X-ray Computed Tomography', 'Upper Lobe', 'Right Upper Lobe Of Lung', 'chest', 'Left Upper Lobe Of Lung']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['X-ray Computed Tomography', 'Upper Lobe', 'Right Upper Lobe Of Lung', 'chest', 'Left Upper Lobe Of Lung'], and caption: \"X-Ray Computed Tomography of the chest demonstrates a large right-sided pleural effusion involving the structure of the right upper lobe of the lung, with relative sparing of the stru ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **Step 1: Process Medical Terms**  \n",
      "Given:  \n",
      "Medical terms: ['X-ray Computed Tomography', 'Upper Lobe', 'Right Upper Lobe Of Lung', 'chest', 'Left Upper Lobe Of Lung']  \n",
      "- Remove modality term: 'X-ray Computed Tomography' (do **not** include).\n",
      "- 'Upper Lobe' is too general and not detected as such. Only include if a bounding box explicitly matches.\n",
      "- Preserve compound terms as in the detections.\n",
      "- Remaining: 'Right Upper Lobe Of Lung', 'Left Upper Lobe Of Lung', 'chest'.\n",
      "\n",
      "**Step 2: Validate Bounding Boxes**  \n",
      "From detections:  \n",
      "- 'Right Upper Lobe Of Lung': x=250, y=150, width=100, height=120  \n",
      "- 'Left Upper Lobe Of Lung': x=50, y=150, width=100, height=120  \n",
      "- 'chest': x=50, y=100, width=350, height=300  \n",
      "\n",
      "These are anatomical structures, have bounding boxes, and match terms.\n",
      "\n",
      "**Step 3: Pathology (not in supplied terms, but for completeness):**  \n",
      "The detection includes \"pleural effusion\". While not in the original medical term list, it's clinically relevant and present in the caption but is NOT requested for export.\n",
      "\n",
      "**Step 4: Prepare Output**  \n",
      "\n",
      "### CSV\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_1776,Right Upper Lobe Of Lung,250,150,100,120\n",
      "ImageCLEFmedical_Caption_2025_test_1776,Left Upper Lobe Of Lung,50,150,100,120\n",
      "ImageCLEFmedical_Caption_2025_test_1776,chest,50,100,350,300\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### JSON\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1776\",\n",
      "    \"Label\": \"Right Upper Lobe Of Lung\",\n",
      "    \"x\": 250,\n",
      "    \"y\": 150,\n",
      "    \"width\": 100,\n",
      "    \"height\": 120\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1776\",\n",
      "    \"Label\": \"Left Upper Lobe Of Lung\",\n",
      "    \"x\": 50,\n",
      "    \"y\": 150,\n",
      "    \"width\": 100,\n",
      "    \"height\": 120\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1776\",\n",
      "    \"Label\": \"chest\",\n",
      "    \"x\": 50,\n",
      "    \"y\": 100,\n",
      "    \"width\": 350,\n",
      "    \"height\": 300\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Note:**  \n",
      "- Only anatomical structure terms from the medical terms list are included.\n",
      "- Bounding boxes come directly from your \"vision detections\".\n",
      "- No image modality or split/partial terms were included.\n",
      "- No estimate boxes were required, as all included terms have bounding boxes. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_19226 ===\n",
      "Terms: ['Optic Nerve', 'Entire Eye']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Optic Nerve', 'Entire Eye'], and caption: \"Ultrasonography of the left eye demonstrates a large choroidal detachment (red arrows) involving the entire eye, with the optic nerve head displaced inferiorly, consistent with choroidal effusion.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"right\" always refer to t ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV Output:**\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_19226,Optic Nerve,40,220,60,40\n",
      "ImageCLEFmedical_Caption_2025_test_19226,Entire Eye,10,50,380,170\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**JSON Output:**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_19226\",\n",
      "    \"Label\": \"Optic Nerve\",\n",
      "    \"x\": 40,\n",
      "    \"y\": 220,\n",
      "    \"width\": 60,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_19226\",\n",
      "    \"Label\": \"Entire Eye\",\n",
      "    \"x\": 10,\n",
      "    \"y\": 50,\n",
      "    \"width\": 380,\n",
      "    \"height\": 170\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "**Notes (for clarity, not part of the output):**\n",
      "- Only \"Optic Nerve\" and \"Entire Eye\" are included as per the medical terms list and instructions.\n",
      "- \"Choroidal Effusion\" detections are ignored, since it wasn't in your provided medical terms list.\n",
      "- Compound terms are preserved as single entities.\n",
      "- No modality terms are included.\n",
      "- Bounding boxes confirmed. No need to estimate any for \"Optic Nerve\" or \"Entire Eye\"; both have valid boxes. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_19232 ===\n",
      "Terms: ['Optic Nerve']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Optic Nerve'], and caption: \"Ultrasonography of the right eye reveals a 3.9 mm thickened optic nerve sheath diameter, suggestive of increased intracranial pressure or optic neuritis involving the Optic Nerve.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"right\" always refer to the patient's left and right (th ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " CSV:\n",
      "\n",
      "ImageID,Label,x,y,width,height  \n",
      "ImageCLEFmedical_Caption_2025_test_19232,Optic Nerve,120,80,60,30  \n",
      "\n",
      "---\n",
      "\n",
      "JSON:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_19232\",\n",
      "    \"Label\": \"Optic Nerve\",\n",
      "    \"x\": 120,\n",
      "    \"y\": 80,\n",
      "    \"width\": 60,\n",
      "    \"height\": 30\n",
      "  }\n",
      "]\n",
      "``` \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_283 ===\n",
      "Terms: ['liver', 'cystic', 'Liver Segment']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['liver', 'cystic', 'Liver Segment'], and caption: \"Magnetic Resonance Imaging (MRI) of the abdomen demonstrates a 2.5 cm cystic mass in the right lobe of the liver, specifically involving liver segment VIII.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"right\" always refer to the patient's left and right (the  ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **Processed Data:**\n",
      "\n",
      "- Terms to include (per your medical terms list and compound term instruction):  \n",
      "    - liver  \n",
      "    - cystic mass (inferred from \"cystic\")  \n",
      "    - liver segment VIII (as per \"Liver Segment\" and being more specific)  \n",
      "\n",
      "**Bounding box and arrow tip handling:**\n",
      "\n",
      "- liver: Has a valid box.\n",
      "- cystic mass:\n",
      "    - First cystic mass: has a valid box.\n",
      "    - Second cystic mass: only has arrow_tip; so we generate a 40x40 box centered at (160,160):  \n",
      "        - x = 160 - 20 = 140  \n",
      "        - y = 160 - 20 = 140  \n",
      "        - width = 40  \n",
      "        - height = 40\n",
      "- liver segment VIII: Has a valid box.\n",
      "\n",
      "**Deduplication:**\n",
      "- Two \"cystic mass\" detections overlap and point to the same region (box at 150,140,50,50; arrow at 160,160). Both should be reported since both forms exist.\n",
      "\n",
      "---\n",
      "\n",
      "### CSV\n",
      "\n",
      "```csv\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_283,liver,120,100,200,150\n",
      "ImageCLEFmedical_Caption_2025_test_283,cystic mass,150,140,50,50\n",
      "ImageCLEFmedical_Caption_2025_test_283,cystic mass,140,140,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_283,liver segment VIII,150,140,50,50\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### JSON\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_283\",\n",
      "    \"Label\": \"liver\",\n",
      "    \"x\": 120,\n",
      "    \"y\": 100,\n",
      "    \"width\": 200,\n",
      "    \"height\": 150\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_283\",\n",
      "    \"Label\": \"cystic mass\",\n",
      "    \"x\": 150,\n",
      "    \"y\": 140,\n",
      "    \"width\": 50,\n",
      "    \"height\": 50\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_283\",\n",
      "    \"Label\": \"cystic mass\",\n",
      "    \"x\": 140,\n",
      "    \"y\": 140,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_283\",\n",
      "    \"Label\": \"liver segment VIII\",\n",
      "    \"x\": 150,\n",
      "    \"y\": 140,\n",
      "    \"width\": 50,\n",
      "    \"height\": 50\n",
      "  }\n",
      "]\n",
      "``` \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_3298 ===\n",
      "Terms: ['device', 'Left Renal Artery', 'stent']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['device', 'Left Renal Artery', 'stent'], and caption: \"Computed Tomography angiogram of the left subclavian artery showing a 90% stenosis of the left subclavian artery (red arrow), which is likely due to atherosclerotic disease and may be amenable to stenting with a bare-metal or drug-eluting stent devic ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV:**\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_3298,device,250,190,60,60\n",
      "ImageCLEFmedical_Caption_2025_test_3298,stent,250,190,60,60\n",
      "ImageCLEFmedical_Caption_2025_test_3298,Left Renal Artery,180,450,80,40\n",
      "```\n",
      "\n",
      "**JSON:**\n",
      "```json\n",
      "[\n",
      "  {\"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3298\", \"Label\": \"device\", \"x\": 250, \"y\": 190, \"width\": 60, \"height\": 60},\n",
      "  {\"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3298\", \"Label\": \"stent\", \"x\": 250, \"y\": 190, \"width\": 60, \"height\": 60},\n",
      "  {\"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3298\", \"Label\": \"Left Renal Artery\", \"x\": 180, \"y\": 450, \"width\": 80, \"height\": 40}\n",
      "]\n",
      "```\n",
      "\n",
      "**Explanation:**  \n",
      "- Compound terms (e.g., \"Left Renal Artery\") kept intact.\n",
      "- Only \"device\", \"stent\", and \"Left Renal Artery\" included, as per medical terms list—no modality terms.\n",
      "- All have bounding boxes; none require an estimated box.\n",
      "- From detections, \"device\" and \"stent\" share the same box (can be real-world overlap for vascular stents/devices), both marked.\n",
      "- The label \"Left Renal Artery\" included with its corresponding box.\n",
      "- \"left subclavian artery\" is not part of the medical terms list for this step, so not included. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_3563 ===\n",
      "Terms: ['X-ray Computed Tomography', 'Left Lower Lobe Of Lung', 'nodule', 'Lower Lobe', 'chest']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['X-ray Computed Tomography', 'Left Lower Lobe Of Lung', 'nodule', 'Lower Lobe', 'chest'], and caption: \"X-Ray Computed Tomography of the chest demonstrates multiple nodules (arrows) in both lungs, specifically involving the structure of the left lower lobe of lung.\".\n",
      "\n",
      "Important: In radiology, \"left\" and  ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " Certainly! Here’s how I’ll process the information:\n",
      "\n",
      "- **Relevant, valid terms:**  \n",
      "  - \"Left Lower Lobe Of Lung\" (keep as compound, matches \"left lower lobe of lung\")\n",
      "  - \"Lower Lobe\" (redundant with above, but if detected separately, list as well)\n",
      "  - \"Nodule\"\n",
      "  - (\"Chest\" is too general, omit per instructions)\n",
      "  - \"X-ray Computed Tomography\" is a modality, omit\n",
      "\n",
      "- **Bounding boxes and arrows:**  \n",
      "  - \"left lower lobe of lung\" and \"lower lobe\": One detected box: (x:50, y:150, width:100, height:200)\n",
      "  - \"nodule\": 5 arrow tips, none with a box → so for each, generate a (40x40) box centered at the arrow tip\n",
      "\n",
      "- **Resulting records:**\n",
      "  - 1 for \"Left Lower Lobe Of Lung\"\n",
      "  - 1 for \"Lower Lobe\"\n",
      "  - 5 for \"Nodule\"\n",
      "\n",
      "---\n",
      "\n",
      "**CSV**\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_3563,Left Lower Lobe Of Lung,50,150,100,200\n",
      "ImageCLEFmedical_Caption_2025_test_3563,Lower Lobe,50,150,100,200\n",
      "ImageCLEFmedical_Caption_2025_test_3563,Nodule,40,20,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_3563,Nodule,20,140,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_3563,Nodule,40,260,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_3563,Nodule,240,80,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_3563,Nodule,260,240,40,40\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**JSON**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3563\",\n",
      "    \"Label\": \"Left Lower Lobe Of Lung\",\n",
      "    \"x\": 50,\n",
      "    \"y\": 150,\n",
      "    \"width\": 100,\n",
      "    \"height\": 200\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3563\",\n",
      "    \"Label\": \"Lower Lobe\",\n",
      "    \"x\": 50,\n",
      "    \"y\": 150,\n",
      "    \"width\": 100,\n",
      "    \"height\": 200\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3563\",\n",
      "    \"Label\": \"Nodule\",\n",
      "    \"x\": 40,\n",
      "    \"y\": 20,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3563\",\n",
      "    \"Label\": \"Nodule\",\n",
      "    \"x\": 20,\n",
      "    \"y\": 140,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3563\",\n",
      "    \"Label\": \"Nodule\",\n",
      "    \"x\": 40,\n",
      "    \"y\": 260,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3563\",\n",
      "    \"Label\": \"Nodule\",\n",
      "    \"x\": 240,\n",
      "    \"y\": 80,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3563\",\n",
      "    \"Label\": \"Nodule\",\n",
      "    \"x\": 260,\n",
      "    \"y\": 240,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "``` \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_368 ===\n",
      "Terms: ['Lymph Nodes', 'Left Axillary Region']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Lymph Nodes', 'Left Axillary Region'], and caption: \"Positron-Emission Tomography/Computed Tomography (PET/CT) scan of the thorax reveals a hypermetabolic mass in the left upper lobe of the lung (arrow), with associated lymphadenopathy in the left axillary region, indicating involvement of the lymph nod ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV:**\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_368,Lymph Nodes,180,100,60,60\n",
      "ImageCLEFmedical_Caption_2025_test_368,Left Axillary Region,130,100,40,40\n",
      "```\n",
      "\n",
      "**JSON:**\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_368\",\n",
      "    \"Label\": \"Lymph Nodes\",\n",
      "    \"x\": 180,\n",
      "    \"y\": 100,\n",
      "    \"width\": 60,\n",
      "    \"height\": 60\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_368\",\n",
      "    \"Label\": \"Left Axillary Region\",\n",
      "    \"x\": 130,\n",
      "    \"y\": 100,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "```\n",
      "**Notes on Inference:**\n",
      "- All terms (Lymph Nodes, Left Axillary Region) are compound and preserved as-is.\n",
      "- No modalities are included.\n",
      "- \"Lymph Nodes\" detection had a bounding box, so used as is.\n",
      "- \"Left Axillary Region\" only had an arrow tip at (150, 120): default box (40x40) centered at (150, 120) gives top-left (130, 100). This is used in both outputs. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_3880 ===\n",
      "Terms: ['brain', 'hematoma', 'X-ray Computed Tomography', 'Right Middle Cerebral Artery']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['brain', 'hematoma', 'X-ray Computed Tomography', 'Right Middle Cerebral Artery'], and caption: \"X-Ray Computed Tomography of the brain reveals a large right-sided subdural hematoma adjacent to the structure of the right middle cerebral artery, which appears compressed by the hematoma.\".\n",
      "\n",
      "Important: In r ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV**\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_3880,brain,50,50,150,150\n",
      "ImageCLEFmedical_Caption_2025_test_3880,hematoma,140,100,60,60\n",
      "ImageCLEFmedical_Caption_2025_test_3880,hematoma,160,100,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_3880,Right Middle Cerebral Artery,130,105,40,20\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**JSON**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3880\",\n",
      "    \"Label\": \"brain\",\n",
      "    \"x\": 50,\n",
      "    \"y\": 50,\n",
      "    \"width\": 150,\n",
      "    \"height\": 150\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3880\",\n",
      "    \"Label\": \"hematoma\",\n",
      "    \"x\": 140,\n",
      "    \"y\": 100,\n",
      "    \"width\": 60,\n",
      "    \"height\": 60\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3880\",\n",
      "    \"Label\": \"hematoma\",\n",
      "    \"x\": 160,\n",
      "    \"y\": 100,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3880\",\n",
      "    \"Label\": \"Right Middle Cerebral Artery\",\n",
      "    \"x\": 130,\n",
      "    \"y\": 105,\n",
      "    \"width\": 40,\n",
      "    \"height\": 20\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Notes on Validation/Inferences**:\n",
      "- \"brain\", \"hematoma\", and \"Right Middle Cerebral Artery\" are valid, undivided terms per your requirement.\n",
      "- Omitted modality term \"X-ray Computed Tomography\".\n",
      "- One \"hematoma\" detection only had an arrow tip at (180, 120): inferred box with (x=160, y=100, width=40, height=40) centered at the arrow tip.\n",
      "- Everything is presented per your requested formats and professional standards. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_4346 ===\n",
      "Terms: ['cystic', 'Right Testis']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['cystic', 'Right Testis'], and caption: \"Ultrasonography of the right breast demonstrates a 1.5 cm hypoechoic mass (arrow) with cystic characteristics in the right breast, distinct from the normal ultrasonographic structure of the right testis.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"right\" always refer  ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " CSV:\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_4346,cystic,255,160,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_4346,Right Testis,10,200,100,250\n",
      "```\n",
      "\n",
      "JSON:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_4346\",\n",
      "    \"Label\": \"cystic\",\n",
      "    \"x\": 255,\n",
      "    \"y\": 160,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_4346\",\n",
      "    \"Label\": \"Right Testis\",\n",
      "    \"x\": 10,\n",
      "    \"y\": 200,\n",
      "    \"width\": 100,\n",
      "    \"height\": 250\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Notes on reasoning:\n",
      "- **Compound terms**: The term \"Right Testis\" is preserved as a whole.\n",
      "- **Modality terms omitted**: No modality terms are included.\n",
      "- **Cystic region**: \"Cystic\" is descriptive of the mass, indicated at the arrow tip (`x: 275, y: 180`); a default 40x40 box is centered here: top-left at (`x: 255`, `y: 160`).\n",
      "- **Right Testis bounding box**: Taken directly as provided.\n",
      "- **Other labels** (e.g., \"right breast\" or \"hypoechoic mass\") are omitted since not requested in the medical terms.\n",
      "- **CSV first, then JSON.** \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_5522 ===\n",
      "Terms: ['Right Internal Carotid Artery', 'Left Middle Cerebral Artery', 'Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Left Internal Carotid Artery']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Right Internal Carotid Artery', 'Left Middle Cerebral Artery', 'Middle Cerebral Artery', 'Right Middle Cerebral Artery', 'Left Internal Carotid Artery'], and caption: \"Computed Tomography angiogram of the brain showing the right vertebral artery (yellow arrows) and demonstrating the normal structure of  ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV Output**\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_5522,Right Internal Carotid Artery,220,180,20,60\n",
      "ImageCLEFmedical_Caption_2025_test_5522,Left Internal Carotid Artery,100,180,20,60\n",
      "ImageCLEFmedical_Caption_2025_test_5522,Middle Cerebral Artery,160,120,120,40\n",
      "ImageCLEFmedical_Caption_2025_test_5522,Right Middle Cerebral Artery,240,100,60,40\n",
      "ImageCLEFmedical_Caption_2025_test_5522,Left Middle Cerebral Artery,60,100,60,40\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**JSON Output**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_5522\",\n",
      "    \"Label\": \"Right Internal Carotid Artery\",\n",
      "    \"x\": 220,\n",
      "    \"y\": 180,\n",
      "    \"width\": 20,\n",
      "    \"height\": 60\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_5522\",\n",
      "    \"Label\": \"Left Internal Carotid Artery\",\n",
      "    \"x\": 100,\n",
      "    \"y\": 180,\n",
      "    \"width\": 20,\n",
      "    \"height\": 60\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_5522\",\n",
      "    \"Label\": \"Middle Cerebral Artery\",\n",
      "    \"x\": 160,\n",
      "    \"y\": 120,\n",
      "    \"width\": 120,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_5522\",\n",
      "    \"Label\": \"Right Middle Cerebral Artery\",\n",
      "    \"x\": 240,\n",
      "    \"y\": 100,\n",
      "    \"width\": 60,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_5522\",\n",
      "    \"Label\": \"Left Middle Cerebral Artery\",\n",
      "    \"x\": 60,\n",
      "    \"y\": 100,\n",
      "    \"width\": 60,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "**Notes**:  \n",
      "- Terms preserved as compound names.  \n",
      "- Only anatomical structures from the medical terms list are included.  \n",
      "- All have bounding boxes from detection data; none needed estimation from arrow tips.  \n",
      "- No imaging modality terms included. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_8779 ===\n",
      "Terms: ['Lymph Nodes']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Lymph Nodes'], and caption: \"Positron-Emission Tomography-Computed Tomography (PET-CT) scan of the chest demonstrating a hypermetabolic mass in the right breast (arrow), with corresponding lymph nodes showing increased metabolic activity, suggestive of malignancy.\".\n",
      "\n",
      "Important: In radiology, \"left\" and  ...\n",
      "Image exists? True\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **Step-by-step reasoning and validation:**\n",
      "\n",
      "1. **Medical Terms:**\n",
      "   - Only \"Lymph Nodes\" is relevant from your provided list.\n",
      "   - Compound term \"Lymph Nodes\" is preserved. No splitting.\n",
      "\n",
      "2. **Imaging Modality:**\n",
      "   - Omit any references to modality (which would include PET, CT, etc.).\n",
      "   - Only annotate for anatomical structures/pathologies/findings (\"Lymph Nodes\", \"hypermetabolic mass\").\n",
      "   - But *only* for terms in the provided list, which is just \"Lymph Nodes\".\n",
      "\n",
      "3. **Detections for 'Lymph Nodes':**\n",
      "   - Detected: `{\"label\": \"Lymph Nodes\", \"box\": {\"x\": 180, \"y\": 250, \"width\": 50, \"height\": 50}, \"uncertain\": true}`\n",
      "   - Box is present, so use the provided box.\n",
      "   - \"uncertain\" is noted, but for annotation purposes we annotate it as present.\n",
      "\n",
      "4. **Bounding boxes and arrow tips:**\n",
      "   - No further detections for \"Lymph Nodes\" with only an arrow tip.\n",
      "   - Only one valid box for \"Lymph Nodes\".\n",
      "   - No action needed for missing bounding box.\n",
      "\n",
      "5. **Other Detections:**\n",
      "   - There are detections for \"hypermetabolic mass\" but since it's not in the given medical terms list, omit it.\n",
      "\n",
      "**Final annotation:**\n",
      "- Only ONE entry for ImageCLEFmedical_Caption_2025_test_8779, for \"Lymph Nodes\" at x=180, y=250, width=50, height=50.\n",
      "\n",
      "---\n",
      "\n",
      "### CSV Output\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_8779,Lymph Nodes,180,250,50,50\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### JSON Output\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_8779\",\n",
      "    \"Label\": \"Lymph Nodes\",\n",
      "    \"x\": 180,\n",
      "    \"y\": 250,\n",
      "    \"width\": 50,\n",
      "    \"height\": 50\n",
      "  }\n",
      "]\n",
      "``` \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "Writing outputs to ./results_explain-3/sam_coord.csv and ./results_explain-3/sam_coord.json ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline\n",
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9593b9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ImageID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "width",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "height",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "28b071d0-fa0e-48b5-a3c5-c428674c41f8",
       "rows": [
        [
         "0",
         "ImageCLEFmedical_Caption_2025_test_118",
         "Bone Structure Of Ilium",
         "200.0",
         "450.0",
         "150.0",
         "100.0"
        ],
        [
         "1",
         "ImageCLEFmedical_Caption_2025_test_118",
         "pelvis",
         "220.0",
         "500.0",
         "160.0",
         "120.0"
        ],
        [
         "2",
         "ImageCLEFmedical_Caption_2025_test_118",
         "abdomen",
         "150.0",
         "100.0",
         "300.0",
         "350.0"
        ],
        [
         "3",
         "ImageCLEFmedical_Caption_2025_test_118",
         "Bone Structure Of Pubis",
         "230.0",
         "580.0",
         "140.0",
         "60.0"
        ],
        [
         "4",
         "ImageCLEFmedical_Caption_2025_test_118",
         "air-fluid levels",
         "230.0",
         "180.0",
         "40.0",
         "40.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ImageCLEFmedical_Caption_2025_test_118</td>\n",
       "      <td>Bone Structure Of Ilium</td>\n",
       "      <td>200.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ImageCLEFmedical_Caption_2025_test_118</td>\n",
       "      <td>pelvis</td>\n",
       "      <td>220.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ImageCLEFmedical_Caption_2025_test_118</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>150.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ImageCLEFmedical_Caption_2025_test_118</td>\n",
       "      <td>Bone Structure Of Pubis</td>\n",
       "      <td>230.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ImageCLEFmedical_Caption_2025_test_118</td>\n",
       "      <td>air-fluid levels</td>\n",
       "      <td>230.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ImageID                    Label      x  \\\n",
       "0  ImageCLEFmedical_Caption_2025_test_118  Bone Structure Of Ilium  200.0   \n",
       "1  ImageCLEFmedical_Caption_2025_test_118                   pelvis  220.0   \n",
       "2  ImageCLEFmedical_Caption_2025_test_118                  abdomen  150.0   \n",
       "3  ImageCLEFmedical_Caption_2025_test_118  Bone Structure Of Pubis  230.0   \n",
       "4  ImageCLEFmedical_Caption_2025_test_118         air-fluid levels  230.0   \n",
       "\n",
       "       y  width  height  \n",
       "0  450.0  150.0   100.0  \n",
       "1  500.0  160.0   120.0  \n",
       "2  100.0  300.0   350.0  \n",
       "3  580.0  140.0    60.0  \n",
       "4  180.0   40.0    40.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========== RESULTS ==========\n",
    "\n",
    "# Visualize the results\n",
    "display(pd.read_csv(CSV_OUTPUT).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a811d7aa",
   "metadata": {},
   "source": [
    "## SAM Medical Image Analysis with Heatmap-based Confidence\n",
    "\n",
    "This script adds heatmap generation and confidence scoring to select the best mask per label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a0223a",
   "metadata": {},
   "source": [
    "### 3. Using SAM for bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a252860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== LIBRARIES ==========\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import textwrap\n",
    "import re\n",
    "import urllib.request\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from IPython.display import display, Image as IPImage\n",
    "import warnings\n",
    "from scipy import ndimage\n",
    "from sklearn.cluster import DBSCAN\n",
    "from skimage.measure import label as skimage_label, regionprops\n",
    "from scipy.spatial.distance import euclidean\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c149598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Advanced Medical SAM with NER and Arrow Detection...\n"
     ]
    }
   ],
   "source": [
    "# ========== CONFIGURATION ==========\n",
    "\n",
    "SAM_COORD_PATH = './sam_coord.csv'\n",
    "CAPTIONS_PATH = './3_submission_explainability.csv'\n",
    "CONCEPTS_PATH = './ref_mini_concepts_natural_.csv'\n",
    "CAPTION_FILE_PATH = './caption.csv'\n",
    "IMAGES_DIR = './data/test_set_explain'\n",
    "OUTPUT_DIR = './result_explain-3/sam'\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Color palette for consistency\n",
    "COLORS = [\n",
    "    '#FF0000',  # Red\n",
    "    '#00FF00',  # Green  \n",
    "    '#0000FF',  # Blue\n",
    "    '#FFA500',  # Orange\n",
    "    '#FF00FF',  # Magenta\n",
    "    '#00FFFF',  # Cyan\n",
    "    '#800080',  # Purple\n",
    "    '#FFC0CB',  # Pink\n",
    "    '#A52A2A',  # Brown\n",
    "    '#FFFF00',  # Yellow\n",
    "    '#808080',  # Gray\n",
    "    '#000080'   # Navy Blue\n",
    "]\n",
    "\n",
    "print(\"Setting up Advanced Medical SAM with NER and Arrow Detection...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fc1a08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "SAM configured for medical images!\n"
     ]
    }
   ],
   "source": [
    "# ========== SAM SETUP ==========\n",
    "\n",
    "# Setup SAM model\n",
    "def setup_sam():\n",
    "    \"\"\"Setup SAM model with automatic download if needed.\"\"\"\n",
    "    # Download SAM model if not exists\n",
    "    os.makedirs('sam_models', exist_ok=True)\n",
    "    sam_checkpoint = \"sam_models/sam_vit_h_4b8939.pth\"\n",
    "    \n",
    "    if not os.path.exists(sam_checkpoint):\n",
    "        print(\"Downloading SAM model (this may take a few minutes)...\")\n",
    "        urllib.request.urlretrieve(\n",
    "            \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\",\n",
    "            sam_checkpoint\n",
    "        )\n",
    "        print(\"SAM model downloaded successfully!\")\n",
    "    \n",
    "    # Load SAM model\n",
    "    model_type = \"vit_h\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "    sam.to(device=device)\n",
    "    \n",
    "    # Configure mask generator optimized for medical images\n",
    "    mask_generator = SamAutomaticMaskGenerator(\n",
    "        model=sam,\n",
    "        points_per_side=32,\n",
    "        pred_iou_thresh=0.85,\n",
    "        stability_score_thresh=0.92,\n",
    "        crop_n_layers=1,\n",
    "        crop_n_points_downscale_factor=2,\n",
    "        min_mask_region_area=200\n",
    "    )\n",
    "    \n",
    "    predictor = SamPredictor(sam)\n",
    "    print(\"SAM configured for medical images!\")\n",
    "    return mask_generator, predictor, device\n",
    "\n",
    "# Initialize SAM\n",
    "mask_generator, predictor, device = setup_sam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fdcb0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading biomedical NER model...\n",
      "Medical NER model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup Medical NER Model\n",
    "def setup_medical_ner():\n",
    "    \"\"\"Setup biomedical NER model for extracting medical terms.\"\"\"\n",
    "    try:\n",
    "        print(\"Loading biomedical NER model...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
    "        model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
    "        ner_pipeline = pipeline(\"ner\", \n",
    "                               model=model, \n",
    "                               tokenizer=tokenizer, \n",
    "                               aggregation_strategy=\"simple\")\n",
    "        print(\"Medical NER model loaded successfully!\")\n",
    "        return ner_pipeline\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load biomedical NER model: {e}\")\n",
    "        print(\"Installing transformers: pip install transformers\")\n",
    "        return None\n",
    "\n",
    "# Initialize Medical NER\n",
    "medical_ner = setup_medical_ner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1bc4d6",
   "metadata": {},
   "source": [
    "## NER Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d7e4c",
   "metadata": {},
   "source": [
    "Medical NER Extraction and Comparison Script\n",
    "Extracts medical terms from explanations, cleans them, and compares with existing annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a49930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Medical NER Extraction and Comparison\n",
      "============================================================\n",
      "Loading data files...\n",
      "Loaded 16 explanations and 110 SAM annotations\n",
      "\n",
      "Extracting medical terms from captions...\n",
      "Extracted 36 raw medical terms\n",
      "\n",
      "Cleaning and deduplicating terms...\n",
      "Found 18 unique medical terms\n",
      "Comparing with 40 existing SAM labels\n",
      "\n",
      "Comparison Results:\n",
      "New terms not in SAM: 12\n",
      "Terms covered by SAM: 6\n",
      "\n",
      "Results saved to: ./data/ner.csv\n",
      "\n",
      "TOP 15 NEW MEDICAL TERMS:\n",
      "================================================================================\n",
      "Rank Term                      Freq   Conf   Location Hints       Sample ID \n",
      "--------------------------------------------------------------------------------\n",
      "1    Lymph Nodess              4      0.80   {'left': True, 'ar.. ImageCLEFmedical_Caption_2025_test_15167\n",
      "2    Right Breast              3      0.80   {'right': True, 'a.. ImageCLEFmedical_Caption_2025_test_4346\n",
      "3    Air-Fluid Level           2      0.80   {'anterior': True,.. ImageCLEFmedical_Caption_2025_test_118\n",
      "4    Stenosis                  2      0.80   {'left': True, 'ar.. ImageCLEFmedical_Caption_2025_test_3298\n",
      "5    Hypermetabolic            2      0.80   {'left': True, 'up.. ImageCLEFmedical_Caption_2025_test_368\n",
      "6    Blood                     1      0.80   {'arrow': True}      ImageCLEFmedical_Caption_2025_test_1260\n",
      "7    Fluid                     1      0.80   {'arrow': True}      ImageCLEFmedical_Caption_2025_test_1260\n",
      "8    Large Mass                1      0.80   {'right': True, 'a.. ImageCLEFmedical_Caption_2025_test_1260\n",
      "9    Free Fluid                1      0.80   {'arrow': True}      ImageCLEFmedical_Caption_2025_test_1260\n",
      "10   Pleural Effusion          1      0.80   {'right': True, 'u.. ImageCLEFmedical_Caption_2025_test_1776\n",
      "11   Effusion                  1      0.80   {'lower': True}      ImageCLEFmedical_Caption_2025_test_19226\n",
      "12   Metabolic                 1      0.80   {'right': True, 'a.. ImageCLEFmedical_Caption_2025_test_8779\n",
      "--------------------------------------------------------------------------------\n",
      "Total new terms found: 12\n",
      "Coverage rate: 33.3%\n",
      "\n",
      "NER extraction and comparison completed!\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "EXPLANATIONS_PATH = './3_submission_explainability.csv'\n",
    "SAM_COORD_PATH = './sam_coord.csv'\n",
    "OUTPUT_PATH = './data/ner.csv'\n",
    "\n",
    "def extract_location_hint(caption, term):\n",
    "    \"\"\"Extract location hints from caption context.\"\"\"\n",
    "    caption_lower = caption.lower()\n",
    "    term_lower = term.lower()\n",
    "    \n",
    "    # Find the term position in caption\n",
    "    term_pos = caption_lower.find(term_lower)\n",
    "    if term_pos == -1:\n",
    "        return None\n",
    "    \n",
    "    # Look for directional indicators around the term\n",
    "    context_window = 50  # Characters before and after\n",
    "    start = max(0, term_pos - context_window)\n",
    "    end = min(len(caption), term_pos + len(term) + context_window)\n",
    "    context = caption_lower[start:end]\n",
    "    \n",
    "    location_hints = {\n",
    "        'left': ['left', 'sinister', 'l.'],\n",
    "        'right': ['right', 'dexter', 'r.'],\n",
    "        'upper': ['upper', 'superior', 'top', 'cranial'],\n",
    "        'lower': ['lower', 'inferior', 'bottom', 'caudal'],\n",
    "        'anterior': ['anterior', 'front', 'ventral'],\n",
    "        'posterior': ['posterior', 'back', 'dorsal'],\n",
    "        'medial': ['medial', 'central', 'middle'],\n",
    "        'lateral': ['lateral', 'side', 'peripheral'],\n",
    "        'arrow': ['arrow', 'pointer', 'indicated', 'shown', 'marked']\n",
    "    }\n",
    "    \n",
    "    found_hints = {}\n",
    "    for direction, keywords in location_hints.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in context:\n",
    "                found_hints[direction] = True\n",
    "                break\n",
    "    \n",
    "    return found_hints if found_hints else None\n",
    "\n",
    "def extract_medical_terms_rule_based(caption):\n",
    "    \"\"\"Enhanced rule-based extraction of medical terms from captions.\"\"\"\n",
    "    medical_patterns = [\n",
    "        # Pathological conditions with boundaries\n",
    "        r'\\b(?:mass|tumor|tumour|lesion|nodule|growth|neoplasm)\\b',\n",
    "        r'\\b(?:hematoma|hemorrhage|bleeding|blood|clot)\\b',\n",
    "        r'\\b(?:air-fluid|fluid|effusion|pneumothorax|pleural\\s+effusion)\\b',\n",
    "        r'\\b(?:hypermetabolic|metabolic|uptake|enhancement)\\b',\n",
    "        r'\\b(?:fracture|break|dislocation|injury)\\b',\n",
    "        r'\\b(?:stenosis|occlusion|blockage|obstruction)\\b',\n",
    "        r'\\b(?:inflammation|infection|abscess|sepsis)\\b',\n",
    "        r'\\b(?:calcification|calcified|calcium|mineralization)\\b',\n",
    "        \n",
    "        # Anatomical references with descriptors\n",
    "        r'\\b(?:left|right)\\s+(?:upper|lower|middle)?\\s*(?:lobe|lung|breast|kidney|liver|ventricle)\\b',\n",
    "        r'\\b(?:left|right)\\s+(?:ventricle|atrium|carotid|cerebral|temporal|frontal|parietal|occipital)\\b',\n",
    "        r'\\b(?:internal|external|common)\\s+(?:carotid|iliac|mammary)\\s+artery\\b',\n",
    "        r'\\blymph\\s+nodes?\\b|\\badenopathy\\b',\n",
    "        \n",
    "        # Size and severity descriptors with following nouns\n",
    "        r'\\b(?:large|small|massive|extensive|diffuse|focal)\\s+(?:mass|lesion|area|collection|density)\\b',\n",
    "        r'\\b(?:severe|moderate|mild|acute|chronic)\\s+(?:inflammation|infection|stenosis|obstruction)\\b',\n",
    "        r'\\b(?:free|trapped|loculated)\\s+fluid\\b',\n",
    "        \n",
    "        # Specific medical conditions\n",
    "        r'\\b(?:pneumonia|atelectasis|consolidation|opacity|infiltrate)\\b',\n",
    "        r'\\b(?:cardiomegaly|hepatomegaly|splenomegaly)\\b',\n",
    "        r'\\b(?:thrombosis|embolism|infarct|ischemia)\\b',\n",
    "        r'\\b(?:aneurysm|dissection|stenosis)\\b',\n",
    "        r'\\b(?:cyst|polyp|diverticulum|hernia)\\b',\n",
    "        \n",
    "        # Contrast and imaging terms\n",
    "        r'\\b(?:contrast|enhancement|hypodense|hyperdense|isodense)\\b',\n",
    "        r'\\b(?:hypointense|hyperintense|signal|intensity)\\b',\n",
    "        \n",
    "        # Anatomical structures\n",
    "        r'\\b(?:vertebra|vertebrae|disc|facet|joint|bone|rib|sternum)\\b',\n",
    "        r'\\b(?:aorta|vena\\s+cava|pulmonary|coronary)\\b',\n",
    "        r'\\b(?:bladder|prostate|uterus|ovary|kidney|adrenal)\\b'\n",
    "    ]\n",
    "    \n",
    "    medical_terms = []\n",
    "    caption_lower = caption.lower()\n",
    "    \n",
    "    for pattern in medical_patterns:\n",
    "        matches = re.finditer(pattern, caption_lower, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            term = match.group().strip()\n",
    "            if len(term) > 2:  # Filter out very short terms\n",
    "                # Clean the term\n",
    "                cleaned_term = clean_medical_term(term)\n",
    "                if cleaned_term and is_valid_medical_term(cleaned_term):\n",
    "                    medical_terms.append({\n",
    "                        'term': cleaned_term,\n",
    "                        'type': 'MEDICAL_RULE',\n",
    "                        'confidence': 0.8,\n",
    "                        'location_hint': extract_location_hint(caption, term),\n",
    "                        'original_match': term,\n",
    "                        'pattern_matched': pattern\n",
    "                    })\n",
    "    \n",
    "    return medical_terms\n",
    "\n",
    "def clean_medical_term(term):\n",
    "    \"\"\"Clean and standardize medical terms.\"\"\"\n",
    "    # Convert to title case\n",
    "    cleaned = term.strip().title()\n",
    "    \n",
    "    # Handle specific medical abbreviations\n",
    "    abbreviations = {\n",
    "        'Ca': 'Calcium',\n",
    "        'Hb': 'Hemoglobin',\n",
    "        'O2': 'Oxygen',\n",
    "        'Co2': 'Carbon Dioxide',\n",
    "        'Iv': 'Intravenous',\n",
    "        'Im': 'Intramuscular'\n",
    "    }\n",
    "    \n",
    "    for abbr, full in abbreviations.items():\n",
    "        if cleaned == abbr:\n",
    "            return full\n",
    "    \n",
    "    # Remove redundant words\n",
    "    remove_words = ['Structure Of', 'Bone Structure Of', 'Entire', 'Complete']\n",
    "    for remove_word in remove_words:\n",
    "        cleaned = cleaned.replace(remove_word + ' ', '').replace(remove_word, '')\n",
    "    \n",
    "    # Standardize compound terms\n",
    "    standardizations = {\n",
    "        'Air-Fluid': 'Air-Fluid Level',\n",
    "        'Free Fluid': 'Free Fluid',\n",
    "        'Lymph Node': 'Lymph Nodes',\n",
    "        'Blood Clot': 'Thrombosis'\n",
    "    }\n",
    "    \n",
    "    for old, new in standardizations.items():\n",
    "        if old in cleaned:\n",
    "            cleaned = cleaned.replace(old, new)\n",
    "    \n",
    "    return cleaned.strip()\n",
    "\n",
    "def is_valid_medical_term(term):\n",
    "    \"\"\"Validate if a term is a proper medical term.\"\"\"\n",
    "    term_lower = term.lower()\n",
    "    \n",
    "    # Exclude common non-medical words\n",
    "    exclude_words = {\n",
    "        'the', 'and', 'or', 'of', 'in', 'on', 'at', 'to', 'for', 'with', 'by',\n",
    "        'from', 'as', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has',\n",
    "        'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may',\n",
    "        'might', 'can', 'must', 'shall', 'this', 'that', 'these', 'those',\n",
    "        'there', 'here', 'where', 'when', 'how', 'what', 'which', 'who', 'why',\n",
    "        'very', 'more', 'most', 'some', 'all', 'any', 'each', 'every', 'both',\n",
    "        'either', 'neither', 'one', 'two', 'three', 'first', 'second', 'third',\n",
    "        'new', 'old', 'good', 'bad', 'big', 'small', 'long', 'short', 'high', 'low'\n",
    "    }\n",
    "    \n",
    "    if term_lower in exclude_words:\n",
    "        return False\n",
    "    \n",
    "    # Must be at least 3 characters\n",
    "    if len(term) < 3:\n",
    "        return False\n",
    "    \n",
    "    # Must contain at least one letter\n",
    "    if not re.search(r'[a-zA-Z]', term):\n",
    "        return False\n",
    "    \n",
    "    # Should not be purely numeric\n",
    "    if term.replace('-', '').replace(' ', '').isdigit():\n",
    "        return False\n",
    "    \n",
    "    # Should not contain too many special characters\n",
    "    special_char_ratio = len(re.findall(r'[^a-zA-Z0-9\\s\\-]', term)) / len(term)\n",
    "    if special_char_ratio > 0.3:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def normalize_term_for_comparison(term):\n",
    "    \"\"\"Normalize term for comparison purposes.\"\"\"\n",
    "    # Convert to lowercase\n",
    "    normalized = term.lower()\n",
    "    \n",
    "    # Remove common prefixes/suffixes for comparison\n",
    "    prefixes_to_remove = ['left ', 'right ', 'bilateral ', 'upper ', 'lower ', 'middle ']\n",
    "    suffixes_to_remove = [' left', ' right', ' bilateral', ' upper', ' lower', ' middle']\n",
    "    \n",
    "    for prefix in prefixes_to_remove:\n",
    "        if normalized.startswith(prefix):\n",
    "            normalized = normalized[len(prefix):]\n",
    "    \n",
    "    for suffix in suffixes_to_remove:\n",
    "        if normalized.endswith(suffix):\n",
    "            normalized = normalized[:-len(suffix)]\n",
    "    \n",
    "    # Remove articles and common words\n",
    "    words_to_remove = ['the ', ' the', 'of ', ' of', 'structure ', ' structure']\n",
    "    for word in words_to_remove:\n",
    "        normalized = normalized.replace(word, ' ')\n",
    "    \n",
    "    # Clean up extra spaces\n",
    "    normalized = ' '.join(normalized.split())\n",
    "    \n",
    "    return normalized.strip()\n",
    "\n",
    "def compare_with_existing_annotations(ner_terms, sam_labels):\n",
    "    \"\"\"Compare NER terms with existing SAM annotations.\"\"\"\n",
    "    # Normalize existing SAM labels for comparison\n",
    "    sam_normalized = set()\n",
    "    for label in sam_labels:\n",
    "        normalized = normalize_term_for_comparison(label)\n",
    "        if normalized:\n",
    "            sam_normalized.add(normalized)\n",
    "    \n",
    "    # Find new terms not covered by existing annotations\n",
    "    new_terms = []\n",
    "    covered_terms = []\n",
    "    \n",
    "    for term_data in ner_terms:\n",
    "        term = term_data['term']\n",
    "        normalized_term = normalize_term_for_comparison(term)\n",
    "        \n",
    "        is_covered = False\n",
    "        \n",
    "        # Check exact match\n",
    "        if normalized_term in sam_normalized:\n",
    "            is_covered = True\n",
    "            covered_terms.append({**term_data, 'coverage_type': 'exact_match'})\n",
    "        else:\n",
    "            # Check partial matches\n",
    "            for sam_term in sam_normalized:\n",
    "                # Check if terms share significant words\n",
    "                ner_words = set(normalized_term.split())\n",
    "                sam_words = set(sam_term.split())\n",
    "                \n",
    "                # If more than 50% of words overlap, consider it covered\n",
    "                if len(ner_words.intersection(sam_words)) / max(len(ner_words), 1) > 0.5:\n",
    "                    is_covered = True\n",
    "                    covered_terms.append({**term_data, 'coverage_type': 'partial_match', 'matched_with': sam_term})\n",
    "                    break\n",
    "        \n",
    "        if not is_covered:\n",
    "            new_terms.append({**term_data, 'status': 'new_term'})\n",
    "    \n",
    "    return new_terms, covered_terms\n",
    "\n",
    "def process_ner_extraction():\n",
    "    \"\"\"Main function to process NER extraction and comparison.\"\"\"\n",
    "    print(\"Starting Medical NER Extraction and Comparison\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load data files\n",
    "    print(\"Loading data files...\")\n",
    "    \n",
    "    if not os.path.exists(EXPLANATIONS_PATH):\n",
    "        print(f\"Explanations file not found: {EXPLANATIONS_PATH}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(SAM_COORD_PATH):\n",
    "        print(f\"SAM coordinates file not found: {SAM_COORD_PATH}\")\n",
    "        return\n",
    "    \n",
    "    explanations_df = pd.read_csv(EXPLANATIONS_PATH)\n",
    "    sam_df = pd.read_csv(SAM_COORD_PATH)\n",
    "    \n",
    "    print(f\"Loaded {len(explanations_df)} explanations and {len(sam_df)} SAM annotations\")\n",
    "    \n",
    "    # Extract medical terms from all captions\n",
    "    print(\"\\nExtracting medical terms from captions...\")\n",
    "    all_ner_terms = []\n",
    "    \n",
    "    for idx, row in explanations_df.iterrows():\n",
    "        image_id = row.get('ID', row.get('id', idx))\n",
    "        caption = row.get('Caption', row.get('caption', ''))\n",
    "        \n",
    "        if pd.notna(caption) and caption.strip():\n",
    "            ner_terms = extract_medical_terms_rule_based(str(caption))\n",
    "            \n",
    "            for term_data in ner_terms:\n",
    "                term_data['image_id'] = image_id\n",
    "                term_data['source_caption'] = caption[:100] + '...' if len(caption) > 100 else caption\n",
    "                all_ner_terms.append(term_data)\n",
    "    \n",
    "    print(f\"Extracted {len(all_ner_terms)} raw medical terms\")\n",
    "    \n",
    "    # Remove duplicates and count frequencies\n",
    "    print(\"\\nCleaning and deduplicating terms...\")\n",
    "    term_counter = Counter()\n",
    "    unique_terms = {}\n",
    "    \n",
    "    for term_data in all_ner_terms:\n",
    "        term = term_data['term']\n",
    "        normalized = normalize_term_for_comparison(term)\n",
    "        \n",
    "        if normalized not in unique_terms:\n",
    "            unique_terms[normalized] = term_data\n",
    "        \n",
    "        term_counter[normalized] += 1\n",
    "    \n",
    "    # Add frequency information\n",
    "    for normalized_term, term_data in unique_terms.items():\n",
    "        term_data['frequency'] = term_counter[normalized_term]\n",
    "    \n",
    "    print(f\"Found {len(unique_terms)} unique medical terms\")\n",
    "    \n",
    "    # Get existing SAM labels\n",
    "    sam_labels = sam_df['Label'].dropna().unique().tolist()\n",
    "    print(f\"Comparing with {len(sam_labels)} existing SAM labels\")\n",
    "    \n",
    "    # Compare with existing annotations\n",
    "    new_terms, covered_terms = compare_with_existing_annotations(\n",
    "        list(unique_terms.values()), sam_labels\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nComparison Results:\")\n",
    "    print(f\"New terms not in SAM: {len(new_terms)}\")\n",
    "    print(f\"Terms covered by SAM: {len(covered_terms)}\")\n",
    "    \n",
    "    # Sort new terms by frequency and confidence\n",
    "    new_terms.sort(key=lambda x: (x['frequency'], x['confidence']), reverse=True)\n",
    "    \n",
    "    # Prepare output DataFrame\n",
    "    output_records = []\n",
    "    for i, term_data in enumerate(new_terms):\n",
    "        output_records.append({\n",
    "            'rank': i + 1,\n",
    "            'term': term_data['term'],\n",
    "            'frequency': term_data['frequency'],\n",
    "            'confidence': term_data['confidence'],\n",
    "            'type': term_data['type'],\n",
    "            'location_hints': str(term_data.get('location_hint', {})),\n",
    "            'sample_image_id': term_data['image_id'],\n",
    "            'sample_caption': term_data['source_caption'],\n",
    "            'status': term_data['status']\n",
    "        })\n",
    "    \n",
    "    # Create output directory if needed\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_df = pd.DataFrame(output_records)\n",
    "    output_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    \n",
    "    print(f\"\\nResults saved to: {OUTPUT_PATH}\")\n",
    "    \n",
    "    # Display top 15 new terms\n",
    "    print(f\"\\nTOP 15 NEW MEDICAL TERMS:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Rank':<4} {'Term':<25} {'Freq':<6} {'Conf':<6} {'Location Hints':<20} {'Sample ID':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, record in enumerate(output_records[:15]):\n",
    "        location_display = record['location_hints'][:18] + '..' if len(record['location_hints']) > 20 else record['location_hints']\n",
    "        print(f\"{record['rank']:<4} {record['term']:<25} {record['frequency']:<6} {record['confidence']:<6.2f} {location_display:<20} {record['sample_image_id']:<10}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Total new terms found: {len(new_terms)}\")\n",
    "    print(f\"Coverage rate: {len(covered_terms)/(len(covered_terms)+len(new_terms))*100:.1f}%\")\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_df = process_ner_extraction()\n",
    "    print(\"\\nNER extraction and comparison completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f163366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required functions from your notebook:\n",
      "   - get_image_path()\n",
      "   - group_compound_terms()\n",
      "   - call_gpt4v_vision()\n",
      "   - call_gpt4_1_refiner()\n",
      "\n",
      "Files that will be created/modified:\n",
      "   ./ner_coord.csv (new NER coordinates)\n",
      "   ./sam_coord.csv (merged coordinates)\n",
      "   ./sam_coord_backup.csv (backup of original)\n",
      "\n",
      "Medical context: Duplicates preserved (multiple findings per image)\n",
      "\n",
      "To run: csv_rows, merged_count = run_ner_pipeline()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NER Pipeline Adapter\n",
    "Uses existing pipeline output format and preserves duplicates (multiple findings per image)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "IMAGE_FOLDER = \"./data/test_set_explain/\"\n",
    "NER_FILE = './data/ner.csv'\n",
    "CAPTIONS_FILE = './3_submission_explainability.csv'\n",
    "ORIGINAL_SAM_COORD = './sam_coord.csv'\n",
    "NER_COORD_OUTPUT = './ner_coord.csv'\n",
    "MERGED_SAM_COORD = './sam_coord.csv'  # Overwrites original with merged data\n",
    "BACKUP_SAM_COORD = './sam_coord_backup.csv'  # Backup of original\n",
    "\n",
    "def backup_original_sam_coord():\n",
    "    \"\"\"Create backup of original sam_coord.csv before merging.\"\"\"\n",
    "    if os.path.exists(ORIGINAL_SAM_COORD):\n",
    "        print(f\"Creating backup: {BACKUP_SAM_COORD}\")\n",
    "        import shutil\n",
    "        shutil.copy2(ORIGINAL_SAM_COORD, BACKUP_SAM_COORD)\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Original sam_coord.csv not found at: {ORIGINAL_SAM_COORD}\")\n",
    "        return False\n",
    "\n",
    "def prepare_ner_data_for_pipeline():\n",
    "    \"\"\"Prepare NER data in the same format as the original concepts pipeline expects.\"\"\"\n",
    "    print(\"Loading NER terms and captions...\")\n",
    "    \n",
    "    # Load files\n",
    "    ner_df = pd.read_csv(NER_FILE)\n",
    "    captions_df = pd.read_csv(CAPTIONS_FILE)\n",
    "    \n",
    "    # Create caption mapping\n",
    "    cap_map = {str(row[\"ID\"]): str(row[\"Caption\"]) for _, row in captions_df.iterrows()}\n",
    "    \n",
    "    # Group NER terms by image_id\n",
    "    image_groups = ner_df.groupby('sample_image_id')\n",
    "    \n",
    "    # Create a concepts-like DataFrame\n",
    "    concepts_like_data = []\n",
    "    \n",
    "    for image_id, group in image_groups:\n",
    "        # Get all terms for this image (no filtering - all terms)\n",
    "        terms_list = group['term'].tolist()\n",
    "        \n",
    "        # Join terms with semicolon (like CUIs in original format)\n",
    "        terms_string = '; '.join(terms_list)\n",
    "        \n",
    "        concepts_like_data.append({\n",
    "            'ID': image_id,\n",
    "            'CUIs': terms_string\n",
    "        })\n",
    "    \n",
    "    concepts_like_df = pd.DataFrame(concepts_like_data)\n",
    "    \n",
    "    print(f\"Loaded {len(ner_df)} NER terms\")\n",
    "    print(f\"Processing {len(concepts_like_df)} images with NER terms\")\n",
    "    print(f\"Available captions: {len(captions_df)}\")\n",
    "    \n",
    "    return concepts_like_df, cap_map\n",
    "\n",
    "def merge_with_original_sam_coord(ner_csv_rows):\n",
    "    \"\"\"\n",
    "    Merge new NER coordinates with existing sam_coord.csv.\n",
    "    Preserves duplicates since multiple findings per image are valid.\n",
    "    \"\"\"\n",
    "    print(\"\\nMerging with existing sam_coord.csv...\")\n",
    "    \n",
    "    # Prepare NER data for merging\n",
    "    ner_data_lines = []\n",
    "    if ner_csv_rows:\n",
    "        # Skip header if present, keep all data rows\n",
    "        for row in ner_csv_rows:\n",
    "            if row and not row.lower().startswith('imageid'):\n",
    "                ner_data_lines.append(row)\n",
    "    \n",
    "    if not os.path.exists(ORIGINAL_SAM_COORD):\n",
    "        print(f\"Original sam_coord.csv not found. Creating new file with NER data only.\")\n",
    "        # Create new file with header + NER data\n",
    "        with open(MERGED_SAM_COORD, 'w') as f:\n",
    "            f.write(\"ImageID,Label,x,y,width,height\\n\")\n",
    "            for line in ner_data_lines:\n",
    "                f.write(line + \"\\n\")\n",
    "        merged_count = len(ner_data_lines)\n",
    "    else:\n",
    "        # Read original file\n",
    "        with open(ORIGINAL_SAM_COORD, 'r') as f:\n",
    "            original_lines = f.readlines()\n",
    "        \n",
    "        original_count = len(original_lines) - 1  # Subtract header\n",
    "        print(f\"Original sam_coord.csv: {original_count} records\")\n",
    "        \n",
    "        # Write merged file\n",
    "        with open(MERGED_SAM_COORD, 'w') as f:\n",
    "            # Write original content\n",
    "            for line in original_lines:\n",
    "                f.write(line)\n",
    "            \n",
    "            # Append NER data (no duplicates check - preserving all findings)\n",
    "            for line in ner_data_lines:\n",
    "                f.write(line + \"\\n\")\n",
    "        \n",
    "        merged_count = original_count + len(ner_data_lines)\n",
    "    \n",
    "    print(f\"Merged file: {merged_count} total records\")\n",
    "    print(f\"Added {len(ner_data_lines)} new NER records\")\n",
    "    \n",
    "    return merged_count\n",
    "\n",
    "def run_ner_pipeline():\n",
    "    \"\"\"\n",
    "    Run NER pipeline using existing functions and preserve original output format.\n",
    "    \"\"\"\n",
    "    print(\"Starting NER Terms Pipeline (Preserving Original Format)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check files exist\n",
    "    if not os.path.exists(NER_FILE):\n",
    "        print(f\"ERROR: NER file not found: {NER_FILE}\")\n",
    "        return None, None\n",
    "    \n",
    "    if not os.path.exists(CAPTIONS_FILE):\n",
    "        print(f\"ERROR: Captions file not found: {CAPTIONS_FILE}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Create backup of original sam_coord.csv\n",
    "    backup_created = backup_original_sam_coord()\n",
    "    \n",
    "    # Prepare data in the format expected by existing pipeline\n",
    "    concepts_df, cap_map = prepare_ner_data_for_pipeline()\n",
    "    \n",
    "    # Use the existing pipeline logic - EXACTLY as original\n",
    "    all_csv_rows = []\n",
    "    all_json_objs = []\n",
    "    \n",
    "    for idx, row in concepts_df.iterrows():\n",
    "        image_id = str(row[\"ID\"])\n",
    "        terms_raw = [c.strip() for c in str(row[\"CUIs\"]).split(';') if c.strip()]\n",
    "        caption = cap_map.get(image_id, \"\")\n",
    "        \n",
    "        # Use existing function to get image path\n",
    "        image_path = get_image_path(image_id)\n",
    "        if image_path is None:\n",
    "            print(f\"[{image_id}] Image not found, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Use existing function to group compound terms\n",
    "        terms = group_compound_terms(terms_raw)\n",
    "        \n",
    "        print(f\"\\n=== Processing {image_id} ===\")\n",
    "        print(f\"Original NER terms: {terms_raw}\")\n",
    "        print(f\"Grouped terms: {terms}\")\n",
    "        \n",
    "        if not terms:\n",
    "            print(f\"[{image_id}] No valid terms after grouping, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Use existing vision function\n",
    "        vision_results = call_gpt4v_vision(image_path, terms, caption)\n",
    "        if not vision_results:\n",
    "            print(f\"[{image_id}] No vision results, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Vision model returned {len(vision_results)} detections\")\n",
    "        \n",
    "        # Use existing refiner function\n",
    "        csv_out, json_out = call_gpt4_1_refiner(vision_results, terms, caption, image_id)\n",
    "        \n",
    "        # Process CSV output - EXACTLY as original pipeline\n",
    "        if csv_out:\n",
    "            if not all_csv_rows and \"ImageID\" in csv_out:\n",
    "                header, *rest = csv_out.splitlines()\n",
    "                all_csv_rows.append(header)\n",
    "                all_csv_rows.extend(rest)\n",
    "            else:\n",
    "                lines = [line for line in csv_out.splitlines() if not line.lower().startswith(\"imageid\")]\n",
    "                all_csv_rows.extend(lines)\n",
    "        \n",
    "        # Process JSON output - EXACTLY as original pipeline\n",
    "        if json_out and json_out != \"[]\":\n",
    "            try:\n",
    "                data = json.loads(json_out)\n",
    "                if isinstance(data, list):\n",
    "                    all_json_objs.extend(data)\n",
    "                    print(f\"Added {len(data)} JSON objects\")\n",
    "            except Exception as e:\n",
    "                print(f\"[{image_id}] Error parsing JSON output: {e}\")\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(2.5)\n",
    "    \n",
    "    # Save ner_coord.csv - EXACTLY as original pipeline saves\n",
    "    print(f\"\\nSaving NER coordinates to: {NER_COORD_OUTPUT}\")\n",
    "    with open(NER_COORD_OUTPUT, \"w\") as f:\n",
    "        for row in all_csv_rows:\n",
    "            f.write(row + \"\\n\")\n",
    "    \n",
    "    # Merge with original sam_coord.csv (preserving duplicates)\n",
    "    merged_count = merge_with_original_sam_coord(all_csv_rows)\n",
    "    \n",
    "    print(f\"\\nNER Pipeline completed!\")\n",
    "    print(f\"Final Summary:\")\n",
    "    print(f\"NER coordinates: {len(all_csv_rows)} rows → {NER_COORD_OUTPUT}\")\n",
    "    print(f\"Merged coordinates: {merged_count} total rows → {MERGED_SAM_COORD}\")\n",
    "    if backup_created:\n",
    "        print(f\"Original backup: {BACKUP_SAM_COORD}\")\n",
    "    print(f\"JSON objects: {len(all_json_objs)}\")\n",
    "    print(f\"Duplicates preserved (multiple findings per image allowed)\")\n",
    "    \n",
    "    return all_csv_rows, merged_count\n",
    "\n",
    "# ========== EXECUTION ==========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    To use this with existing functions in your notebook:\n",
    "    \n",
    "    1. Make sure you have the existing functions available:\n",
    "       - get_image_path()\n",
    "       - group_compound_terms() \n",
    "       - call_gpt4v_vision()\n",
    "       - call_gpt4_1_refiner()\n",
    "    \n",
    "    2. Then call:\n",
    "       csv_rows, merged_count = run_ner_pipeline()\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Required functions from your notebook:\")\n",
    "    print(\"   - get_image_path()\")\n",
    "    print(\"   - group_compound_terms()\")\n",
    "    print(\"   - call_gpt4v_vision()\")\n",
    "    print(\"   - call_gpt4_1_refiner()\")\n",
    "    print()\n",
    "    print(\"Files that will be created/modified:\")\n",
    "    print(f\"   {NER_COORD_OUTPUT} (new NER coordinates)\")\n",
    "    print(f\"   {MERGED_SAM_COORD} (merged coordinates)\")\n",
    "    print(f\"   {BACKUP_SAM_COORD} (backup of original)\")\n",
    "    print()\n",
    "    print(\"Medical context: Duplicates preserved (multiple findings per image)\")\n",
    "    print()\n",
    "    print(\"To run: csv_rows, merged_count = run_ner_pipeline()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dc7f579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NER Terms Pipeline (Preserving Original Format)\n",
      "============================================================\n",
      "Creating backup: ./sam_coord_backup.csv\n",
      "Loading NER terms and captions...\n",
      "Loaded 12 NER terms\n",
      "Processing 9 images with NER terms\n",
      "Available captions: 16\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_118 ===\n",
      "Original NER terms: ['Air-Fluid Level']\n",
      "Grouped terms: ['Air-fluid Level']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Air-fluid Level'], and caption: \"Plain radiograph of the abdomen, taken in the anterior-posterior projection, shows multiple air-fluid levels within the bowel loops, extending into the pelvis. The bone structure of the ilium and pubis is unremarkable.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"right\" alway ...\n",
      "Image exists? True\n",
      "Vision model returned 5 detections\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV Output**\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_118,Air-fluid Level,160,280,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_118,Air-fluid Level,230,260,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_118,Air-fluid Level,270,330,40,40\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**JSON Output**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_118\",\n",
      "    \"Label\": \"Air-fluid Level\",\n",
      "    \"x\": 160,\n",
      "    \"y\": 280,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_118\",\n",
      "    \"Label\": \"Air-fluid Level\",\n",
      "    \"x\": 230,\n",
      "    \"y\": 260,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_118\",\n",
      "    \"Label\": \"Air-fluid Level\",\n",
      "    \"x\": 270,\n",
      "    \"y\": 330,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Explanation:**  \n",
      "- The only relevant term from the provided medical terms list, as well as the validated visual detections, is \"Air-fluid Level.\"\n",
      "- Each detection for \"air-fluid level\" has only an arrow tip, so a default box of 40x40 px is centered at each arrow tip.  \n",
      "  - The box is defined such that `(x, y)` is the top-left corner; calculated by subtracting 20 from the tip's x and y.\n",
      "- No modality terms or split terms are present. \n",
      "- \"Ilium\" and \"pubis\" are not in the provided terms list and thus omitted. \n",
      "=== END REPLY ===\n",
      "\n",
      "Added 3 JSON objects\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_1260 ===\n",
      "Original NER terms: ['Blood', 'Fluid', 'Large Mass', 'Free Fluid']\n",
      "Grouped terms: ['blood', 'Large Mass', 'fluid', 'Free Fluid']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['blood', 'Large Mass', 'fluid', 'Free Fluid'], and caption: \"Magnetic Resonance Imaging (MRI) of the pelvis demonstrates a large mass (green arrow) in the right adnexa involving the uterus and cervix uteri, with a small amount of free fluid (blue arrow) and a small amount of blood (red arrow) within the  ...\n",
      "Image exists? True\n",
      "Vision model returned 3 detections\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV:**\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_1260,Large Mass,207,372,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_1260,Free Fluid,243,354,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_1260,blood,274,385,40,40\n",
      "```\n",
      "\n",
      "**JSON:**\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1260\",\n",
      "    \"Label\": \"Large Mass\",\n",
      "    \"x\": 207,\n",
      "    \"y\": 372,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1260\",\n",
      "    \"Label\": \"Free Fluid\",\n",
      "    \"x\": 243,\n",
      "    \"y\": 354,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1260\",\n",
      "    \"Label\": \"blood\",\n",
      "    \"x\": 274,\n",
      "    \"y\": 385,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "**Notes:**\n",
      "- Compound terms \"Large Mass\" and \"Free Fluid\" are preserved as single entities.\n",
      "- General imaging modality (\"MRI\") is omitted.\n",
      "- \"fluid\" (as a standalone term) is not present in the detections, but \"Free Fluid\" covers the relevant finding.\n",
      "- Default bounding boxes of 40x40 pixels are centered at each arrow tip: `(arrow_tip.x - 20, arrow_tip.y - 20, 40, 40)`. Calculated for each term. \n",
      "=== END REPLY ===\n",
      "\n",
      "Added 3 JSON objects\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_15167 ===\n",
      "Original NER terms: ['Lymph Nodess']\n",
      "Grouped terms: ['Lymph Nodess']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Lymph Nodess'], and caption: \"Positron-Emission Tomography/Computed Tomography (PET/CT) scan of the chest, abdomen, and pelvis showing multiple metastatic lesions in the liver (blue arrow), spleen (red arrow), and lymph nodes in the left axillary region (green arrow), inguinal region (yellow arrow), and ...\n",
      "Image exists? True\n",
      "Vision model returned 5 detections\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV**\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_15167,Lymph Nodess,125,80,50,30\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**JSON**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_15167\",\n",
      "    \"Label\": \"Lymph Nodess\",\n",
      "    \"x\": 125,\n",
      "    \"y\": 80,\n",
      "    \"width\": 50,\n",
      "    \"height\": 30\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Explanation/Notes:**\n",
      "\n",
      "- The only term in your \"medical terms to consider\" list is \"Lymph Nodess\" (note the nonstandard spelling; normally \"Lymph Nodes,\" but preserved as given).\n",
      "- Per your rules, only this term is kept.\n",
      "- The detection includes a bounding box for \"mediastinal lymph nodes,\" which matches a lymph node region and is thus retained.\n",
      "- All other anatomical structures (liver, spleen, axillary/inguinal region) are not included because they are not in your term list.\n",
      "- Modality terms are omitted per instructions.\n",
      "- No box estimation was required, as the \"mediastinal lymph nodes\" detection included a box.\n",
      "- Full CSV and JSON as specified. \n",
      "=== END REPLY ===\n",
      "\n",
      "Added 1 JSON objects\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_1776 ===\n",
      "Original NER terms: ['Pleural Effusion']\n",
      "Grouped terms: ['Pleural Effusion']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Pleural Effusion'], and caption: \"X-Ray Computed Tomography of the chest demonstrates a large right-sided pleural effusion involving the structure of the right upper lobe of the lung, with relative sparing of the structure of the left upper lobe of the lung.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"right ...\n",
      "Image exists? True\n",
      "Vision model returned 3 detections\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " Certainly. Here’s the output after curating your labels:\n",
      "\n",
      "**Given Medical Terms:**  \n",
      "- Pleural Effusion\n",
      "\n",
      "**Validation & Mapping:**  \n",
      "- Only \"Pleural Effusion\" is on the provided list and is found in the detections as \"right-sided pleural effusion\" (location: right hemithorax, matches detection and context).\n",
      "- No splitting of the compound term.\n",
      "- Other labels (“right upper lobe”, “left upper lobe”) are anatomical, not on the medical terms list.\n",
      "- No missing bounding boxes or arrow tips for the term (per provided input).\n",
      "\n",
      "---\n",
      "\n",
      "**CSV:**\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_1776,Pleural Effusion,380,150,120,200\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**JSON:**\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1776\",\n",
      "    \"Label\": \"Pleural Effusion\",\n",
      "    \"x\": 380,\n",
      "    \"y\": 150,\n",
      "    \"width\": 120,\n",
      "    \"height\": 200\n",
      "  }\n",
      "]\n",
      "```\n",
      "---\n",
      "\n",
      "**Explanation:**  \n",
      "- Only “Pleural Effusion” is included (no imaging modalities, no anatomy, no split).\n",
      "- The most specific, radiologically correct label is used: \"Pleural Effusion\" (not \"right-sided pleural effusion\").\n",
      "- The bounding box is copied from the detection (\"right-sided pleural effusion\").\n",
      "- CSV and JSON formats are provided per instruction. \n",
      "=== END REPLY ===\n",
      "\n",
      "Added 1 JSON objects\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_19226 ===\n",
      "Original NER terms: ['Effusion']\n",
      "Grouped terms: ['effusion']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['effusion'], and caption: \"Ultrasonography of the left eye demonstrates a large choroidal detachment (red arrows) involving the entire eye, with the optic nerve head displaced inferiorly, consistent with choroidal effusion.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"right\" always refer to the patient's left ...\n",
      "Image exists? True\n",
      "Vision model returned 5 detections\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **Step-by-step curation:**\n",
      "\n",
      "**1. Medical terms to consider:**  \n",
      "[\"effusion\"]  \n",
      "*Compound terms like \"choroidal effusion\" must be preserved as one entity.*\n",
      "\n",
      "**2. Detections with location:**  \n",
      "- \"choroidal detachment\" (box)\n",
      "- \"optic nerve head\" (box)\n",
      "- \"choroidal effusion\" (box)\n",
      "- \"effusion\" (arrow_tip 1)\n",
      "- \"effusion\" (arrow_tip 2)\n",
      "\n",
      "**3. Filter only the medical term(s):**  \n",
      "We need rows for every mention of \"effusion\" (whether standalone or in compounds like \"choroidal effusion\"), skip others.\n",
      "\n",
      "**4. Validate bounding boxes and arrow tips:**  \n",
      "- \"choroidal effusion\": **box present:** x=80, y=40, width=260, height=160\n",
      "- \"effusion\": **arrow tips:**  \n",
      "  - First: tip at (180, 110) → box x=160, y=90, width=40, height=40  \n",
      "  - Second: tip at (220, 180) → box x=200, y=160, width=40, height=40\n",
      "\n",
      "**Summary for CSV/JSON:**\n",
      "- 1 row for \"choroidal effusion\" (from box)\n",
      "- 2 rows for \"effusion\" (from 2 arrow tips, giving inferred boxes)\n",
      "\n",
      "**Bounding box estimation for arrow tips:**  \n",
      "Box centered at arrow tip, 40x40:  \n",
      "x = arrow_x - 20, y = arrow_y - 20\n",
      "\n",
      "---\n",
      "\n",
      "## **CSV**\n",
      "\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_19226,choroidal effusion,80,40,260,160\n",
      "ImageCLEFmedical_Caption_2025_test_19226,effusion,160,90,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_19226,effusion,200,160,40,40\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **JSON**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_19226\",\n",
      "    \"Label\": \"choroidal effusion\",\n",
      "    \"x\": 80,\n",
      "    \"y\": 40,\n",
      "    \"width\": 260,\n",
      "    \"height\": 160\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_19226\",\n",
      "    \"Label\": \"effusion\",\n",
      "    \"x\": 160,\n",
      "    \"y\": 90,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_19226\",\n",
      "    \"Label\": \"effusion\",\n",
      "    \"x\": 200,\n",
      "    \"y\": 160,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "``` \n",
      "=== END REPLY ===\n",
      "\n",
      "Added 1 JSON objects\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_3298 ===\n",
      "Original NER terms: ['Stenosis']\n",
      "Grouped terms: ['stenosis']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['stenosis'], and caption: \"Computed Tomography angiogram of the left subclavian artery showing a 90% stenosis of the left subclavian artery (red arrow), which is likely due to atherosclerotic disease and may be amenable to stenting with a bare-metal or drug-eluting stent device. The left renal artery str ...\n",
      "Image exists? True\n",
      "Vision model returned 3 detections\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV:**\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_3298,left subclavian artery stenosis,150,50,60,60\n",
      "ImageCLEFmedical_Caption_2025_test_3298,stenosis,200,40,40,40\n",
      "```\n",
      "\n",
      "**JSON:**\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3298\",\n",
      "    \"Label\": \"left subclavian artery stenosis\",\n",
      "    \"x\": 150,\n",
      "    \"y\": 50,\n",
      "    \"width\": 60,\n",
      "    \"height\": 60\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_3298\",\n",
      "    \"Label\": \"stenosis\",\n",
      "    \"x\": 200,\n",
      "    \"y\": 40,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "**Notes / Reasoning:**\n",
      "- Both \"left subclavian artery stenosis\" and \"stenosis\" are valid medical terms; \"stenosis\" is not split nor a modality. \n",
      "- \"Left subclavian artery stenosis\" already has a proper bounding box.\n",
      "- For \"stenosis\", only an arrow tip is available, so a default 40x40 box is placed centered at (220, 60): (200, 40, 40, 40).\n",
      "- \"left renal artery structure\" is an anatomical structure but described as \"unremarkable\" (normal), and does not match the term in the required medical terms list, so it is omitted.\n",
      "- No imaging modality terms included. \n",
      "=== END REPLY ===\n",
      "\n",
      "Added 2 JSON objects\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_368 ===\n",
      "Original NER terms: ['Hypermetabolic']\n",
      "Grouped terms: ['hypermetabolic']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['hypermetabolic'], and caption: \"Positron-Emission Tomography/Computed Tomography (PET/CT) scan of the thorax reveals a hypermetabolic mass in the left upper lobe of the lung (arrow), with associated lymphadenopathy in the left axillary region, indicating involvement of the lymph nodes.\".\n",
      "\n",
      "Important: In  ...\n",
      "Image exists? True\n",
      "Vision model returned 4 detections\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **CSV Output**\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_368,hypermetabolic mass,240,100,80,80\n",
      "ImageCLEFmedical_Caption_2025_test_368,lymphadenopathy,200,150,60,60\n",
      "ImageCLEFmedical_Caption_2025_test_368,left upper lobe,250,100,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_368,left axillary region,210,140,40,40\n",
      "```\n",
      "\n",
      "**JSON Output**\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_368\",\n",
      "    \"Label\": \"hypermetabolic mass\",\n",
      "    \"x\": 240,\n",
      "    \"y\": 100,\n",
      "    \"width\": 80,\n",
      "    \"height\": 80\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_368\",\n",
      "    \"Label\": \"lymphadenopathy\",\n",
      "    \"x\": 200,\n",
      "    \"y\": 150,\n",
      "    \"width\": 60,\n",
      "    \"height\": 60\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_368\",\n",
      "    \"Label\": \"left upper lobe\",\n",
      "    \"x\": 250,\n",
      "    \"y\": 100,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_368\",\n",
      "    \"Label\": \"left axillary region\",\n",
      "    \"x\": 210,\n",
      "    \"y\": 140,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "**Notes on Inference and Adherence to Instructions:**\n",
      "- Compound terms (\"hypermetabolic mass,\" \"left upper lobe,\" \"left axillary region\") are preserved as single entities.\n",
      "- Only findings, pathologies, or specific anatomical regions are included (no modalities like PET/CT).\n",
      "- For arrow tip detections (\"left upper lobe\" at 270,120 and \"left axillary region\" at 230,160), default bounding boxes of 40x40 px are centered at those points, so top-left of box is at (arrow_tip.x-20, arrow_tip.y-20).\n",
      "- All coordinates and context use the patient's anatomic left/right conventions. \n",
      "=== END REPLY ===\n",
      "\n",
      "Added 4 JSON objects\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_4346 ===\n",
      "Original NER terms: ['Right Breast']\n",
      "Grouped terms: ['Right Breast']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['Right Breast'], and caption: \"Ultrasonography of the right breast demonstrates a 1.5 cm hypoechoic mass (arrow) with cystic characteristics in the right breast, distinct from the normal ultrasonographic structure of the right testis.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"right\" always refer to the pat ...\n",
      "Image exists? True\n",
      "Vision model returned 2 detections\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " CSV:\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_4346,Right Breast,50,50,150,150\n",
      "```\n",
      "\n",
      "JSON:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_4346\",\n",
      "    \"Label\": \"Right Breast\",\n",
      "    \"x\": 50,\n",
      "    \"y\": 50,\n",
      "    \"width\": 150,\n",
      "    \"height\": 150\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "**Notes:**\n",
      "- Only \"Right Breast\" from the provided medical terms list is used, as required.\n",
      "- \"Right Breast\" is detected with a bounding box ([50, 50, 150, 150]).\n",
      "- General imaging modalities are omitted.\n",
      "- Compound term (\"Right Breast\") is preserved as a single label.\n",
      "- No bounding box or term for \"testis\" is present in either the terms or detections, so it's omitted.\n",
      "- Only valid medical term detections are listed per instructions. \n",
      "=== END REPLY ===\n",
      "\n",
      "Added 1 JSON objects\n",
      "\n",
      "=== Processing ImageCLEFmedical_Caption_2025_test_8779 ===\n",
      "Original NER terms: ['Metabolic']\n",
      "Grouped terms: ['metabolic']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['metabolic'], and caption: \"Positron-Emission Tomography-Computed Tomography (PET-CT) scan of the chest demonstrating a hypermetabolic mass in the right breast (arrow), with corresponding lymph nodes showing increased metabolic activity, suggestive of malignancy.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"r ...\n",
      "Image exists? True\n",
      "Vision model returned 3 detections\n",
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **Step-by-step reasoning:**\n",
      "\n",
      "### Step 1: Medical Terms Filtering\n",
      "\n",
      "- Given terms: **['metabolic']**\n",
      "    - \"Metabolic\" is a finding/descriptor, and should stay as a single unit if part of a compound, like \"metabolic activity\". From caption: \"hypermetabolic mass\", \"increased metabolic activity\".\n",
      "- Remove imaging modality terms: PET, CT, scan.\n",
      "- Target anatomical/pathological items: right breast, lymph nodes, (hyper)metabolic mass/activity.\n",
      "- For bounding boxes, only process valid medical terms, per instructions.\n",
      "\n",
      "### Step 2: Bounding Boxes\n",
      "\n",
      "From detections:\n",
      "\n",
      "1. {\"label\": \"right breast\", \"box\": {\"x\": 250, \"y\": 300, \"width\": 150, \"height\": 150}}\n",
      "    - Valid: \"right breast\"\n",
      "2. {\"label\": \"lymph nodes\", \"box\": {\"x\": 280, \"y\": 420, \"width\": 100, \"height\": 100}, \"uncertain\": true}\n",
      "    - Valid: \"lymph nodes\"\n",
      "3. {\"label\": \"right breast\", \"arrow_tip\": {\"x\": 220, \"y\": 320}}\n",
      "    - No bounding box, but there is arrow_tip: estimate a 40x40 box centered at (220,320)\n",
      "        - Thus: x=220-20=200; y=320-20=300; width=40; height=40\n",
      "\n",
      "**No explicit box for \"hypermetabolic mass\", but caption says in the right breast (arrow).**\n",
      "So the \"arrow_tip\" may specifically indicate the location of the mass (not general right breast).\n",
      "\n",
      "Thus, it's best to label this detection as \"hypermetabolic mass\" rather than \"right breast\" because that's what the arrow is highlighting (per caption).\n",
      "\n",
      "So, edit detection #3 from \"right breast\" to \"hypermetabolic mass\", because that's what the arrow is conveying.\n",
      "\n",
      "### Step 3: CSV and JSON output for medical terms only\n",
      "\n",
      "**Rows:**\n",
      "\n",
      "- ImageCLEFmedical_Caption_2025_test_8779, right breast, 250, 300, 150, 150\n",
      "- ImageCLEFmedical_Caption_2025_test_8779, lymph nodes, 280, 420, 100, 100\n",
      "- ImageCLEFmedical_Caption_2025_test_8779, hypermetabolic mass, 200, 300, 40, 40\n",
      "\n",
      "(\"Metabolic\" is not an anatomical finding, but \"hypermetabolic mass\" is the relevant finding for the location.)\n",
      "\n",
      "---\n",
      "\n",
      "## CSV\n",
      "\n",
      "```csv\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_8779,right breast,250,300,150,150\n",
      "ImageCLEFmedical_Caption_2025_test_8779,lymph nodes,280,420,100,100\n",
      "ImageCLEFmedical_Caption_2025_test_8779,hypermetabolic mass,200,300,40,40\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## JSON\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_8779\",\n",
      "    \"Label\": \"right breast\",\n",
      "    \"x\": 250,\n",
      "    \"y\": 300,\n",
      "    \"width\": 150,\n",
      "    \"height\": 150\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_8779\",\n",
      "    \"Label\": \"lymph nodes\",\n",
      "    \"x\": 280,\n",
      "    \"y\": 420,\n",
      "    \"width\": 100,\n",
      "    \"height\": 100\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_8779\",\n",
      "    \"Label\": \"hypermetabolic mass\",\n",
      "    \"x\": 200,\n",
      "    \"y\": 300,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "``` \n",
      "=== END REPLY ===\n",
      "\n",
      "Added 3 JSON objects\n",
      "\n",
      "Saving NER coordinates to: ./ner_coord.csv\n",
      "\n",
      "Merging with existing sam_coord.csv...\n",
      "Original sam_coord.csv: 147 records\n",
      "Merged file: 200 total records\n",
      "Added 53 new NER records\n",
      "\n",
      "NER Pipeline completed!\n",
      "Final Summary:\n",
      "NER coordinates: 72 rows → ./ner_coord.csv\n",
      "Merged coordinates: 200 total rows → ./sam_coord.csv\n",
      "Original backup: ./sam_coord_backup.csv\n",
      "JSON objects: 19\n",
      "Duplicates preserved (multiple findings per image allowed)\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el pipeline\n",
    "csv_rows, merged_count = run_ner_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb4f66",
   "metadata": {},
   "source": [
    "### NLP Techniques to detect missing terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c00c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting search for missing medical terms...\n",
      "WARNING:__main__:No term column found in sam_coord.csv. Available columns: ['ImageID', 'Label', 'x', 'y', 'width', 'height']\n",
      "INFO:__main__:Existing terms loaded: 83\n",
      "INFO:__main__:Explainability file loaded: 16 rows\n",
      "INFO:__main__:Using ID column: 'ID', text column: 'Caption'\n",
      "INFO:__main__:File missing_terms.csv created with 4 missing terms\n",
      "INFO:__main__:Summary:\n",
      "INFO:__main__:- Images with missing terms: 3\n",
      "INFO:__main__:- Unique missing terms: 4\n",
      "INFO:__main__:- Total records: 4\n",
      "INFO:__main__:\n",
      "Most frequent missing terms:\n",
      "INFO:__main__:  - 'mitral': 1 times\n",
      "INFO:__main__:  - 'spleen': 1 times\n",
      "INFO:__main__:  - '1.5 cm hypoechoic mass': 1 times\n",
      "INFO:__main__:  - 'hypoechoic mass': 1 times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process completed. Check the file missing_terms.csv\n",
      "Example of missing terms for ImageCLEFmedical_Caption_2025_test_4346:\n",
      "                               image_id           missing_term\n",
      "ImageCLEFmedical_Caption_2025_test_4346 1.5 cm hypoechoic mass\n",
      "ImageCLEFmedical_Caption_2025_test_4346        hypoechoic mass\n"
     ]
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def extract_medical_terms_enhanced(text):\n",
    "    \"\"\"\n",
    "    Enhanced rule-based extraction of medical terms from captions.\n",
    "    Ensures measurements are always extracted with their associated nouns.\n",
    "    \"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return []\n",
    "    \n",
    "    text = text.lower()\n",
    "    medical_terms = []\n",
    "    \n",
    "    # PRIORITY: Complete measurement phrases with descriptors and nouns\n",
    "    measurement_phrase_patterns = [\n",
    "        # Complete phrases: measurement + descriptor + noun\n",
    "        r'\\b\\d+(?:\\.\\d+)?\\s*(?:cm|mm)\\s+(?:hypoechoic|hyperechoic|isoechoic|anechoic|mixed|echogenic|echolucent|solid|cystic|complex|heterogeneous|homogeneous|well-defined|ill-defined|poorly-defined)\\s+(?:mass|lesion|nodule|cyst|tumor|tumour|growth|collection|area|region|structure)\\b',\n",
    "        \n",
    "        # Reverse order: descriptor + noun + measurement\n",
    "        r'\\b(?:hypoechoic|hyperechoic|isoechoic|anechoic|mixed|echogenic|echolucent|solid|cystic|complex|heterogeneous|homogeneous|well-defined|ill-defined|poorly-defined)\\s+(?:mass|lesion|nodule|cyst|tumor|tumour|growth|collection|area|region|structure)\\s+(?:measuring|of|approximately)\\s+\\d+(?:\\.\\d+)?\\s*(?:cm|mm)\\b',\n",
    "        \n",
    "        # Noun + measuring + dimension\n",
    "        r'\\b(?:mass|lesion|nodule|cyst|tumor|tumour|growth|collection|area|region|structure)\\s+measuring\\s+\\d+(?:\\.\\d+)?\\s*(?:x\\s*\\d+(?:\\.\\d+)?)?\\s*(?:x\\s*\\d+(?:\\.\\d+)?)?\\s*(?:cm|mm)\\b',\n",
    "        \n",
    "        # Multi-dimensional measurements with nouns\n",
    "        r'\\b\\d+(?:\\.\\d+)?\\s*(?:x\\s*\\d+(?:\\.\\d+)?)?\\s*(?:x\\s*\\d+(?:\\.\\d+)?)?\\s*(?:cm|mm)\\s+(?:mass|lesion|nodule|tumor|tumour|cyst|growth|collection|area|region)\\b',\n",
    "        \n",
    "        # Approximate measurements with nouns\n",
    "        r'\\b(?:approximately|about|roughly)\\s+\\d+(?:\\.\\d+)?\\s*(?:cm|mm)\\s+(?:mass|lesion|nodule|tumor|tumour|cyst|growth|collection|area|region)\\b',\n",
    "        r'\\b(?:mass|lesion|nodule|tumor|tumour|cyst|growth|collection|area|region)\\s+(?:approximately|about|roughly)\\s+\\d+(?:\\.\\d+)?\\s*(?:cm|mm)\\b',\n",
    "        \n",
    "        # Multi-word descriptive phrases with measurements\n",
    "        r'\\b\\d+(?:\\.\\d+)?\\s*(?:cm|mm)\\s+(?:well|ill|poorly)\\s*-?\\s*(?:defined|circumscribed|demarcated)\\s+(?:hypoechoic|hyperechoic|isoechoic|anechoic|mixed|echogenic)\\s+(?:mass|lesion|nodule|cyst|structure)\\b',\n",
    "        \n",
    "        # Complex anatomical measurements\n",
    "        r'\\b(?:approximately|about|roughly)\\s+\\d+(?:\\.\\d+)?\\s*(?:cm|mm)\\s+(?:hypoechoic|hyperechoic|isoechoic|anechoic|mixed|echogenic|solid|cystic|complex)\\s+(?:mass|lesion|nodule|cyst|structure)\\s+(?:in|within|at)\\s+(?:the\\s+)?(?:liver|kidney|thyroid|pancreas|gallbladder|uterus|ovary|breast|heart)\\b'\n",
    "    ]\n",
    "    \n",
    "    # Extract complete measurement phrases first (highest priority)\n",
    "    for pattern in measurement_phrase_patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            if isinstance(match, tuple):\n",
    "                term = ' '.join(match).strip()\n",
    "            else:\n",
    "                term = match.strip()\n",
    "            \n",
    "            if len(term) > 5:  # Ensure meaningful phrases\n",
    "                medical_terms.append(term.lower())\n",
    "                logger.debug(f\"Captured measurement phrase: {term}\")\n",
    "    \n",
    "    # Enhanced medical patterns - MEASUREMENTS MUST BE LINKED TO NOUNS\n",
    "    medical_patterns = [\n",
    "        # Specific ultrasound characteristics WITH CONTEXT (no standalone characteristics)\n",
    "        r'\\b(?:well|ill|poorly)\\s*-?\\s*(?:defined|circumscribed|demarcated)\\s+(?:mass|lesion|nodule|area|region|cyst|tumor|tumour|growth)\\b',\n",
    "        r'\\b(?:mass|lesion|nodule|area|region|cyst|tumor|tumour|growth)\\s+(?:with\\s+)?(?:well|ill|poorly)\\s*-?\\s*(?:defined|circumscribed|demarcated)\\s+(?:margins|borders|contours)\\b',\n",
    "        r'\\b(?:heterogeneous|homogeneous)\\s+(?:mass|lesion|nodule|area|region|cyst|tumor|tumour|growth|echogenicity|echotexture|appearance)\\b',\n",
    "        r'\\b(?:mass|lesion|nodule|area|region|cyst|tumor|tumour|growth)\\s+(?:with\\s+)?(?:heterogeneous|homogeneous)\\s+(?:echogenicity|echotexture|appearance)\\b',\n",
    "        r'\\b(?:acoustic|posterior)\\s+(?:shadowing|enhancement)\\s+(?:from|behind|of)\\s+(?:mass|lesion|nodule|cyst|structure)\\b',\n",
    "        \n",
    "        # Echo characteristics ONLY with anatomical context\n",
    "        r'\\b(?:hypoechoic|hyperechoic|isoechoic|anechoic|mixed\\s+echogenicity|echogenic|echolucent|echopoor|echorich)\\s+(?:mass|lesion|nodule|area|region|cyst|tumor|tumour|growth|structure|parenchyma|wall|cortex|medulla)\\b',\n",
    "        r'\\b(?:mass|lesion|nodule|area|region|cyst|tumor|tumour|growth|structure|parenchyma|wall|cortex|medulla)\\s+(?:with\\s+|showing\\s+)?(?:hypoechoic|hyperechoic|isoechoic|anechoic|mixed|echogenic|echolucent|echopoor|echorich)\\s+(?:echogenicity|appearance|characteristics)\\b',\n",
    "        \n",
    "        # Pathologies and conditions (standalone medical terms - these are OK without measurements)\n",
    "        r'\\b(?:mass|tumor|tumour|lesion|nodule|growth|neoplasm|cyst|polyp|hematoma|hemorrhage|bleeding|abscess|collection|calcification|thrombus|thrombosis|embolism|stenosis|occlusion|obstruction|dilatation|dilation|distension|inflammation|infection|fibrosis|scarring)\\b',\n",
    "        \n",
    "        # Anatomical structures with modifiers (these provide medical context)\n",
    "        r'\\b(?:gallbladder|cholecyst)\\s+(?:wall|mucosa|fundus|neck|distension|thickening)\\b',\n",
    "        r'\\b(?:liver|hepatic)\\s+(?:parenchyma|segment|lobe|capsule|surface|contour)\\b',\n",
    "        r'\\b(?:pancreatic|pancreas)\\s+(?:head|body|tail|duct|parenchyma|contour)\\b',\n",
    "        r'\\b(?:renal|kidney)\\s+(?:cortex|medulla|pelvis|calix|capsule|parenchyma|collecting\\s+system)\\b',\n",
    "        r'\\b(?:thyroid|thyroidal)\\s+(?:gland|nodule|lobe|isthmus|parenchyma|capsule)\\b',\n",
    "        r'\\b(?:uterine|uterus)\\s+(?:fundus|body|cervix|wall|cavity|endometrium|myometrium)\\b',\n",
    "        r'\\b(?:ovarian|ovary|ovaries)\\s+(?:follicle|cyst|mass|parenchyma|capsule|stroma)\\b',\n",
    "        r'\\b(?:cardiac|heart)\\s+(?:chamber|valve|wall|septum|muscle|pericardium)\\b',\n",
    "        r'\\b(?:vascular|vessel|artery|vein)\\s+(?:wall|lumen|flow|diameter|caliber)\\b',\n",
    "        \n",
    "        # Organs and anatomical structures (contextual - these are meaningful standalone)\n",
    "        r'\\b(?:liver|hepatic|gallbladder|pancreas|pancreatic|spleen|splenic|kidney|renal|bladder|prostate|prostatic|thyroid|thyroidal|parathyroid|carotid|uterus|uterine|ovary|ovarian|cervix|cervical|heart|cardiac|aorta|aortic|mitral|tricuspid|breast|mammary|axillary|lymph\\s+node|pleura|pleural|lung|pulmonary|bronchial)\\b',\n",
    "        \n",
    "        # Texture/characteristics ONLY with anatomical context\n",
    "        r'\\b(?:solid|cystic|complex|simple)\\s+(?:mass|lesion|nodule|cyst|structure|component|area|region)\\b',\n",
    "        r'\\b(?:mass|lesion|nodule|cyst|structure|component|area|region)\\s+(?:with\\s+)?(?:solid|cystic|complex|simple)\\s+(?:components|characteristics|appearance|features)\\b',\n",
    "        r'\\b(?:regular|irregular)\\s+(?:contour|margin|border|outline)\\s+(?:of\\s+)?(?:mass|lesion|nodule|cyst|organ|structure)\\b',\n",
    "        r'\\b(?:mass|lesion|nodule|cyst|organ|structure)\\s+(?:with\\s+)?(?:regular|irregular)\\s+(?:contour|margin|border|outline)\\b',\n",
    "        r'\\b(?:increased|decreased|normal)\\s+(?:echogenicity|vascularity|enhancement)\\s+(?:of\\s+)?(?:mass|lesion|organ|parenchyma|structure)\\b',\n",
    "        r'\\b(?:doppler|color\\s+flow|power\\s+doppler)\\s+(?:signal|assessment|evaluation)\\s+(?:of\\s+)?(?:mass|lesion|vessel|organ)\\b',\n",
    "        \n",
    "        # Specific anatomical locations with direction/position\n",
    "        r'\\b(?:right|left|bilateral|unilateral)\\s+(?:upper|lower|middle)\\s+(?:pole|third|quadrant|lobe|segment)\\b',\n",
    "        r'\\b(?:anterior|posterior|superior|inferior|medial|lateral)\\s+(?:wall|aspect|portion|surface)\\s+(?:of\\s+)?(?:organ|structure|mass|lesion)\\b',\n",
    "        r'\\b(?:subcapsular|intraparenchymal|extraperitoneal|retroperitoneal)\\s+(?:mass|lesion|collection|hematoma|structure)\\b'\n",
    "    ]\n",
    "    \n",
    "    # Extract other medical patterns (contextual terms only)\n",
    "    for pattern in medical_patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            if isinstance(match, tuple):\n",
    "                term = ' '.join(match).strip()\n",
    "            else:\n",
    "                term = match.strip()\n",
    "            \n",
    "            if len(term) > 2:  # Filter very short terms\n",
    "                medical_terms.append(term.lower())\n",
    "    \n",
    "    # Remove duplicates and filter out standalone measurements without context\n",
    "    unique_terms = []\n",
    "    seen_terms = set()\n",
    "    \n",
    "    for term in medical_terms:\n",
    "        term = term.strip()\n",
    "        if len(term) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Skip standalone measurements without medical context\n",
    "        if re.match(r'^\\d+(?:\\.\\d+)?\\s*(?:cm|mm)$', term):\n",
    "            logger.debug(f\"Skipped standalone measurement: {term}\")\n",
    "            continue\n",
    "        \n",
    "        # Skip standalone dimensions without context  \n",
    "        if re.match(r'^\\d+(?:\\.\\d+)?\\s*x\\s*\\d+(?:\\.\\d+)?\\s*(?:cm|mm)$', term):\n",
    "            logger.debug(f\"Skipped standalone dimensions: {term}\")\n",
    "            continue\n",
    "            \n",
    "        # Skip very generic terms without context\n",
    "        generic_terms = {'measuring', 'approximately', 'about', 'cm', 'mm'}\n",
    "        if term.lower() in generic_terms:\n",
    "            logger.debug(f\"Skipped generic term: {term}\")\n",
    "            continue\n",
    "        \n",
    "        if term not in seen_terms:\n",
    "            unique_terms.append(term)\n",
    "            seen_terms.add(term)\n",
    "    \n",
    "    # Sort by length (more specific terms first) and then by presence of measurements\n",
    "    def sort_key(term):\n",
    "        has_measurement = bool(re.search(r'\\d+(?:\\.\\d+)?\\s*(?:cm|mm)', term))\n",
    "        return (has_measurement, len(term))\n",
    "    \n",
    "    unique_terms.sort(key=sort_key, reverse=True)\n",
    "    \n",
    "    return unique_terms\n",
    "\n",
    "def load_existing_terms(sam_coord_file):\n",
    "    \"\"\"\n",
    "    Load existing medical terms from sam_coord.csv\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sam_df = pd.read_csv(sam_coord_file)\n",
    "        existing_terms = set()\n",
    "        \n",
    "        # Assume there's a column with medical terms (adjust according to actual structure)\n",
    "        # Commonly could be 'term', 'medical_term', 'object', etc.\n",
    "        possible_columns = ['term', 'medical_term', 'object', 'label', 'annotation']\n",
    "        \n",
    "        term_column = None\n",
    "        for col in possible_columns:\n",
    "            if col in sam_df.columns:\n",
    "                term_column = col\n",
    "                break\n",
    "        \n",
    "        if term_column:\n",
    "            existing_terms = set(sam_df[term_column].dropna().str.lower())\n",
    "            logger.info(f\"Loaded {len(existing_terms)} existing terms from column '{term_column}'\")\n",
    "        else:\n",
    "            logger.warning(f\"No term column found in {sam_coord_file}. Available columns: {list(sam_df.columns)}\")\n",
    "            # If we don't find the column, check all text columns\n",
    "            for col in sam_df.columns:\n",
    "                if sam_df[col].dtype == 'object':\n",
    "                    existing_terms.update(sam_df[col].dropna().str.lower())\n",
    "        \n",
    "        return existing_terms\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading {sam_coord_file}: {e}\")\n",
    "        return set()\n",
    "\n",
    "def find_missing_medical_terms(explainability_file, sam_coord_file, output_file='missing_terms.csv'):\n",
    "    \"\"\"\n",
    "    Main function to find missing medical terms\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting search for missing medical terms...\")\n",
    "    \n",
    "    # Load existing terms\n",
    "    existing_terms = load_existing_terms(sam_coord_file)\n",
    "    logger.info(f\"Existing terms loaded: {len(existing_terms)}\")\n",
    "    \n",
    "    # Load explainability file\n",
    "    try:\n",
    "        explain_df = pd.read_csv(explainability_file)\n",
    "        logger.info(f\"Explainability file loaded: {len(explain_df)} rows\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading {explainability_file}: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Identify relevant columns\n",
    "    id_column = None\n",
    "    text_column = None\n",
    "    \n",
    "    # Search for ID column\n",
    "    for col in explain_df.columns:\n",
    "        if 'id' in col.lower() or 'image' in col.lower():\n",
    "            id_column = col\n",
    "            break\n",
    "    \n",
    "    # Search for text/explanation column\n",
    "    for col in explain_df.columns:\n",
    "        if any(keyword in col.lower() for keyword in ['caption', 'explanation', 'text', 'description']):\n",
    "            text_column = col\n",
    "            break\n",
    "    \n",
    "    if not id_column or not text_column:\n",
    "        logger.error(f\"ID or text columns not found. Available columns: {list(explain_df.columns)}\")\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"Using ID column: '{id_column}', text column: '{text_column}'\")\n",
    "    \n",
    "    # Process each row\n",
    "    missing_terms_data = []\n",
    "    processed_count = 0\n",
    "    \n",
    "    for idx, row in explain_df.iterrows():\n",
    "        image_id = row[id_column]\n",
    "        caption = row[text_column]\n",
    "        \n",
    "        if pd.isna(caption) or pd.isna(image_id):\n",
    "            continue\n",
    "        \n",
    "        # Extract medical terms from explanation\n",
    "        extracted_terms = extract_medical_terms_enhanced(caption)\n",
    "        \n",
    "        # Find missing terms\n",
    "        missing_terms = []\n",
    "        for term in extracted_terms:\n",
    "            # Check if the term or any variation is in existing terms\n",
    "            term_found = False\n",
    "            for existing_term in existing_terms:\n",
    "                if term in existing_term or existing_term in term:\n",
    "                    term_found = True\n",
    "                    break\n",
    "            \n",
    "            if not term_found:\n",
    "                missing_terms.append(term)\n",
    "        \n",
    "        # If there are missing terms, add to results\n",
    "        if missing_terms:\n",
    "            for term in missing_terms:\n",
    "                missing_terms_data.append({\n",
    "                    'image_id': image_id,\n",
    "                    'missing_term': term,\n",
    "                    'original_caption': caption[:200] + '...' if len(caption) > 200 else caption\n",
    "                })\n",
    "        \n",
    "        processed_count += 1\n",
    "        if processed_count % 100 == 0:\n",
    "            logger.info(f\"Processed {processed_count} images...\")\n",
    "    \n",
    "    # Save results\n",
    "    if missing_terms_data:\n",
    "        missing_df = pd.DataFrame(missing_terms_data)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        missing_df = missing_df.drop_duplicates(subset=['image_id', 'missing_term'])\n",
    "        \n",
    "        # Save CSV\n",
    "        missing_df.to_csv(output_file, index=False)\n",
    "        logger.info(f\"File {output_file} created with {len(missing_df)} missing terms\")\n",
    "        \n",
    "        # Show statistics\n",
    "        unique_images = missing_df['image_id'].nunique()\n",
    "        unique_terms = missing_df['missing_term'].nunique()\n",
    "        \n",
    "        logger.info(f\"Summary:\")\n",
    "        logger.info(f\"- Images with missing terms: {unique_images}\")\n",
    "        logger.info(f\"- Unique missing terms: {unique_terms}\")\n",
    "        logger.info(f\"- Total records: {len(missing_df)}\")\n",
    "        \n",
    "        # Show most common missing terms\n",
    "        term_counts = missing_df['missing_term'].value_counts().head(10)\n",
    "        logger.info(f\"\\nMost frequent missing terms:\")\n",
    "        for term, count in term_counts.items():\n",
    "            logger.info(f\"  - '{term}': {count} times\")\n",
    "        \n",
    "        return missing_df\n",
    "    else:\n",
    "        logger.info(\"No missing medical terms found\")\n",
    "        return None\n",
    "\n",
    "# Example usage function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main example function\n",
    "    \"\"\"\n",
    "    explainability_file = '3_submission_explainability.csv'\n",
    "    sam_coord_file = 'sam_coord.csv'\n",
    "    output_file = 'missing_terms.csv'\n",
    "    \n",
    "    result = find_missing_medical_terms(explainability_file, sam_coord_file, output_file)\n",
    "    \n",
    "    if result is not None:\n",
    "        print(f\"\\nProcess completed. Check the file {output_file}\")\n",
    "        print(f\"Example of missing terms for ImageCLEFmedical_Caption_2025_test_4346:\")\n",
    "        \n",
    "        # Search for the specific image mentioned\n",
    "        example_image = result[result['image_id'].str.contains('4346', na=False)]\n",
    "        if not example_image.empty:\n",
    "            print(example_image[['image_id', 'missing_term']].to_string(index=False))\n",
    "        else:\n",
    "            print(\"No missing terms found for that specific image\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4b2e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85ab318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Medical Terms Pipeline\n",
      "Required functions: get_image_path, group_compound_terms, call_gpt4v_vision, call_gpt4_1_refiner\n",
      "Usage:\n",
      "  csv_rows, total = run_complete_workflow()  # Complete pipeline\n",
      "  csv_rows, total = run_missing_terms_pipeline()  # Process existing missing_terms.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Missing Medical Terms Pipeline Adapter\n",
    "Reuses existing notebook functions to process missing terms\n",
    "\"\"\"\n",
    "\n",
    "# Configuration\n",
    "MISSING_TERMS_FILE = './missing_terms.csv'\n",
    "CAPTIONS_FILE = './3_submission_explainability.csv'\n",
    "SAM_COORD_FILE = './sam_coord.csv'\n",
    "MISSING_COORD_OUTPUT = './missing_terms_coord.csv'\n",
    "BACKUP_SAM_COORD = './sam_coord_backup.csv'\n",
    "\n",
    "def prepare_missing_terms_data():\n",
    "    \"\"\"Convert missing_terms.csv to the format expected by existing functions.\"\"\"\n",
    "    missing_df = pd.read_csv(MISSING_TERMS_FILE)\n",
    "    captions_df = pd.read_csv(CAPTIONS_FILE)\n",
    "    \n",
    "    # Create caption mapping (auto-detect columns)\n",
    "    id_col = next((col for col in captions_df.columns if 'id' in col.lower()), None)\n",
    "    cap_col = next((col for col in captions_df.columns if any(k in col.lower() for k in ['caption', 'explanation', 'text'])), None)\n",
    "    \n",
    "    cap_map = {str(row[id_col]): str(row[cap_col]) for _, row in captions_df.iterrows()}\n",
    "    \n",
    "    # Group terms by image (concepts format)\n",
    "    concepts_data = []\n",
    "    for image_id, group in missing_df.groupby('image_id'):\n",
    "        terms = '; '.join(group['missing_term'].unique())\n",
    "        concepts_data.append({'ID': image_id, 'CUIs': terms})\n",
    "    \n",
    "    return pd.DataFrame(concepts_data), cap_map\n",
    "\n",
    "def run_missing_terms_pipeline():\n",
    "    \"\"\"Pipeline to process missing medical terms using existing functions.\"\"\"\n",
    "    \n",
    "    print(\"Processing Missing Medical Terms...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Backup sam_coord.csv\n",
    "    if os.path.exists(SAM_COORD_FILE):\n",
    "        shutil.copy2(SAM_COORD_FILE, BACKUP_SAM_COORD)\n",
    "        print(f\"Backup created: {BACKUP_SAM_COORD}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    concepts_df, cap_map = prepare_missing_terms_data()\n",
    "    print(f\"Processing {len(concepts_df)} images with missing terms\")\n",
    "    \n",
    "    # Use existing pipeline\n",
    "    all_csv_rows = []\n",
    "    all_json_objs = []\n",
    "    \n",
    "    for idx, row in concepts_df.iterrows():\n",
    "        image_id = str(row[\"ID\"])\n",
    "        terms_raw = [c.strip() for c in str(row[\"CUIs\"]).split(';') if c.strip()]\n",
    "        caption = cap_map.get(image_id, \"\")\n",
    "        \n",
    "        # Reuse existing functions\n",
    "        image_path = get_image_path(image_id)\n",
    "        if image_path is None:\n",
    "            continue\n",
    "        \n",
    "        terms = group_compound_terms(terms_raw)\n",
    "        if not terms:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n[{image_id}] Processing {len(terms)} missing terms: {terms}\")\n",
    "        \n",
    "        # GPT-4 Vision\n",
    "        vision_results = call_gpt4v_vision(image_path, terms, caption)\n",
    "        if not vision_results:\n",
    "            continue\n",
    "        \n",
    "        # Refiner\n",
    "        csv_out, json_out = call_gpt4_1_refiner(vision_results, terms, caption, image_id)\n",
    "        \n",
    "        # Process outputs (same format as previous adapter)\n",
    "        if csv_out:\n",
    "            if not all_csv_rows and \"ImageID\" in csv_out:\n",
    "                header, *rest = csv_out.splitlines()\n",
    "                all_csv_rows.append(header)\n",
    "                all_csv_rows.extend(rest)\n",
    "            else:\n",
    "                lines = [line for line in csv_out.splitlines() if not line.lower().startswith(\"imageid\")]\n",
    "                all_csv_rows.extend(lines)\n",
    "        \n",
    "        if json_out and json_out != \"[]\":\n",
    "            try:\n",
    "                data = json.loads(json_out)\n",
    "                if isinstance(data, list):\n",
    "                    all_json_objs.extend(data)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        time.sleep(2.5)  # Rate limiting\n",
    "    \n",
    "    # Save missing_terms_coord.csv\n",
    "    with open(MISSING_COORD_OUTPUT, \"w\") as f:\n",
    "        for row in all_csv_rows:\n",
    "            f.write(row + \"\\n\")\n",
    "    \n",
    "    # Update sam_coord.csv (merge)\n",
    "    if os.path.exists(SAM_COORD_FILE):\n",
    "        with open(SAM_COORD_FILE, 'r') as f:\n",
    "            original_lines = f.readlines()\n",
    "        original_count = len(original_lines) - 1\n",
    "    else:\n",
    "        original_lines = [\"ImageID,Label,x,y,width,height\\n\"]\n",
    "        original_count = 0\n",
    "    \n",
    "    # Write final merged file\n",
    "    with open(SAM_COORD_FILE, 'w') as f:\n",
    "        for line in original_lines:\n",
    "            f.write(line)\n",
    "        for row in all_csv_rows:\n",
    "            if row and not row.lower().startswith(\"imageid\"):\n",
    "                f.write(row + \"\\n\")\n",
    "    \n",
    "    new_count = len([r for r in all_csv_rows if r and not r.lower().startswith(\"imageid\")])\n",
    "    total_count = original_count + new_count\n",
    "    \n",
    "    print(f\"\\nCompleted!\")\n",
    "    print(f\"Missing terms coordinates: {new_count} → {MISSING_COORD_OUTPUT}\")\n",
    "    print(f\"Updated sam_coord.csv: {total_count} total records\")\n",
    "    print(f\"Original backup: {BACKUP_SAM_COORD}\")\n",
    "    \n",
    "    return all_csv_rows, total_count\n",
    "\n",
    "# Complete function that includes find_missing_medical_terms\n",
    "def run_complete_workflow():\n",
    "    \"\"\"Execute everything: find missing terms + process with GPT-4.\"\"\"\n",
    "    \n",
    "    # Step 1: Find missing terms\n",
    "    print(\"Step 1: Finding missing medical terms...\")\n",
    "    missing_df = find_missing_medical_terms('3_submission_explainability.csv', 'sam_coord.csv', 'missing_terms.csv')\n",
    "    \n",
    "    if missing_df is None or missing_df.empty:\n",
    "        print(\"No missing terms found.\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Found {len(missing_df)} missing terms\")\n",
    "    \n",
    "    # Step 2: Process with GPT-4\n",
    "    print(\"\\nStep 2: Processing with GPT-4 Vision...\")\n",
    "    return run_missing_terms_pipeline()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Missing Medical Terms Pipeline\")\n",
    "    print(\"Required functions: get_image_path, group_compound_terms, call_gpt4v_vision, call_gpt4_1_refiner\")\n",
    "    print(\"Usage:\")\n",
    "    print(\"  csv_rows, total = run_complete_workflow()  # Complete pipeline\") \n",
    "    print(\"  csv_rows, total = run_missing_terms_pipeline()  # Process existing missing_terms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a650bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Missing Medical Terms...\n",
      "==================================================\n",
      "Backup created: ./sam_coord_backup.csv\n",
      "Processing 3 images with missing terms\n",
      "\n",
      "[ImageCLEFmedical_Caption_2025_test_1251] Processing 1 missing terms: ['mitral']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['mitral'], and caption: \"Transthoracic ultrasonography echocardiogram showing a large vegetation on the mitral valve involving the heart ventricle, with possible thrombus formation affecting the right ventricular structure.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"right\" always refer to the patient's left ...\n",
      "Image exists? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **Step-by-step Rationalization:**\n",
      "\n",
      "1. **Compound Terms**: Medical terms list: ['mitral']  \n",
      "   - \"mitral\" is not a complete anatomic structure; most likely referring to \"mitral valve\" (compound word). Use \"mitral valve\" as the preserved term.\n",
      "\n",
      "2. **Exclude Imaging Modality Terms**:  \n",
      "   - Exclude terms like \"ultrasound\", \"ultrasonography\", \"echocardiogram.\"\n",
      "   - Do not split terms (e.g. \"heart ventricle\" remains as is).\n",
      "\n",
      "3. **Analyze Detections**:  \n",
      "   - \"mitral valve\" (x=240, y=120, width=50, height=50)\n",
      "   - \"heart ventricle\" (x=200, y=160, width=70, height=70)\n",
      "   - \"right ventricular structure\" (uncertain, x=100, y=200, width=70, height=70)\n",
      "   - \"large vegetation\" (x=240, y=140, width=50, height=50)\n",
      "   - \"possible thrombus formation\" (uncertain, x=120, y=180, width=60, height=60)\n",
      "   - \"arrow\" (arrow_tip at x=230, y=135)\n",
      "\n",
      "4. **Candidate Terms to Output:**  \n",
      "   - \"mitral valve\" – present as a detection\n",
      "   - \"large vegetation\" – is a finding aligned with \"vegetation\" on the valve\n",
      "   - \"heart ventricle,\" \"right ventricular structure,\" and \"possible thrombus formation\" are relevant findings/structures.\n",
      "   - \"mitral\" as in the original list is only output as \"mitral valve\" (preserved entity).\n",
      "\n",
      "5. **Bounding boxes and Arrow tips:**  \n",
      "   - All relevant terms have bounding boxes except the term \"mitral\" (which should be \"mitral valve\"), but a detection for \"mitral valve\" exists and overlaps with arrow tip (x=230, y=135). Not necessary to infer additional box.\n",
      "   - No term is missing a bounding box (as per instruction, only include valid medical terms).\n",
      "\n",
      "6. **Final Terms to Output**:  \n",
      "   - \"mitral valve\"\n",
      "   - \"large vegetation\"\n",
      "   - \"heart ventricle\"\n",
      "   - \"right ventricular structure\"\n",
      "   - \"possible thrombus formation\"\n",
      "\n",
      "---\n",
      "\n",
      "### **CSV Output**\n",
      "\n",
      "```csv\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_1251,mitral valve,240,120,50,50\n",
      "ImageCLEFmedical_Caption_2025_test_1251,large vegetation,240,140,50,50\n",
      "ImageCLEFmedical_Caption_2025_test_1251,heart ventricle,200,160,70,70\n",
      "ImageCLEFmedical_Caption_2025_test_1251,right ventricular structure,100,200,70,70\n",
      "ImageCLEFmedical_Caption_2025_test_1251,possible thrombus formation,120,180,60,60\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **JSON Output**\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1251\",\n",
      "    \"Label\": \"mitral valve\",\n",
      "    \"x\": 240,\n",
      "    \"y\": 120,\n",
      "    \"width\": 50,\n",
      "    \"height\": 50\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1251\",\n",
      "    \"Label\": \"large vegetation\",\n",
      "    \"x\": 240,\n",
      "    \"y\": 140,\n",
      "    \"width\": 50,\n",
      "    \"height\": 50\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1251\",\n",
      "    \"Label\": \"heart ventricle\",\n",
      "    \"x\": 200,\n",
      "    \"y\": 160,\n",
      "    \"width\": 70,\n",
      "    \"height\": 70\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_1251\",\n",
      "    \"Label\": \"right ventricular structure\",\n",
      "    \"x\": 100,\n",
      "    \"y\": 200,\n",
      "    \"width\": 70,\n",
      "    \"height\": 70\n",
      "  },\n",
      "  { \n",
      "=== END REPLY ===\n",
      "\n",
      "[Language model] Could not parse JSON part.\n",
      "\n",
      "[ImageCLEFmedical_Caption_2025_test_15167] Processing 1 missing terms: ['spleen']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['spleen'], and caption: \"Positron-Emission Tomography/Computed Tomography (PET/CT) scan of the chest, abdomen, and pelvis showing multiple metastatic lesions in the liver (blue arrow), spleen (red arrow), and lymph nodes in the left axillary region (green arrow), inguinal region (yellow arrow), and media ...\n",
      "Image exists? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " **Step-by-step solution:**\n",
      "\n",
      "1. **Medical Terms to Retain (from list):** `['spleen']`  \n",
      "   - It's not split; keep as is.\n",
      "2. **Omit Modalities:** Already omitted (PET/CT, etc.) per instructions.\n",
      "3. **Bounding Box Validation:**  \n",
      "   - \"spleen\": **No bounding box given**, only arrow tip at (160, 210). Per instruction, create a default 40x40 px box centered at that point. So:\n",
      "     - x = 160 - 20 = 140\n",
      "     - y = 210 - 20 = 190\n",
      "     - width = 40\n",
      "     - height = 40\n",
      "\n",
      "---\n",
      "\n",
      "**CSV:**\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_15167,spleen,140,190,40,40\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**JSON:**\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_15167\",\n",
      "    \"Label\": \"spleen\",\n",
      "    \"x\": 140,\n",
      "    \"y\": 190,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "``` \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "[ImageCLEFmedical_Caption_2025_test_4346] Processing 2 missing terms: ['1.5 Cm Hypoechoic Mass', 'Hypoechoic Mass']\n",
      "Prompt:\n",
      " \n",
      "You are an expert radiologist. Analyze the provided medical image together with these terms: ['1.5 Cm Hypoechoic Mass', 'Hypoechoic Mass'], and caption: \"Ultrasonography of the right breast demonstrates a 1.5 cm hypoechoic mass (arrow) with cystic characteristics in the right breast, distinct from the normal ultrasonographic structure of the right testis.\".\n",
      "\n",
      "Important: In radiology, \"left\" and \"r ...\n",
      "Image exists? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPT-4.1 RAW REPLY ===\n",
      " CSV:\n",
      "```\n",
      "ImageID,Label,x,y,width,height\n",
      "ImageCLEFmedical_Caption_2025_test_4346,Hypoechoic Mass,180,60,40,40\n",
      "ImageCLEFmedical_Caption_2025_test_4346,Hypoechoic Mass,180,50,40,40\n",
      "```\n",
      "\n",
      "JSON:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_4346\",\n",
      "    \"Label\": \"Hypoechoic Mass\",\n",
      "    \"x\": 180,\n",
      "    \"y\": 60,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  },\n",
      "  {\n",
      "    \"ImageID\": \"ImageCLEFmedical_Caption_2025_test_4346\",\n",
      "    \"Label\": \"Hypoechoic Mass\",\n",
      "    \"x\": 180,\n",
      "    \"y\": 50,\n",
      "    \"width\": 40,\n",
      "    \"height\": 40\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "**Notes:**\n",
      "- Compound term \"Hypoechoic Mass\" is preserved as one entity (matches both terms in medical terms list: '1.5 Cm Hypoechoic Mass', 'Hypoechoic Mass').\n",
      "- General modality terms (e.g., \"ultrasound\") are not included.\n",
      "- The first detection had a valid bounding box.\n",
      "- The second had only an arrow_tip at (200,70). Default box (40x40) is centered at the arrow tip, so x = 200-20=180, y = 70-20=50.\n",
      "- Both are labeled \"Hypoechoic Mass\" because the more specific \"1.5 Cm Hypoechoic Mass\" is not uniquely localizable from detections, but the general finding is. \n",
      "=== END REPLY ===\n",
      "\n",
      "\n",
      "Completed!\n",
      "Missing terms coordinates: 19 → ./missing_terms_coord.csv\n",
      "Updated sam_coord.csv: 219 total records\n",
      "Original backup: ./sam_coord_backup.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline\n",
    "csv_rows, total_count = run_missing_terms_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed6f81",
   "metadata": {},
   "source": [
    "### SAM: Defining boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf44137",
   "metadata": {},
   "source": [
    "After applying generative AI, NER, and other NLP techniques, we finally have a file to feed SAM with the key medical terms and their approximate positions for refinement through computing vision techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c92feafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "SECTION I: INITIALIZING LIBRARIES, CONFIGURATION, AND CUDA\n",
      "----------------------------------------------------------------------\n",
      "✓ Scikit-image (skimage) available.\n",
      "✓ Ultralytics YOLO available.\n",
      "\n",
      "--- Loading Configuration ---\n",
      "✓ Output directory set to: ./result_explain-3/sam_deduplicated\n",
      "✓ Color palette loaded with 15 colors.\n",
      "✓ Warnings are suppressed (set to 'ignore').\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SECTION II: DEFINING CORE UTILITY FUNCTIONS\n",
      "----------------------------------------------------------------------\n",
      "✓ Core utility functions defined.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SECTION III: SETTING UP SEGMENT ANYTHING MODEL (SAM)\n",
      "----------------------------------------------------------------------\n",
      "✓ SAM setup function defined.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SECTION IV: DEFINING SAM MASKING LOGIC\n",
      "----------------------------------------------------------------------\n",
      "✓ SAM masking functions defined.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SECTION V: DEFINING KEYPOINT AND ARROW DETECTION LOGIC\n",
      "----------------------------------------------------------------------\n",
      "✓ Keypoint, Arrow Detection, and Advanced Mask Selection functions defined.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SECTION VI: DEFINING YOLO ENHANCEMENT LOGIC\n",
      "----------------------------------------------------------------------\n",
      "✓ YOLO Enhancement functions defined.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SECTION VII: DEFINING VISUALIZATION AND REPORTING UTILITIES\n",
      "----------------------------------------------------------------------\n",
      "✓ Visualization and Reporting utilities defined.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SECTION VIII: DEFINING MAIN PER-IMAGE ANALYSIS LOGIC\n",
      "----------------------------------------------------------------------\n",
      "✓ Main Per-Image Analysis function defined.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SECTION IX: DEFINING MAIN EXECUTION PIPELINE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SECTION X: TRIGGERING SCRIPT EXECUTION\n",
      "----------------------------------------------------------------------\n",
      "Starting the main execution block...\n",
      "======================================================================\n",
      " INITIATING FULL MEDICAL IMAGE ANALYSIS PIPELINE \n",
      "======================================================================\n",
      "\n",
      "--- Phase 1: Initial Setup ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "--- Initializing SAM ---\n",
      "Attempting to load SAM model on device: cuda\n",
      "✓ SAM model (vit_h) loaded and predictor initialized successfully on cuda!\n",
      "--- Loading CSV Data Files ---\n",
      "✓ SAM coordinates loaded: 83 records from ./sam_coord.csv\n",
      "✓ Explanations/Captions (for main vis) loaded: 16 records from ./3_submission_explainability.csv\n",
      "✓ Concepts loaded: 16 records from ./ref_mini_concepts_natural_.csv\n",
      "✓ Caption file (for table) loaded: 16 records from ./caption.csv\n",
      "✓ All available data files loaded.\n",
      "Found 16 unique image IDs to process.\n",
      "Recess time between images: 15 seconds.\n",
      "Output will be saved in: ./result_explain-3/sam_deduplicated\n",
      "\n",
      "--- Phase 2: Processing Images ---\n",
      "\n",
      "------------------------- PROCESSING IMAGE 1/16: ImageCLEFmedical_Caption_2025_test_118 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_118 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_118' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_118: 9\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_118: 9 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Air-fluid Level' (3 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Air-Fluid Level' from BBox: (160, 280, 40, 40)\n",
      "Attempting SAM for 'Air-Fluid Level' with original bbox: (160, 280, 40, 40)\n",
      "  Original bbox SAM: conf=0.799, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Air-Fluid Level' still potentially low (0.799). Trying keypoint strategies from bbox: (160, 280, 40, 40)\n",
      "    Trying SAM with 'fast_corners' (3 points) for 'Air-Fluid Level'\n",
      "      SAM with 'fast_corners': conf=0.996\n",
      "      Selected keypoint strategy 'fast_corners' for 'Air-Fluid Level' with new conf: 0.996\n",
      "  Keypoint strategy improved mask for 'Air-Fluid Level'.\n",
      "  Final best strategy for 'Air-Fluid Level': keypoints_fast_corners, Final best conf: 0.996\n",
      "  Generating useful heatmap for 'Air-Fluid Level' (Image: ImageCLEFmedical_Caption_2025_test_118, Conf: 1.00)\n",
      " Error generating 'useful heatmap analysis' for Air-Fluid Level on ImageCLEFmedical_Caption_2025_test_118: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Air-Fluid Level': Strategy='keypoints_fast_corners', Confidence=0.996\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_118/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_118_Air_Fluid_Level.png\n",
      "\n",
      "  Processing label group: 'Bone Structure Of Ilium' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Bone Structure Of Ilium' from BBox: (200, 450, 150, 100)\n",
      "Attempting SAM for 'Bone Structure Of Ilium' with original bbox: (200, 450, 150, 100)\n",
      " Bbox (200, 450, 150, 100) partially outside image bounds (512x512). Clamping not implemented here, might lead to errors.\n",
      "  Original bbox SAM: conf=0.859, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Bone Structure Of Ilium': original_bbox (bbox_success), Final best conf: 0.859\n",
      "  Generating useful heatmap for 'Bone Structure Of Ilium' (Image: ImageCLEFmedical_Caption_2025_test_118, Conf: 0.86)\n",
      " Error generating 'useful heatmap analysis' for Bone Structure Of Ilium on ImageCLEFmedical_Caption_2025_test_118: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Bone Structure Of Ilium': Strategy='original_bbox (bbox_success)', Confidence=0.859\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_118/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_118_Bone_Structure_Of_Ilium.png\n",
      "\n",
      "  Processing label group: 'Bone Structure Of Pubis' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Bone Structure Of Pubis' from BBox: (230, 580, 140, 60)\n",
      "Attempting SAM for 'Bone Structure Of Pubis' with original bbox: (230, 580, 140, 60)\n",
      " Bbox (230, 580, 140, 60) partially outside image bounds (512x512). Clamping not implemented here, might lead to errors.\n",
      "  Original bbox SAM: conf=0.681, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.681) for 'Bone Structure Of Pubis'. Trying arrow detection from bbox: (230, 580, 140, 60)\n",
      " Invalid ROI (230, 580, 140, 60) for arrow detection. Using original bbox as target.\n",
      "  Confidence for 'Bone Structure Of Pubis' still potentially low (0.681). Trying keypoint strategies from bbox: (230, 580, 140, 60)\n",
      " Invalid ROI (230, 580, 140, 60) for keypoint detection in image of shape (512, 512, 3). Skipping.\n",
      "  Final best strategy for 'Bone Structure Of Pubis': original_bbox (bbox_success), Final best conf: 0.681\n",
      "  Generating useful heatmap for 'Bone Structure Of Pubis' (Image: ImageCLEFmedical_Caption_2025_test_118, Conf: 0.68)\n",
      " Error generating 'useful heatmap analysis' for Bone Structure Of Pubis on ImageCLEFmedical_Caption_2025_test_118: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Bone Structure Of Pubis': Strategy='original_bbox (bbox_success)', Confidence=0.681\n",
      "\n",
      "  Processing label group: 'abdomen' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Abdomen' from BBox: (150, 100, 300, 350)\n",
      "Attempting SAM for 'Abdomen' with original bbox: (150, 100, 300, 350)\n",
      "  Original bbox SAM: conf=0.892, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Abdomen': original_bbox (bbox_success), Final best conf: 0.892\n",
      "  Generating useful heatmap for 'Abdomen' (Image: ImageCLEFmedical_Caption_2025_test_118, Conf: 0.89)\n",
      " Error generating 'useful heatmap analysis' for Abdomen on ImageCLEFmedical_Caption_2025_test_118: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Abdomen': Strategy='original_bbox (bbox_success)', Confidence=0.892\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_118/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_118_Abdomen.png\n",
      "\n",
      "  Processing label group: 'air-fluid levels' (2 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Air-Fluid Levels' from BBox: (230, 180, 40, 40)\n",
      "Attempting SAM for 'Air-Fluid Levels' with original bbox: (230, 180, 40, 40)\n",
      "  Original bbox SAM: conf=0.894, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Air-Fluid Levels': original_bbox (bbox_success), Final best conf: 0.894\n",
      "  Generating useful heatmap for 'Air-Fluid Levels' (Image: ImageCLEFmedical_Caption_2025_test_118, Conf: 0.89)\n",
      " Error generating 'useful heatmap analysis' for Air-Fluid Levels on ImageCLEFmedical_Caption_2025_test_118: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Air-Fluid Levels': Strategy='original_bbox (bbox_success)', Confidence=0.894\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_118/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_118_Air_Fluid_Levels.png\n",
      "\n",
      "  Processing label group: 'pelvis' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Pelvis' from BBox: (220, 500, 160, 120)\n",
      "Attempting SAM for 'Pelvis' with original bbox: (220, 500, 160, 120)\n",
      " Bbox (220, 500, 160, 120) partially outside image bounds (512x512). Clamping not implemented here, might lead to errors.\n",
      "  Original bbox SAM: conf=0.660, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.660) for 'Pelvis'. Trying arrow detection from bbox: (220, 500, 160, 120)\n",
      " Invalid ROI (220, 500, 160, 120) for arrow detection. Using original bbox as target.\n",
      "  Confidence for 'Pelvis' still potentially low (0.660). Trying keypoint strategies from bbox: (220, 500, 160, 120)\n",
      " Invalid ROI (220, 500, 160, 120) for keypoint detection in image of shape (512, 512, 3). Skipping.\n",
      "  Final best strategy for 'Pelvis': original_bbox (bbox_success), Final best conf: 0.660\n",
      "  Generating useful heatmap for 'Pelvis' (Image: ImageCLEFmedical_Caption_2025_test_118, Conf: 0.66)\n",
      " Error generating 'useful heatmap analysis' for Pelvis on ImageCLEFmedical_Caption_2025_test_118: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Pelvis': Strategy='original_bbox (bbox_success)', Confidence=0.660\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_118...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_118_main_analysis_20250523_081152.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_118 ---\n",
      "Data Source                 \\\n",
      "          Medical Concepts   \n",
      "      Image Caption (File)   \n",
      "Medical Explanation/Report   \n",
      "\n",
      "Content Summary                                                                                 \\\n",
      "Plain x-ray;Abdomen;Anterior-\n",
      "Posterior;Pelvis;Bone structure of\n",
      "ilium;Bone structure of pubis   \n",
      "                                                  Plain abdominal radiograph showing the\n",
      "[...]   \n",
      "                                               Plain radiograph of the abdomen, taken\n",
      "in [...]   \n",
      "\n",
      "Details                                                                                                                                                                                                                      \n",
      "                                                                                                                        CUIs: Plain x-ray;Abdomen;Anterior-Posterior;Pelvis;Bone\n",
      "structure of ilium;Bone structure of pubis  \n",
      "                                                                                                                                              Plain abdominal radiograph showing the presence of multiple\n",
      "air-fluid levels.  \n",
      "Plain radiograph of the abdomen, taken in the anterior-\n",
      "posterior projection, shows multiple air-fluid levels within\n",
      "the bowel loops, extending into the pelvis. The bone\n",
      "structure of the ilium and pubis is unremarkable.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_118 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_118 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 2/16: ImageCLEFmedical_Caption_2025_test_1251 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_1251 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_1251' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_1251: 9\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "✓ YOLO detection complete. Found 1 new, non-overlapping objects.\n",
      "✓ Added 1 new detections from YOLO to ImageID ImageCLEFmedical_Caption_2025_test_1251.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_1251: 10 (1 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Heart Ventricle' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Heart Ventricle' from BBox: (180, 200, 100, 100)\n",
      "Attempting SAM for 'Heart Ventricle' with original bbox: (180, 200, 100, 100)\n",
      "  Original bbox SAM: conf=0.969, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Heart Ventricle': original_bbox (bbox_success), Final best conf: 0.969\n",
      "  Generating useful heatmap for 'Heart Ventricle' (Image: ImageCLEFmedical_Caption_2025_test_1251, Conf: 0.97)\n",
      " Error generating 'useful heatmap analysis' for Heart Ventricle on ImageCLEFmedical_Caption_2025_test_1251: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Heart Ventricle': Strategy='original_bbox (bbox_success)', Confidence=0.969\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1251/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1251_Heart_Ventricle.png\n",
      "\n",
      "  Processing label group: 'Right Ventricle' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Right Ventricle' from BBox: (230, 250, 50, 50)\n",
      "Attempting SAM for 'Right Ventricle' with original bbox: (230, 250, 50, 50)\n",
      "  Original bbox SAM: conf=0.730, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.730) for 'Right Ventricle'. Trying arrow detection from bbox: (230, 250, 50, 50)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (230, 250, 50, 50), Target bbox: (284, 303, 25, 25), Conf: 0.66\n",
      "  Arrow found for 'Right Ventricle', method: line_detection_heuristic. New target bbox: (284, 303, 25, 25)\n",
      "    SAM on arrow target: conf=0.668 (adjusted: 0.756)\n",
      "    Selected arrow strategy for 'Right Ventricle' with new conf: 0.756\n",
      "  Confidence for 'Right Ventricle' still potentially low (0.756). Trying keypoint strategies from bbox: (230, 250, 50, 50)\n",
      "    Trying SAM with 'sift_points' (9 points) for 'Right Ventricle'\n",
      "      SAM with 'sift_points': conf=0.925\n",
      "      Selected keypoint strategy 'sift_points' for 'Right Ventricle' with new conf: 0.925\n",
      "    Trying SAM with 'log_blobs' (3 points) for 'Right Ventricle'\n",
      "      SAM with 'log_blobs': conf=0.985\n",
      "      Selected keypoint strategy 'log_blobs' for 'Right Ventricle' with new conf: 0.985\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Right Ventricle'\n",
      "      SAM with 'fast_corners': conf=0.934\n",
      "  Keypoint strategy improved mask for 'Right Ventricle'.\n",
      "  Final best strategy for 'Right Ventricle': keypoints_log_blobs, Final best conf: 0.985\n",
      "  Generating useful heatmap for 'Right Ventricle' (Image: ImageCLEFmedical_Caption_2025_test_1251, Conf: 0.98)\n",
      " Error generating 'useful heatmap analysis' for Right Ventricle on ImageCLEFmedical_Caption_2025_test_1251: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Ventricle': Strategy='keypoints_log_blobs', Confidence=0.985\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1251/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1251_Right_Ventricle.png\n",
      "\n",
      "  Processing label group: 'Right Ventricular Structure' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Right Ventricular Structure' from BBox: (230, 250, 50, 50)\n",
      "Attempting SAM for 'Right Ventricular Structure' with original bbox: (230, 250, 50, 50)\n",
      "  Original bbox SAM: conf=0.730, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.730) for 'Right Ventricular Structure'. Trying arrow detection from bbox: (230, 250, 50, 50)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (230, 250, 50, 50), Target bbox: (284, 303, 25, 25), Conf: 0.66\n",
      "  Arrow found for 'Right Ventricular Structure', method: line_detection_heuristic. New target bbox: (284, 303, 25, 25)\n",
      "    SAM on arrow target: conf=0.668 (adjusted: 0.756)\n",
      "    Selected arrow strategy for 'Right Ventricular Structure' with new conf: 0.756\n",
      "  Confidence for 'Right Ventricular Structure' still potentially low (0.756). Trying keypoint strategies from bbox: (230, 250, 50, 50)\n",
      "    Trying SAM with 'sift_points' (9 points) for 'Right Ventricular Structure'\n",
      "      SAM with 'sift_points': conf=0.925\n",
      "      Selected keypoint strategy 'sift_points' for 'Right Ventricular Structure' with new conf: 0.925\n",
      "    Trying SAM with 'log_blobs' (3 points) for 'Right Ventricular Structure'\n",
      "      SAM with 'log_blobs': conf=0.985\n",
      "      Selected keypoint strategy 'log_blobs' for 'Right Ventricular Structure' with new conf: 0.985\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Right Ventricular Structure'\n",
      "      SAM with 'fast_corners': conf=0.934\n",
      "  Keypoint strategy improved mask for 'Right Ventricular Structure'.\n",
      "  Final best strategy for 'Right Ventricular Structure': keypoints_log_blobs, Final best conf: 0.985\n",
      "  Generating useful heatmap for 'Right Ventricular Structure' (Image: ImageCLEFmedical_Caption_2025_test_1251, Conf: 0.98)\n",
      " Error generating 'useful heatmap analysis' for Right Ventricular Structure on ImageCLEFmedical_Caption_2025_test_1251: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Ventricular Structure': Strategy='keypoints_log_blobs', Confidence=0.985\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1251/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1251_Right_Ventricular_Structure.png\n",
      "\n",
      "  Processing label group: 'YOLO_dog' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Yolo_Dog' from BBox: (5, 10, 493, 497)\n",
      "Attempting SAM for 'Yolo_Dog' with original bbox: (5, 10, 493, 497)\n",
      "  Original bbox SAM: conf=0.997, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Yolo_Dog': original_bbox (bbox_success), Final best conf: 0.997\n",
      "  Generating useful heatmap for 'Yolo_Dog' (Image: ImageCLEFmedical_Caption_2025_test_1251, Conf: 1.00)\n",
      " Error generating 'useful heatmap analysis' for Yolo_Dog on ImageCLEFmedical_Caption_2025_test_1251: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Yolo_Dog': Strategy='original_bbox (bbox_success)', Confidence=0.997\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1251/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1251_Yolo_Dog.png\n",
      "\n",
      "  Processing label group: 'heart ventricle' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Heart Ventricle' from BBox: (200, 160, 70, 70)\n",
      "Attempting SAM for 'Heart Ventricle' with original bbox: (200, 160, 70, 70)\n",
      "  Original bbox SAM: conf=0.861, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Heart Ventricle': original_bbox (bbox_success), Final best conf: 0.861\n",
      "  Generating useful heatmap for 'Heart Ventricle' (Image: ImageCLEFmedical_Caption_2025_test_1251, Conf: 0.86)\n",
      " Error generating 'useful heatmap analysis' for Heart Ventricle on ImageCLEFmedical_Caption_2025_test_1251: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Heart Ventricle': Strategy='original_bbox (bbox_success)', Confidence=0.861\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1251/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1251_Heart_Ventricle.png\n",
      "\n",
      "  Processing label group: 'large vegetation' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Large Vegetation' from BBox: (240, 140, 50, 50)\n",
      "Attempting SAM for 'Large Vegetation' with original bbox: (240, 140, 50, 50)\n",
      "  Original bbox SAM: conf=0.873, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Large Vegetation': original_bbox (bbox_success), Final best conf: 0.873\n",
      "  Generating useful heatmap for 'Large Vegetation' (Image: ImageCLEFmedical_Caption_2025_test_1251, Conf: 0.87)\n",
      " Error generating 'useful heatmap analysis' for Large Vegetation on ImageCLEFmedical_Caption_2025_test_1251: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Large Vegetation': Strategy='original_bbox (bbox_success)', Confidence=0.873\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1251/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1251_Large_Vegetation.png\n",
      "\n",
      "  Processing label group: 'mitral valve' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Mitral Valve' from BBox: (240, 120, 50, 50)\n",
      "Attempting SAM for 'Mitral Valve' with original bbox: (240, 120, 50, 50)\n",
      "  Original bbox SAM: conf=0.885, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Mitral Valve': original_bbox (bbox_success), Final best conf: 0.885\n",
      "  Generating useful heatmap for 'Mitral Valve' (Image: ImageCLEFmedical_Caption_2025_test_1251, Conf: 0.88)\n",
      " Error generating 'useful heatmap analysis' for Mitral Valve on ImageCLEFmedical_Caption_2025_test_1251: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Mitral Valve': Strategy='original_bbox (bbox_success)', Confidence=0.885\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1251/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1251_Mitral_Valve.png\n",
      "\n",
      "  Processing label group: 'possible thrombus formation' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Possible Thrombus Formation' from BBox: (120, 180, 60, 60)\n",
      "Attempting SAM for 'Possible Thrombus Formation' with original bbox: (120, 180, 60, 60)\n",
      "  Original bbox SAM: conf=0.767, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Possible Thrombus Formation' still potentially low (0.767). Trying keypoint strategies from bbox: (120, 180, 60, 60)\n",
      "    Trying SAM with 'sift_points' (9 points) for 'Possible Thrombus Formation'\n",
      "      SAM with 'sift_points': conf=0.899\n",
      "      Selected keypoint strategy 'sift_points' for 'Possible Thrombus Formation' with new conf: 0.899\n",
      "    Trying SAM with 'log_blobs' (3 points) for 'Possible Thrombus Formation'\n",
      "      SAM with 'log_blobs': conf=0.988\n",
      "      Selected keypoint strategy 'log_blobs' for 'Possible Thrombus Formation' with new conf: 0.988\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Possible Thrombus Formation'\n",
      "      SAM with 'fast_corners': conf=0.938\n",
      "  Keypoint strategy improved mask for 'Possible Thrombus Formation'.\n",
      "  Final best strategy for 'Possible Thrombus Formation': keypoints_log_blobs, Final best conf: 0.988\n",
      "  Generating useful heatmap for 'Possible Thrombus Formation' (Image: ImageCLEFmedical_Caption_2025_test_1251, Conf: 0.99)\n",
      " Error generating 'useful heatmap analysis' for Possible Thrombus Formation on ImageCLEFmedical_Caption_2025_test_1251: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Possible Thrombus Formation': Strategy='keypoints_log_blobs', Confidence=0.988\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1251/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1251_Possible_Thrombus_Formation.png\n",
      "\n",
      "  Processing label group: 'right ventricular structure' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Right Ventricular Structure' from BBox: (100, 200, 70, 70)\n",
      "Attempting SAM for 'Right Ventricular Structure' with original bbox: (100, 200, 70, 70)\n",
      "  Original bbox SAM: conf=0.756, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Right Ventricular Structure' still potentially low (0.756). Trying keypoint strategies from bbox: (100, 200, 70, 70)\n",
      "    Trying SAM with 'sift_points' (10 points) for 'Right Ventricular Structure'\n",
      "      SAM with 'sift_points': conf=0.903\n",
      "      Selected keypoint strategy 'sift_points' for 'Right Ventricular Structure' with new conf: 0.903\n",
      "    Trying SAM with 'log_blobs' (3 points) for 'Right Ventricular Structure'\n",
      "      SAM with 'log_blobs': conf=0.988\n",
      "      Selected keypoint strategy 'log_blobs' for 'Right Ventricular Structure' with new conf: 0.988\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Right Ventricular Structure'\n",
      "      SAM with 'fast_corners': conf=0.907\n",
      "  Keypoint strategy improved mask for 'Right Ventricular Structure'.\n",
      "  Final best strategy for 'Right Ventricular Structure': keypoints_log_blobs, Final best conf: 0.988\n",
      "  Generating useful heatmap for 'Right Ventricular Structure' (Image: ImageCLEFmedical_Caption_2025_test_1251, Conf: 0.99)\n",
      " Error generating 'useful heatmap analysis' for Right Ventricular Structure on ImageCLEFmedical_Caption_2025_test_1251: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Ventricular Structure': Strategy='keypoints_log_blobs', Confidence=0.988\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1251/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1251_Right_Ventricular_Structure.png\n",
      "\n",
      "  Processing label group: 'thrombus' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Thrombus' from BBox: (180, 220, 60, 60)\n",
      "Attempting SAM for 'Thrombus' with original bbox: (180, 220, 60, 60)\n",
      "  Original bbox SAM: conf=0.974, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Thrombus': original_bbox (bbox_success), Final best conf: 0.974\n",
      "  Generating useful heatmap for 'Thrombus' (Image: ImageCLEFmedical_Caption_2025_test_1251, Conf: 0.97)\n",
      " Error generating 'useful heatmap analysis' for Thrombus on ImageCLEFmedical_Caption_2025_test_1251: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Thrombus': Strategy='original_bbox (bbox_success)', Confidence=0.974\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1251/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1251_Thrombus.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_1251...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_1251_main_analysis_20250523_081356.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_1251 ---\n",
      "Data Source                Content Summary                                                       \\\n",
      "          Medical Concepts Ultrasonography;Heart\n",
      "Ventricle;Thrombus;Right ventricular\n",
      "structure   \n",
      "      Image Caption (File)                   Transthoracic echocardiogram showing a\n",
      "large [...]   \n",
      "Medical Explanation/Report                   Transthoracic ultrasonography\n",
      "echocardiogram [...]   \n",
      "\n",
      "Details                                                                                                                                                                                                 \n",
      "                                                                                                                            CUIs: Ultrasonography;Heart Ventricle;Thrombus;Right\n",
      "ventricular structure  \n",
      "                                                                                                                          Transthoracic echocardiogram showing a large vegetation on\n",
      "the mitral valve.  \n",
      "Transthoracic ultrasonography echocardiogram showing a large\n",
      "vegetation on the mitral valve involving the heart\n",
      "ventricle, with possible thrombus formation affecting the\n",
      "right ventricular structure.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_1251 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_1251 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 3/16: ImageCLEFmedical_Caption_2025_test_1258 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_1258 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_1258' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_1258: 3\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_1258: 3 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'abdomen' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Abdomen' from BBox: (0, 0, 512, 600)\n",
      "Attempting SAM for 'Abdomen' with original bbox: (0, 0, 512, 600)\n",
      " Bbox (0, 0, 512, 600) partially outside image bounds (512x512). Clamping not implemented here, might lead to errors.\n",
      "  Original bbox SAM: conf=0.835, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Abdomen': original_bbox (bbox_success), Final best conf: 0.835\n",
      "  Generating useful heatmap for 'Abdomen' (Image: ImageCLEFmedical_Caption_2025_test_1258, Conf: 0.83)\n",
      " Error generating 'useful heatmap analysis' for Abdomen on ImageCLEFmedical_Caption_2025_test_1258: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Abdomen': Strategy='original_bbox (bbox_success)', Confidence=0.835\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1258/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1258_Abdomen.png\n",
      "\n",
      "  Processing label group: 'intestines' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Intestines' from BBox: (100, 150, 300, 450)\n",
      "Attempting SAM for 'Intestines' with original bbox: (100, 150, 300, 450)\n",
      " Bbox (100, 150, 300, 450) partially outside image bounds (512x512). Clamping not implemented here, might lead to errors.\n",
      "  Original bbox SAM: conf=0.902, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Intestines': original_bbox (bbox_success), Final best conf: 0.902\n",
      "  Generating useful heatmap for 'Intestines' (Image: ImageCLEFmedical_Caption_2025_test_1258, Conf: 0.90)\n",
      " Error generating 'useful heatmap analysis' for Intestines on ImageCLEFmedical_Caption_2025_test_1258: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Intestines': Strategy='original_bbox (bbox_success)', Confidence=0.902\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1258/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1258_Intestines.png\n",
      "\n",
      "  Processing label group: 'small intestine' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Small Intestine' from BBox: (100, 200, 300, 400)\n",
      "Attempting SAM for 'Small Intestine' with original bbox: (100, 200, 300, 400)\n",
      " Bbox (100, 200, 300, 400) partially outside image bounds (512x512). Clamping not implemented here, might lead to errors.\n",
      "  Original bbox SAM: conf=0.934, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Small Intestine': original_bbox (bbox_success), Final best conf: 0.934\n",
      "  Generating useful heatmap for 'Small Intestine' (Image: ImageCLEFmedical_Caption_2025_test_1258, Conf: 0.93)\n",
      " Error generating 'useful heatmap analysis' for Small Intestine on ImageCLEFmedical_Caption_2025_test_1258: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Small Intestine': Strategy='original_bbox (bbox_success)', Confidence=0.934\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1258/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1258_Small_Intestine.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_1258...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_1258_main_analysis_20250523_081429.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_1258 ---\n",
      "Data Source                Content Summary                                           \\\n",
      "          Medical Concepts Plain x-ray;Abdomen;Anterior-\n",
      "Posterior;Intestines;Small   \n",
      "      Image Caption (File)      Abdominal X-ray showing multiple air-\n",
      "fluid levels.   \n",
      "Medical Explanation/Report          Plain radiograph of the abdomen, taken\n",
      "in [...]   \n",
      "\n",
      "Details                                                                                                                                                                            \n",
      "                                                                                                                   CUIs: Plain x-ray;Abdomen;Anterior-\n",
      "Posterior;Intestines;Small  \n",
      "                                                                                                                               Abdominal X-ray showing multiple air-fluid levels.  \n",
      "Plain radiograph of the abdomen, taken in the Anterior-\n",
      "Posterior (AP) projection, shows multiple air-fluid levels\n",
      "within the Intestines, specifically in the Small bowel\n",
      "region.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_1258 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_1258 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 4/16: ImageCLEFmedical_Caption_2025_test_1260 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_1260 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_1260' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_1260: 7\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_1260: 7 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Cervix Uteri' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Cervix Uteri' from BBox: (160, 220, 50, 35)\n",
      "Attempting SAM for 'Cervix Uteri' with original bbox: (160, 220, 50, 35)\n",
      "  Original bbox SAM: conf=0.831, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Cervix Uteri': original_bbox (bbox_success), Final best conf: 0.831\n",
      "  Generating useful heatmap for 'Cervix Uteri' (Image: ImageCLEFmedical_Caption_2025_test_1260, Conf: 0.83)\n",
      " Error generating 'useful heatmap analysis' for Cervix Uteri on ImageCLEFmedical_Caption_2025_test_1260: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Cervix Uteri': Strategy='original_bbox (bbox_success)', Confidence=0.831\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1260/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1260_Cervix_Uteri.png\n",
      "\n",
      "  Processing label group: 'Free Fluid' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Free Fluid' from BBox: (243, 354, 40, 40)\n",
      "Attempting SAM for 'Free Fluid' with original bbox: (243, 354, 40, 40)\n",
      "  Original bbox SAM: conf=0.845, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Free Fluid': original_bbox (bbox_success), Final best conf: 0.845\n",
      "  Generating useful heatmap for 'Free Fluid' (Image: ImageCLEFmedical_Caption_2025_test_1260, Conf: 0.84)\n",
      " Error generating 'useful heatmap analysis' for Free Fluid on ImageCLEFmedical_Caption_2025_test_1260: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Free Fluid': Strategy='original_bbox (bbox_success)', Confidence=0.845\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1260/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1260_Free_Fluid.png\n",
      "\n",
      "  Processing label group: 'Large Mass' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Large Mass' from BBox: (207, 372, 40, 40)\n",
      "Attempting SAM for 'Large Mass' with original bbox: (207, 372, 40, 40)\n",
      "  Original bbox SAM: conf=0.810, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Large Mass': original_bbox (bbox_success), Final best conf: 0.810\n",
      "  Generating useful heatmap for 'Large Mass' (Image: ImageCLEFmedical_Caption_2025_test_1260, Conf: 0.81)\n",
      " Error generating 'useful heatmap analysis' for Large Mass on ImageCLEFmedical_Caption_2025_test_1260: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Large Mass': Strategy='original_bbox (bbox_success)', Confidence=0.810\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1260/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1260_Large_Mass.png\n",
      "\n",
      "  Processing label group: 'Uterine Cavity' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Uterine Cavity' from BBox: (130, 250, 30, 20)\n",
      "Attempting SAM for 'Uterine Cavity' with original bbox: (130, 250, 30, 20)\n",
      "  Original bbox SAM: conf=0.735, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.735) for 'Uterine Cavity'. Trying arrow detection from bbox: (130, 250, 30, 20)\n",
      "  Confidence for 'Uterine Cavity' still potentially low (0.735). Trying keypoint strategies from bbox: (130, 250, 30, 20)\n",
      "    Trying SAM with 'sift_points' (1 points) for 'Uterine Cavity'\n",
      "      SAM with 'sift_points': conf=0.900\n",
      "      Selected keypoint strategy 'sift_points' for 'Uterine Cavity' with new conf: 0.900\n",
      "    Trying SAM with 'log_blobs' (1 points) for 'Uterine Cavity'\n",
      "      SAM with 'log_blobs': conf=0.861\n",
      "    Trying SAM with 'fast_corners' (6 points) for 'Uterine Cavity'\n",
      "      SAM with 'fast_corners': conf=0.901\n",
      "      Selected keypoint strategy 'fast_corners' for 'Uterine Cavity' with new conf: 0.901\n",
      "  Keypoint strategy improved mask for 'Uterine Cavity'.\n",
      "  Final best strategy for 'Uterine Cavity': keypoints_fast_corners, Final best conf: 0.901\n",
      "  Generating useful heatmap for 'Uterine Cavity' (Image: ImageCLEFmedical_Caption_2025_test_1260, Conf: 0.90)\n",
      " Error generating 'useful heatmap analysis' for Uterine Cavity on ImageCLEFmedical_Caption_2025_test_1260: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Uterine Cavity': Strategy='keypoints_fast_corners', Confidence=0.901\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1260/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1260_Uterine_Cavity.png\n",
      "\n",
      "  Processing label group: 'blood' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Blood' from BBox: (274, 385, 40, 40)\n",
      "Attempting SAM for 'Blood' with original bbox: (274, 385, 40, 40)\n",
      "  Original bbox SAM: conf=0.951, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Blood': original_bbox (bbox_success), Final best conf: 0.951\n",
      "  Generating useful heatmap for 'Blood' (Image: ImageCLEFmedical_Caption_2025_test_1260, Conf: 0.95)\n",
      " Error generating 'useful heatmap analysis' for Blood on ImageCLEFmedical_Caption_2025_test_1260: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Blood': Strategy='original_bbox (bbox_success)', Confidence=0.951\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1260/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1260_Blood.png\n",
      "\n",
      "  Processing label group: 'pelvis' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Pelvis' from BBox: (100, 200, 150, 120)\n",
      "Attempting SAM for 'Pelvis' with original bbox: (100, 200, 150, 120)\n",
      "  Original bbox SAM: conf=0.791, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Pelvis' still potentially low (0.791). Trying keypoint strategies from bbox: (100, 200, 150, 120)\n",
      "    Trying SAM with 'sift_points' (10 points) for 'Pelvis'\n",
      "      SAM with 'sift_points': conf=0.882\n",
      "      Selected keypoint strategy 'sift_points' for 'Pelvis' with new conf: 0.882\n",
      "    Trying SAM with 'log_blobs' (5 points) for 'Pelvis'\n",
      "      SAM with 'log_blobs': conf=0.968\n",
      "      Selected keypoint strategy 'log_blobs' for 'Pelvis' with new conf: 0.968\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Pelvis'\n",
      "      SAM with 'fast_corners': conf=0.887\n",
      "    Trying SAM with 'horizontal_lines_midpoints' (1 points) for 'Pelvis'\n",
      "      SAM with 'horizontal_lines_midpoints': conf=0.854\n",
      "  Keypoint strategy improved mask for 'Pelvis'.\n",
      "  Final best strategy for 'Pelvis': keypoints_log_blobs, Final best conf: 0.968\n",
      "  Generating useful heatmap for 'Pelvis' (Image: ImageCLEFmedical_Caption_2025_test_1260, Conf: 0.97)\n",
      " Error generating 'useful heatmap analysis' for Pelvis on ImageCLEFmedical_Caption_2025_test_1260: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Pelvis': Strategy='keypoints_log_blobs', Confidence=0.968\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1260/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1260_Pelvis.png\n",
      "\n",
      "  Processing label group: 'uterus' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Uterus' from BBox: (140, 230, 70, 45)\n",
      "Attempting SAM for 'Uterus' with original bbox: (140, 230, 70, 45)\n",
      "  Original bbox SAM: conf=0.652, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.652) for 'Uterus'. Trying arrow detection from bbox: (140, 230, 70, 45)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (140, 230, 70, 45), Target bbox: (235, 204, 22, 22), Conf: 0.74\n",
      "  Arrow found for 'Uterus', method: line_detection_heuristic. New target bbox: (235, 204, 22, 22)\n",
      "    SAM on arrow target: conf=0.838 (adjusted: 0.962)\n",
      "    Selected arrow strategy for 'Uterus' with new conf: 0.962\n",
      "  Final best strategy for 'Uterus': arrow_followed_line_detection_heuristic_bbox_success, Final best conf: 0.962\n",
      "  Generating useful heatmap for 'Uterus' (Image: ImageCLEFmedical_Caption_2025_test_1260, Conf: 0.96)\n",
      " Error generating 'useful heatmap analysis' for Uterus on ImageCLEFmedical_Caption_2025_test_1260: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Uterus': Strategy='arrow_followed_line_detection_heuristic_bbox_success', Confidence=0.962\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1260/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1260_Uterus.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_1260...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_1260_main_analysis_20250523_081539.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_1260 ---\n",
      "Data Source                Content Summary                                                       \\\n",
      "          Medical Concepts Magnetic Resonance\n",
      "Imaging;Pelvis;Uterus;Cervix\n",
      "Uteri;Uterine cavity   \n",
      "      Image Caption (File)                         MRI of the pelvis showing a large mass\n",
      "[...]   \n",
      "Medical Explanation/Report                        Magnetic Resonance Imaging (MRI) of the\n",
      "[...]   \n",
      "\n",
      "Details                                                                                                                                                                                                                                                              \n",
      "                                                                                                                                                                                         CUIs: Magnetic Resonance Imaging;Pelvis;Uterus;Cervix\n",
      "Uteri;Uterine cavity  \n",
      "                                                                                                   MRI of the pelvis showing a large mass (green arrow) in the\n",
      "right adnexa with a small amount of free fluid (blue arrow)\n",
      "and a small amount of blood (red arrow).  \n",
      "Magnetic Resonance Imaging (MRI) of the pelvis demonstrates\n",
      "a large mass (green arrow) in the right adnexa involving the\n",
      "uterus and cervix uteri, with a small amount of free fluid\n",
      "(blue arrow) and a small amount of blood (red arrow) within\n",
      "the uterine cavity.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_1260 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_1260 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 5/16: ImageCLEFmedical_Caption_2025_test_15167 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_15167 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_15167' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_15167: 5\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "✓ YOLO detection complete. Found 1 new, non-overlapping objects.\n",
      "✓ Added 1 new detections from YOLO to ImageID ImageCLEFmedical_Caption_2025_test_15167.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_15167: 6 (1 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Inguinal Region' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Inguinal Region' from BBox: (160, 320, 40, 40)\n",
      "Attempting SAM for 'Inguinal Region' with original bbox: (160, 320, 40, 40)\n",
      "  Original bbox SAM: conf=0.783, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Inguinal Region' still potentially low (0.783). Trying keypoint strategies from bbox: (160, 320, 40, 40)\n",
      "    Trying SAM with 'sift_points' (3 points) for 'Inguinal Region'\n",
      "      SAM with 'sift_points': conf=0.976\n",
      "      Selected keypoint strategy 'sift_points' for 'Inguinal Region' with new conf: 0.976\n",
      "    Trying SAM with 'log_blobs' (3 points) for 'Inguinal Region'\n",
      "      SAM with 'log_blobs': conf=0.981\n",
      "      Selected keypoint strategy 'log_blobs' for 'Inguinal Region' with new conf: 0.981\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Inguinal Region'\n",
      "      SAM with 'fast_corners': conf=0.900\n",
      "  Keypoint strategy improved mask for 'Inguinal Region'.\n",
      "  Final best strategy for 'Inguinal Region': keypoints_log_blobs, Final best conf: 0.981\n",
      "  Generating useful heatmap for 'Inguinal Region' (Image: ImageCLEFmedical_Caption_2025_test_15167, Conf: 0.98)\n",
      " Error generating 'useful heatmap analysis' for Inguinal Region on ImageCLEFmedical_Caption_2025_test_15167: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Inguinal Region': Strategy='keypoints_log_blobs', Confidence=0.981\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_15167/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_15167_Inguinal_Region.png\n",
      "\n",
      "  Processing label group: 'Left Axillary Region' (1 initial bbox(es))\n",
      " Directional label correction: 'Left Axillary Region' -> 'Right Axillary Region' (bbox on image left, implies patient right)\n",
      "    Cleaned/Corrected Label: 'Right Axillary Region' from BBox: (120, 150, 40, 40)\n",
      "Attempting SAM for 'Right Axillary Region' with original bbox: (120, 150, 40, 40)\n",
      "  Original bbox SAM: conf=0.705, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.705) for 'Right Axillary Region'. Trying arrow detection from bbox: (120, 150, 40, 40)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (120, 150, 40, 40), Target bbox: (151, 115, 20, 20), Conf: 0.82\n",
      "  Arrow found for 'Right Axillary Region', method: line_detection_heuristic. New target bbox: (151, 115, 20, 20)\n",
      "    SAM on arrow target: conf=0.770 (adjusted: 0.896)\n",
      "    Selected arrow strategy for 'Right Axillary Region' with new conf: 0.896\n",
      "  Final best strategy for 'Right Axillary Region': arrow_followed_line_detection_heuristic_bbox_success, Final best conf: 0.896\n",
      "  Generating useful heatmap for 'Right Axillary Region' (Image: ImageCLEFmedical_Caption_2025_test_15167, Conf: 0.90)\n",
      " Error generating 'useful heatmap analysis' for Right Axillary Region on ImageCLEFmedical_Caption_2025_test_15167: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Axillary Region': Strategy='arrow_followed_line_detection_heuristic_bbox_success', Confidence=0.896\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_15167/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_15167_Right_Axillary_Region.png\n",
      "\n",
      "  Processing label group: 'Lymph Nodes' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Lymph Nodes' from BBox: (140, 180, 40, 40)\n",
      "Attempting SAM for 'Lymph Nodes' with original bbox: (140, 180, 40, 40)\n",
      "  Original bbox SAM: conf=0.682, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.682) for 'Lymph Nodes'. Trying arrow detection from bbox: (140, 180, 40, 40)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (140, 180, 40, 40), Target bbox: (190, 231, 20, 20), Conf: 0.96\n",
      "  Arrow found for 'Lymph Nodes', method: line_detection_heuristic. New target bbox: (190, 231, 20, 20)\n",
      "    SAM on arrow target: conf=0.875 (adjusted: 1.042)\n",
      "    Selected arrow strategy for 'Lymph Nodes' with new conf: 1.042\n",
      "  Final best strategy for 'Lymph Nodes': arrow_followed_line_detection_heuristic_bbox_success, Final best conf: 1.042\n",
      "  Generating useful heatmap for 'Lymph Nodes' (Image: ImageCLEFmedical_Caption_2025_test_15167, Conf: 1.04)\n",
      " Error generating 'useful heatmap analysis' for Lymph Nodes on ImageCLEFmedical_Caption_2025_test_15167: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Lymph Nodes': Strategy='arrow_followed_line_detection_heuristic_bbox_success', Confidence=1.042\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_15167/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_15167_Lymph_Nodes.png\n",
      "\n",
      "  Processing label group: 'Lymph Nodess' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Lymph Nodess' from BBox: (125, 80, 50, 30)\n",
      "Attempting SAM for 'Lymph Nodess' with original bbox: (125, 80, 50, 30)\n",
      "  Original bbox SAM: conf=0.884, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Lymph Nodess': original_bbox (bbox_success), Final best conf: 0.884\n",
      "  Generating useful heatmap for 'Lymph Nodess' (Image: ImageCLEFmedical_Caption_2025_test_15167, Conf: 0.88)\n",
      " Error generating 'useful heatmap analysis' for Lymph Nodess on ImageCLEFmedical_Caption_2025_test_15167: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Lymph Nodess': Strategy='original_bbox (bbox_success)', Confidence=0.884\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_15167/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_15167_Lymph_Nodess.png\n",
      "\n",
      "  Processing label group: 'YOLO_dog' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Yolo_Dog' from BBox: (306, 128, 96, 84)\n",
      "Attempting SAM for 'Yolo_Dog' with original bbox: (306, 128, 96, 84)\n",
      "  Original bbox SAM: conf=0.921, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Yolo_Dog': original_bbox (bbox_success), Final best conf: 0.921\n",
      "  Generating useful heatmap for 'Yolo_Dog' (Image: ImageCLEFmedical_Caption_2025_test_15167, Conf: 0.92)\n",
      " Error generating 'useful heatmap analysis' for Yolo_Dog on ImageCLEFmedical_Caption_2025_test_15167: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Yolo_Dog': Strategy='original_bbox (bbox_success)', Confidence=0.921\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_15167/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_15167_Yolo_Dog.png\n",
      "\n",
      "  Processing label group: 'spleen' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Spleen' from BBox: (140, 190, 40, 40)\n",
      "Attempting SAM for 'Spleen' with original bbox: (140, 190, 40, 40)\n",
      "  Original bbox SAM: conf=0.697, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.697) for 'Spleen'. Trying arrow detection from bbox: (140, 190, 40, 40)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (140, 190, 40, 40), Target bbox: (200, 180, 20, 20), Conf: 0.95\n",
      "  Arrow found for 'Spleen', method: line_detection_heuristic. New target bbox: (200, 180, 20, 20)\n",
      "    SAM on arrow target: conf=0.801 (adjusted: 0.953)\n",
      "    Selected arrow strategy for 'Spleen' with new conf: 0.953\n",
      "  Final best strategy for 'Spleen': arrow_followed_line_detection_heuristic_bbox_success, Final best conf: 0.953\n",
      "  Generating useful heatmap for 'Spleen' (Image: ImageCLEFmedical_Caption_2025_test_15167, Conf: 0.95)\n",
      " Error generating 'useful heatmap analysis' for Spleen on ImageCLEFmedical_Caption_2025_test_15167: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Spleen': Strategy='arrow_followed_line_detection_heuristic_bbox_success', Confidence=0.953\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_15167/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_15167_Spleen.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_15167...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_15167_main_analysis_20250523_081633.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_15167 ---\n",
      "Data Source                 \\\n",
      "          Medical Concepts   \n",
      "      Image Caption (File)   \n",
      "Medical Explanation/Report   \n",
      "\n",
      "Content Summary                                                                                               \\\n",
      "Positron-Emission Tomography;lymph\n",
      "nodes;Structure of left axillary\n",
      "region;lymph;Inguinal region;lymph nodes   \n",
      "                                                               PET/CT scan showing multiple metastatic\n",
      "[...]   \n",
      "                                                                 Positron-Emission Tomography/Computed\n",
      "[...]   \n",
      "\n",
      "Details                                                                                                                                                                                                                                                                                                                     \n",
      "                                                                                                                                                                                                        CUIs: Positron-Emission Tomography;lymph nodes;Structure of\n",
      "left axillary region;lymph;Inguinal region;lymph nodes  \n",
      "                                                                                                                                                                                             PET/CT scan showing multiple metastatic lesions in the liver\n",
      "(blue arrow), spleen (red arrow), and lymph nodes (green\n",
      "arrow).  \n",
      "Positron-Emission Tomography/Computed Tomography (PET/CT)\n",
      "scan of the chest, abdomen, and pelvis showing multiple\n",
      "metastatic lesions in the liver (blue arrow), spleen (red\n",
      "arrow), and lymph nodes in the left axillary region (green\n",
      "arrow), inguinal region (yellow arrow), and mediastinal\n",
      "lymph nodes (orange arrow).  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_15167 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_15167 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 6/16: ImageCLEFmedical_Caption_2025_test_1776 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_1776 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_1776' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_1776: 4\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_1776: 4 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Left Upper Lobe Of Lung' (1 initial bbox(es))\n",
      " Directional label correction: 'Left Upper Lobe Of Lung' -> 'Right Upper Lobe Of Lung' (bbox on image left, implies patient right)\n",
      "    Cleaned/Corrected Label: 'Right Upper Lobe Of Lung' from BBox: (50, 150, 100, 120)\n",
      "Attempting SAM for 'Right Upper Lobe Of Lung' with original bbox: (50, 150, 100, 120)\n",
      "  Original bbox SAM: conf=0.736, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.736) for 'Right Upper Lobe Of Lung'. Trying arrow detection from bbox: (50, 150, 100, 120)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (50, 150, 100, 120), Target bbox: (85, 291, 50, 50), Conf: 0.42\n",
      "  Arrow found for 'Right Upper Lobe Of Lung', method: line_detection_heuristic. New target bbox: (85, 291, 50, 50)\n",
      "    SAM on arrow target: conf=0.751 (adjusted: 0.814)\n",
      "    Selected arrow strategy for 'Right Upper Lobe Of Lung' with new conf: 0.814\n",
      "  Final best strategy for 'Right Upper Lobe Of Lung': arrow_followed_line_detection_heuristic_bbox_success, Final best conf: 0.814\n",
      "  Generating useful heatmap for 'Right Upper Lobe Of Lung' (Image: ImageCLEFmedical_Caption_2025_test_1776, Conf: 0.81)\n",
      " Error generating 'useful heatmap analysis' for Right Upper Lobe Of Lung on ImageCLEFmedical_Caption_2025_test_1776: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Upper Lobe Of Lung': Strategy='arrow_followed_line_detection_heuristic_bbox_success', Confidence=0.814\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1776/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1776_Right_Upper_Lobe_Of_Lung.png\n",
      "\n",
      "  Processing label group: 'Pleural Effusion' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Pleural Effusion' from BBox: (380, 150, 120, 200)\n",
      "Attempting SAM for 'Pleural Effusion' with original bbox: (380, 150, 120, 200)\n",
      "  Original bbox SAM: conf=0.907, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Pleural Effusion': original_bbox (bbox_success), Final best conf: 0.907\n",
      "  Generating useful heatmap for 'Pleural Effusion' (Image: ImageCLEFmedical_Caption_2025_test_1776, Conf: 0.91)\n",
      " Error generating 'useful heatmap analysis' for Pleural Effusion on ImageCLEFmedical_Caption_2025_test_1776: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Pleural Effusion': Strategy='original_bbox (bbox_success)', Confidence=0.907\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1776/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1776_Pleural_Effusion.png\n",
      "\n",
      "  Processing label group: 'Right Upper Lobe Of Lung' (1 initial bbox(es))\n",
      "Directional label correction: 'Right Upper Lobe Of Lung' -> 'Left Upper Lobe Of Lung' (bbox on image right, implies patient left)\n",
      "    Cleaned/Corrected Label: 'Left Upper Lobe Of Lung' from BBox: (250, 150, 100, 120)\n",
      "Attempting SAM for 'Left Upper Lobe Of Lung' with original bbox: (250, 150, 100, 120)\n",
      "  Original bbox SAM: conf=0.744, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.744) for 'Left Upper Lobe Of Lung'. Trying arrow detection from bbox: (250, 150, 100, 120)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (250, 150, 100, 120), Target bbox: (309, 248, 50, 50), Conf: 0.30\n",
      "  Arrow found for 'Left Upper Lobe Of Lung', method: line_detection_heuristic. New target bbox: (309, 248, 50, 50)\n",
      "    SAM on arrow target: conf=0.826 (adjusted: 0.876)\n",
      "    Selected arrow strategy for 'Left Upper Lobe Of Lung' with new conf: 0.876\n",
      "  Final best strategy for 'Left Upper Lobe Of Lung': arrow_followed_line_detection_heuristic_bbox_success, Final best conf: 0.876\n",
      "  Generating useful heatmap for 'Left Upper Lobe Of Lung' (Image: ImageCLEFmedical_Caption_2025_test_1776, Conf: 0.88)\n",
      " Error generating 'useful heatmap analysis' for Left Upper Lobe Of Lung on ImageCLEFmedical_Caption_2025_test_1776: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Left Upper Lobe Of Lung': Strategy='arrow_followed_line_detection_heuristic_bbox_success', Confidence=0.876\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1776/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1776_Left_Upper_Lobe_Of_Lung.png\n",
      "\n",
      "  Processing label group: 'chest' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Chest' from BBox: (50, 100, 350, 300)\n",
      "Attempting SAM for 'Chest' with original bbox: (50, 100, 350, 300)\n",
      "  Original bbox SAM: conf=0.978, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Chest': original_bbox (bbox_success), Final best conf: 0.978\n",
      "  Generating useful heatmap for 'Chest' (Image: ImageCLEFmedical_Caption_2025_test_1776, Conf: 0.98)\n",
      " Error generating 'useful heatmap analysis' for Chest on ImageCLEFmedical_Caption_2025_test_1776: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Chest': Strategy='original_bbox (bbox_success)', Confidence=0.978\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_1776/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_1776_Chest.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_1776...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_1776_main_analysis_20250523_081719.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_1776 ---\n",
      "Data Source                 \\\n",
      "          Medical Concepts   \n",
      "      Image Caption (File)   \n",
      "Medical Explanation/Report   \n",
      "\n",
      "Content Summary                                                                                             \\\n",
      "X-Ray Computed\n",
      "Tomography;Chest;Structure of right\n",
      "upper lobe of lung;Structure of left\n",
      "upper lobe of lung   \n",
      "                                                         CT scan of the chest showing a large\n",
      "right- [...]   \n",
      "                                                              X-Ray Computed Tomography of the chest\n",
      "[...]   \n",
      "\n",
      "Details                                                                                                                                                                                                                           \n",
      "                                                                                                                CUIs: X-Ray Computed Tomography;Chest;Structure of right\n",
      "upper lobe of lung;Structure of left upper lobe of lung  \n",
      "                                                                                                                                                              CT scan of the chest showing a large right-sided pleural\n",
      "effusion.  \n",
      "X-Ray Computed Tomography of the chest demonstrates a large\n",
      "right-sided pleural effusion involving the structure of the\n",
      "right upper lobe of the lung, with relative sparing of the\n",
      "structure of the left upper lobe of the lung.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_1776 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_1776 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 7/16: ImageCLEFmedical_Caption_2025_test_19226 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_19226 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_19226' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_19226: 5\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_19226: 5 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Entire Eye' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Eye' from BBox: (10, 50, 380, 170)\n",
      "Attempting SAM for 'Eye' with original bbox: (10, 50, 380, 170)\n",
      "  Original bbox SAM: conf=0.896, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Eye': original_bbox (bbox_success), Final best conf: 0.896\n",
      "  Generating useful heatmap for 'Eye' (Image: ImageCLEFmedical_Caption_2025_test_19226, Conf: 0.90)\n",
      " Error generating 'useful heatmap analysis' for Eye on ImageCLEFmedical_Caption_2025_test_19226: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Eye': Strategy='original_bbox (bbox_success)', Confidence=0.896\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_19226/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_19226_Eye.png\n",
      "\n",
      "  Processing label group: 'Optic Nerve' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Optic Nerve' from BBox: (40, 220, 60, 40)\n",
      "Attempting SAM for 'Optic Nerve' with original bbox: (40, 220, 60, 40)\n",
      "  Original bbox SAM: conf=0.762, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Optic Nerve' still potentially low (0.762). Trying keypoint strategies from bbox: (40, 220, 60, 40)\n",
      "    Trying SAM with 'sift_points' (10 points) for 'Optic Nerve'\n",
      "      SAM with 'sift_points': conf=0.931\n",
      "      Selected keypoint strategy 'sift_points' for 'Optic Nerve' with new conf: 0.931\n",
      "    Trying SAM with 'log_blobs' (3 points) for 'Optic Nerve'\n",
      "      SAM with 'log_blobs': conf=0.992\n",
      "      Selected keypoint strategy 'log_blobs' for 'Optic Nerve' with new conf: 0.992\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Optic Nerve'\n",
      "      SAM with 'fast_corners': conf=0.951\n",
      "    Trying SAM with 'horizontal_lines_midpoints' (16 points) for 'Optic Nerve'\n",
      "      SAM with 'horizontal_lines_midpoints': conf=0.919\n",
      "  Keypoint strategy improved mask for 'Optic Nerve'.\n",
      "  Final best strategy for 'Optic Nerve': keypoints_log_blobs, Final best conf: 0.992\n",
      "  Generating useful heatmap for 'Optic Nerve' (Image: ImageCLEFmedical_Caption_2025_test_19226, Conf: 0.99)\n",
      " Error generating 'useful heatmap analysis' for Optic Nerve on ImageCLEFmedical_Caption_2025_test_19226: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Optic Nerve': Strategy='keypoints_log_blobs', Confidence=0.992\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_19226/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_19226_Optic_Nerve.png\n",
      "\n",
      "  Processing label group: 'choroidal effusion' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Choroidal Effusion' from BBox: (80, 40, 260, 160)\n",
      "Attempting SAM for 'Choroidal Effusion' with original bbox: (80, 40, 260, 160)\n",
      "  Original bbox SAM: conf=0.880, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Choroidal Effusion': original_bbox (bbox_success), Final best conf: 0.880\n",
      "  Generating useful heatmap for 'Choroidal Effusion' (Image: ImageCLEFmedical_Caption_2025_test_19226, Conf: 0.88)\n",
      " Error generating 'useful heatmap analysis' for Choroidal Effusion on ImageCLEFmedical_Caption_2025_test_19226: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Choroidal Effusion': Strategy='original_bbox (bbox_success)', Confidence=0.880\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_19226/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_19226_Choroidal_Effusion.png\n",
      "\n",
      "  Processing label group: 'effusion' (2 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Effusion' from BBox: (160, 90, 40, 40)\n",
      "Attempting SAM for 'Effusion' with original bbox: (160, 90, 40, 40)\n",
      "  Original bbox SAM: conf=0.742, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.742) for 'Effusion'. Trying arrow detection from bbox: (160, 90, 40, 40)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (160, 90, 40, 40), Target bbox: (227, 122, 20, 20), Conf: 0.95\n",
      "  Arrow found for 'Effusion', method: line_detection_heuristic. New target bbox: (227, 122, 20, 20)\n",
      "    SAM on arrow target: conf=0.785 (adjusted: 0.934)\n",
      "    Selected arrow strategy for 'Effusion' with new conf: 0.934\n",
      "  Final best strategy for 'Effusion': arrow_followed_line_detection_heuristic_bbox_success, Final best conf: 0.934\n",
      "  Generating useful heatmap for 'Effusion' (Image: ImageCLEFmedical_Caption_2025_test_19226, Conf: 0.93)\n",
      " Error generating 'useful heatmap analysis' for Effusion on ImageCLEFmedical_Caption_2025_test_19226: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Effusion': Strategy='arrow_followed_line_detection_heuristic_bbox_success', Confidence=0.934\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_19226/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_19226_Effusion.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_19226...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_19226_main_analysis_20250523_081809.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_19226 ---\n",
      "Data Source                Content Summary                                     \\\n",
      "          Medical Concepts             Ultrasonography;Optic Nerve;Entire eye   \n",
      "      Image Caption (File)       B-scan of the left eye showing a large\n",
      "[...]   \n",
      "Medical Explanation/Report Ultrasonography of the left eye\n",
      "demonstrates [...]   \n",
      "\n",
      "Details                                                                                                                                                                                               \n",
      "                                                                                                                                                        CUIs: Ultrasonography;Optic Nerve;Entire eye  \n",
      "                                                                                                                            B-scan of the left eye showing a large choroidal detachment\n",
      "(red arrows)  \n",
      "Ultrasonography of the left eye demonstrates a large\n",
      "choroidal detachment (red arrows) involving the entire eye,\n",
      "with the optic nerve head displaced inferiorly, consistent\n",
      "with choroidal effusion.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_19226 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_19226 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 8/16: ImageCLEFmedical_Caption_2025_test_19232 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_19232 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_19232' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_19232: 1\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_19232: 1 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Optic Nerve' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Optic Nerve' from BBox: (120, 80, 60, 30)\n",
      "Attempting SAM for 'Optic Nerve' with original bbox: (120, 80, 60, 30)\n",
      "  Original bbox SAM: conf=0.812, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Optic Nerve': original_bbox (bbox_success), Final best conf: 0.812\n",
      "  Generating useful heatmap for 'Optic Nerve' (Image: ImageCLEFmedical_Caption_2025_test_19232, Conf: 0.81)\n",
      " Error generating 'useful heatmap analysis' for Optic Nerve on ImageCLEFmedical_Caption_2025_test_19232: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Optic Nerve': Strategy='original_bbox (bbox_success)', Confidence=0.812\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_19232/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_19232_Optic_Nerve.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_19232...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_19232_main_analysis_20250523_081832.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_19232 ---\n",
      "Data Source                Content Summary                                    \\\n",
      "          Medical Concepts                       Ultrasonography;Optic Nerve   \n",
      "      Image Caption (File) Ultrasound image of the right eye\n",
      "showing a [...]   \n",
      "Medical Explanation/Report  Ultrasonography of the right eye reveals\n",
      "a [...]   \n",
      "\n",
      "Details                                                                                                                                                                              \n",
      "                                                                                                                                                  CUIs: Ultrasonography;Optic Nerve  \n",
      "                                                                                          Ultrasound image of the right eye showing a 3.9 mm thickened\n",
      "optic nerve sheath diameter.  \n",
      "Ultrasonography of the right eye reveals a 3.9 mm thickened\n",
      "optic nerve sheath diameter, suggestive of increased\n",
      "intracranial pressure or optic neuritis involving the Optic\n",
      "Nerve.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_19232 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_19232 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 9/16: ImageCLEFmedical_Caption_2025_test_283 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_283 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_283' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_283: 4\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_283: 4 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'cystic mass' (2 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Cystic Mass' from BBox: (150, 140, 50, 50)\n",
      "Attempting SAM for 'Cystic Mass' with original bbox: (150, 140, 50, 50)\n",
      "  Original bbox SAM: conf=0.789, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Cystic Mass' still potentially low (0.789). Trying keypoint strategies from bbox: (150, 140, 50, 50)\n",
      "    Trying SAM with 'sift_points' (7 points) for 'Cystic Mass'\n",
      "      SAM with 'sift_points': conf=0.966\n",
      "      Selected keypoint strategy 'sift_points' for 'Cystic Mass' with new conf: 0.966\n",
      "    Trying SAM with 'log_blobs' (3 points) for 'Cystic Mass'\n",
      "      SAM with 'log_blobs': conf=1.010\n",
      "      Selected keypoint strategy 'log_blobs' for 'Cystic Mass' with new conf: 1.010\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Cystic Mass'\n",
      "      SAM with 'fast_corners': conf=0.949\n",
      "  Keypoint strategy improved mask for 'Cystic Mass'.\n",
      "  Final best strategy for 'Cystic Mass': keypoints_log_blobs, Final best conf: 1.010\n",
      "  Generating useful heatmap for 'Cystic Mass' (Image: ImageCLEFmedical_Caption_2025_test_283, Conf: 1.01)\n",
      " Error generating 'useful heatmap analysis' for Cystic Mass on ImageCLEFmedical_Caption_2025_test_283: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Cystic Mass': Strategy='keypoints_log_blobs', Confidence=1.010\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_283/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_283_Cystic_Mass.png\n",
      "\n",
      "  Processing label group: 'liver' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Liver' from BBox: (120, 100, 200, 150)\n",
      "Attempting SAM for 'Liver' with original bbox: (120, 100, 200, 150)\n",
      "  Original bbox SAM: conf=0.811, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Liver': original_bbox (bbox_success), Final best conf: 0.811\n",
      "  Generating useful heatmap for 'Liver' (Image: ImageCLEFmedical_Caption_2025_test_283, Conf: 0.81)\n",
      " Error generating 'useful heatmap analysis' for Liver on ImageCLEFmedical_Caption_2025_test_283: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Liver': Strategy='original_bbox (bbox_success)', Confidence=0.811\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_283/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_283_Liver.png\n",
      "\n",
      "  Processing label group: 'liver segment VIII' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Liver Segment Viii' from BBox: (150, 140, 50, 50)\n",
      "Attempting SAM for 'Liver Segment Viii' with original bbox: (150, 140, 50, 50)\n",
      "  Original bbox SAM: conf=0.789, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Liver Segment Viii' still potentially low (0.789). Trying keypoint strategies from bbox: (150, 140, 50, 50)\n",
      "    Trying SAM with 'sift_points' (7 points) for 'Liver Segment Viii'\n",
      "      SAM with 'sift_points': conf=0.966\n",
      "      Selected keypoint strategy 'sift_points' for 'Liver Segment Viii' with new conf: 0.966\n",
      "    Trying SAM with 'log_blobs' (3 points) for 'Liver Segment Viii'\n",
      "      SAM with 'log_blobs': conf=1.010\n",
      "      Selected keypoint strategy 'log_blobs' for 'Liver Segment Viii' with new conf: 1.010\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Liver Segment Viii'\n",
      "      SAM with 'fast_corners': conf=0.949\n",
      "  Keypoint strategy improved mask for 'Liver Segment Viii'.\n",
      "  Final best strategy for 'Liver Segment Viii': keypoints_log_blobs, Final best conf: 1.010\n",
      "  Generating useful heatmap for 'Liver Segment Viii' (Image: ImageCLEFmedical_Caption_2025_test_283, Conf: 1.01)\n",
      " Error generating 'useful heatmap analysis' for Liver Segment Viii on ImageCLEFmedical_Caption_2025_test_283: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Liver Segment Viii': Strategy='keypoints_log_blobs', Confidence=1.010\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_283/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_283_Liver_Segment_Viii.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_283...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_283_main_analysis_20250523_081917.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_283 ---\n",
      "Data Source                Content Summary                                        \\\n",
      "          Medical Concepts Magnetic Resonance\n",
      "Imaging;Liver;Cystic;Liver segment   \n",
      "      Image Caption (File)     MRI of the abdomen showing a 2.5 cm mass\n",
      "in [...]   \n",
      "Medical Explanation/Report         Magnetic Resonance Imaging (MRI) of the\n",
      "[...]   \n",
      "\n",
      "Details                                                                                                                                                       \n",
      "                                                                                                 CUIs: Magnetic Resonance Imaging;Liver;Cystic;Liver segment  \n",
      "                                                                            MRI of the abdomen showing a 2.5 cm mass in the right lobe\n",
      "of the liver (arrow).  \n",
      "Magnetic Resonance Imaging (MRI) of the abdomen demonstrates\n",
      "a 2.5 cm cystic mass in the right lobe of the liver,\n",
      "specifically involving liver segment VIII.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_283 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_283 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 10/16: ImageCLEFmedical_Caption_2025_test_3298 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_3298 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_3298' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_3298: 5\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "✓ YOLO detection complete. Found 1 new, non-overlapping objects.\n",
      "✓ Added 1 new detections from YOLO to ImageID ImageCLEFmedical_Caption_2025_test_3298.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_3298: 6 (1 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Left Renal Artery' (1 initial bbox(es))\n",
      " Directional label correction: 'Left Renal Artery' -> 'Right Renal Artery' (bbox on image left, implies patient right)\n",
      "    Cleaned/Corrected Label: 'Right Renal Artery' from BBox: (180, 450, 80, 40)\n",
      "Attempting SAM for 'Right Renal Artery' with original bbox: (180, 450, 80, 40)\n",
      "  Original bbox SAM: conf=0.852, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Right Renal Artery': original_bbox (bbox_success), Final best conf: 0.852\n",
      "  Generating useful heatmap for 'Right Renal Artery' (Image: ImageCLEFmedical_Caption_2025_test_3298, Conf: 0.85)\n",
      " Error generating 'useful heatmap analysis' for Right Renal Artery on ImageCLEFmedical_Caption_2025_test_3298: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Renal Artery': Strategy='original_bbox (bbox_success)', Confidence=0.852\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_3298/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_3298_Right_Renal_Artery.png\n",
      "\n",
      "  Processing label group: 'YOLO_person' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Yolo_Person' from BBox: (304, 3, 160, 507)\n",
      "Attempting SAM for 'Yolo_Person' with original bbox: (304, 3, 160, 507)\n",
      "  Original bbox SAM: conf=0.978, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Yolo_Person': original_bbox (bbox_success), Final best conf: 0.978\n",
      "  Generating useful heatmap for 'Yolo_Person' (Image: ImageCLEFmedical_Caption_2025_test_3298, Conf: 0.98)\n",
      " Error generating 'useful heatmap analysis' for Yolo_Person on ImageCLEFmedical_Caption_2025_test_3298: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Yolo_Person': Strategy='original_bbox (bbox_success)', Confidence=0.978\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_3298/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_3298_Yolo_Person.png\n",
      "\n",
      "  Processing label group: 'device' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Device' from BBox: (250, 190, 60, 60)\n",
      "Attempting SAM for 'Device' with original bbox: (250, 190, 60, 60)\n",
      "  Original bbox SAM: conf=0.728, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.728) for 'Device'. Trying arrow detection from bbox: (250, 190, 60, 60)\n",
      "  Confidence for 'Device' still potentially low (0.728). Trying keypoint strategies from bbox: (250, 190, 60, 60)\n",
      "    Trying SAM with 'fast_corners' (1 points) for 'Device'\n",
      "      SAM with 'fast_corners': conf=0.918\n",
      "      Selected keypoint strategy 'fast_corners' for 'Device' with new conf: 0.918\n",
      "  Keypoint strategy improved mask for 'Device'.\n",
      "  Final best strategy for 'Device': keypoints_fast_corners, Final best conf: 0.918\n",
      "  Generating useful heatmap for 'Device' (Image: ImageCLEFmedical_Caption_2025_test_3298, Conf: 0.92)\n",
      " Error generating 'useful heatmap analysis' for Device on ImageCLEFmedical_Caption_2025_test_3298: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Device': Strategy='keypoints_fast_corners', Confidence=0.918\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_3298/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_3298_Device.png\n",
      "\n",
      "  Processing label group: 'left subclavian artery stenosis' (1 initial bbox(es))\n",
      " Directional label correction: 'Left Subclavian Artery Stenosis' -> 'Right Subclavian Artery Stenosis' (bbox on image left, implies patient right)\n",
      "    Cleaned/Corrected Label: 'Right Subclavian Artery Stenosis' from BBox: (150, 50, 60, 60)\n",
      "Attempting SAM for 'Right Subclavian Artery Stenosis' with original bbox: (150, 50, 60, 60)\n",
      "  Original bbox SAM: conf=0.728, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.728) for 'Right Subclavian Artery Stenosis'. Trying arrow detection from bbox: (150, 50, 60, 60)\n",
      "  Confidence for 'Right Subclavian Artery Stenosis' still potentially low (0.728). Trying keypoint strategies from bbox: (150, 50, 60, 60)\n",
      "  Final best strategy for 'Right Subclavian Artery Stenosis': original_bbox (bbox_success), Final best conf: 0.728\n",
      "  Generating useful heatmap for 'Right Subclavian Artery Stenosis' (Image: ImageCLEFmedical_Caption_2025_test_3298, Conf: 0.73)\n",
      " Error generating 'useful heatmap analysis' for Right Subclavian Artery Stenosis on ImageCLEFmedical_Caption_2025_test_3298: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Subclavian Artery Stenosis': Strategy='original_bbox (bbox_success)', Confidence=0.728\n",
      "\n",
      "  Processing label group: 'stenosis' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Stenosis' from BBox: (200, 40, 40, 40)\n",
      "Attempting SAM for 'Stenosis' with original bbox: (200, 40, 40, 40)\n",
      "  Original bbox SAM: conf=0.747, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.747) for 'Stenosis'. Trying arrow detection from bbox: (200, 40, 40, 40)\n",
      "  Confidence for 'Stenosis' still potentially low (0.747). Trying keypoint strategies from bbox: (200, 40, 40, 40)\n",
      "  Final best strategy for 'Stenosis': original_bbox (bbox_success), Final best conf: 0.747\n",
      "  Generating useful heatmap for 'Stenosis' (Image: ImageCLEFmedical_Caption_2025_test_3298, Conf: 0.75)\n",
      " Error generating 'useful heatmap analysis' for Stenosis on ImageCLEFmedical_Caption_2025_test_3298: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Stenosis': Strategy='original_bbox (bbox_success)', Confidence=0.747\n",
      "\n",
      "  Processing label group: 'stent' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Stent' from BBox: (250, 190, 60, 60)\n",
      "Attempting SAM for 'Stent' with original bbox: (250, 190, 60, 60)\n",
      "  Original bbox SAM: conf=0.728, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.728) for 'Stent'. Trying arrow detection from bbox: (250, 190, 60, 60)\n",
      "  Confidence for 'Stent' still potentially low (0.728). Trying keypoint strategies from bbox: (250, 190, 60, 60)\n",
      "    Trying SAM with 'fast_corners' (1 points) for 'Stent'\n",
      "      SAM with 'fast_corners': conf=0.918\n",
      "      Selected keypoint strategy 'fast_corners' for 'Stent' with new conf: 0.918\n",
      "  Keypoint strategy improved mask for 'Stent'.\n",
      "  Final best strategy for 'Stent': keypoints_fast_corners, Final best conf: 0.918\n",
      "  Generating useful heatmap for 'Stent' (Image: ImageCLEFmedical_Caption_2025_test_3298, Conf: 0.92)\n",
      " Error generating 'useful heatmap analysis' for Stent on ImageCLEFmedical_Caption_2025_test_3298: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Stent': Strategy='keypoints_fast_corners', Confidence=0.918\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_3298/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_3298_Stent.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_3298...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_3298_main_analysis_20250523_081959.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_3298 ---\n",
      "Data Source                Content Summary                                        \\\n",
      "          Medical Concepts angiogram;Structure of left renal\n",
      "artery;Stent;device   \n",
      "      Image Caption (File)       Angiography of the left subclavian\n",
      "artery [...]   \n",
      "Medical Explanation/Report       Computed Tomography angiogram of the\n",
      "left [...]   \n",
      "\n",
      "Details                                                                                                                                                                                                                                                                                                              \n",
      "                                                                                                                                                                                                                                                        CUIs: angiogram;Structure of left renal artery;Stent;device  \n",
      "                                                                                                                                                                                                        Angiography of the left subclavian artery showing a 90%\n",
      "stenosis of the left subclavian artery (red arrow).  \n",
      "Computed Tomography angiogram of the left subclavian artery\n",
      "showing a 90% stenosis of the left subclavian artery (red\n",
      "arrow), which is likely due to atherosclerotic disease and\n",
      "may be amenable to stenting with a bare-metal or drug-\n",
      "eluting stent device. The left renal artery structure\n",
      "appears unremarkable.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_3298 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_3298 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 11/16: ImageCLEFmedical_Caption_2025_test_3563 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_3563 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_3563' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_3563: 7\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_3563: 7 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Left Lower Lobe Of Lung' (1 initial bbox(es))\n",
      " Directional label correction: 'Left Lower Lobe Of Lung' -> 'Right Lower Lobe Of Lung' (bbox on image left, implies patient right)\n",
      "    Cleaned/Corrected Label: 'Right Lower Lobe Of Lung' from BBox: (50, 150, 100, 200)\n",
      "Attempting SAM for 'Right Lower Lobe Of Lung' with original bbox: (50, 150, 100, 200)\n",
      "  Original bbox SAM: conf=0.816, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Right Lower Lobe Of Lung': original_bbox (bbox_success), Final best conf: 0.816\n",
      "  Generating useful heatmap for 'Right Lower Lobe Of Lung' (Image: ImageCLEFmedical_Caption_2025_test_3563, Conf: 0.82)\n",
      " Error generating 'useful heatmap analysis' for Right Lower Lobe Of Lung on ImageCLEFmedical_Caption_2025_test_3563: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Lower Lobe Of Lung': Strategy='original_bbox (bbox_success)', Confidence=0.816\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_3563/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_3563_Right_Lower_Lobe_Of_Lung.png\n",
      "\n",
      "  Processing label group: 'Lower Lobe' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Lower Lobe' from BBox: (50, 150, 100, 200)\n",
      "Attempting SAM for 'Lower Lobe' with original bbox: (50, 150, 100, 200)\n",
      "  Original bbox SAM: conf=0.816, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Lower Lobe': original_bbox (bbox_success), Final best conf: 0.816\n",
      "  Generating useful heatmap for 'Lower Lobe' (Image: ImageCLEFmedical_Caption_2025_test_3563, Conf: 0.82)\n",
      " Error generating 'useful heatmap analysis' for Lower Lobe on ImageCLEFmedical_Caption_2025_test_3563: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Lower Lobe': Strategy='original_bbox (bbox_success)', Confidence=0.816\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_3563/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_3563_Lower_Lobe.png\n",
      "\n",
      "  Processing label group: 'Nodule' (5 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Nodule' from BBox: (40, 20, 40, 40)\n",
      "Attempting SAM for 'Nodule' with original bbox: (40, 20, 40, 40)\n",
      "  Original bbox SAM: conf=0.697, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.697) for 'Nodule'. Trying arrow detection from bbox: (40, 20, 40, 40)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (40, 20, 40, 40), Target bbox: (65, 0, 20, 20), Conf: 1.00\n",
      "  Arrow found for 'Nodule', method: line_detection_heuristic. New target bbox: (65, 0, 20, 20)\n",
      "    SAM on arrow target: conf=0.643 (adjusted: 0.771)\n",
      "    Selected arrow strategy for 'Nodule' with new conf: 0.771\n",
      "  Confidence for 'Nodule' still potentially low (0.771). Trying keypoint strategies from bbox: (40, 20, 40, 40)\n",
      "    Trying SAM with 'sift_points' (10 points) for 'Nodule'\n",
      "      SAM with 'sift_points': conf=0.913\n",
      "      Selected keypoint strategy 'sift_points' for 'Nodule' with new conf: 0.913\n",
      "    Trying SAM with 'log_blobs' (3 points) for 'Nodule'\n",
      "      SAM with 'log_blobs': conf=0.897\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Nodule'\n",
      "      SAM with 'fast_corners': conf=0.936\n",
      "      Selected keypoint strategy 'fast_corners' for 'Nodule' with new conf: 0.936\n",
      "  Keypoint strategy improved mask for 'Nodule'.\n",
      "  Final best strategy for 'Nodule': keypoints_fast_corners, Final best conf: 0.936\n",
      "  Generating useful heatmap for 'Nodule' (Image: ImageCLEFmedical_Caption_2025_test_3563, Conf: 0.94)\n",
      " Error generating 'useful heatmap analysis' for Nodule on ImageCLEFmedical_Caption_2025_test_3563: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Nodule': Strategy='keypoints_fast_corners', Confidence=0.936\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_3563/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_3563_Nodule.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_3563...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_3563_main_analysis_20250523_082037.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_3563 ---\n",
      "Data Source                Content Summary                                                              \\\n",
      "          Medical Concepts X-Ray Computed\n",
      "Tomography;Chest;Nodule;Structure of\n",
      "left lower lobe of lung   \n",
      "      Image Caption (File)                                Chest CT scan showing multiple nodules\n",
      "[...]   \n",
      "Medical Explanation/Report                                X-Ray Computed Tomography of the chest\n",
      "[...]   \n",
      "\n",
      "Details                                                                                                                                                            \n",
      "                                                                                CUIs: X-Ray Computed Tomography;Chest;Nodule;Structure of\n",
      "left lower lobe of lung  \n",
      "                                                                                                   Chest CT scan showing multiple nodules (arrows) in both\n",
      "lungs.  \n",
      "X-Ray Computed Tomography of the chest demonstrates multiple\n",
      "nodules (arrows) in both lungs, specifically involving the\n",
      "structure of the left lower lobe of lung.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_3563 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_3563 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 12/16: ImageCLEFmedical_Caption_2025_test_368 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_368 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_368' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_368: 6\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_368: 6 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Left Axillary Region' (1 initial bbox(es))\n",
      " Directional label correction: 'Left Axillary Region' -> 'Right Axillary Region' (bbox on image left, implies patient right)\n",
      "    Cleaned/Corrected Label: 'Right Axillary Region' from BBox: (130, 100, 40, 40)\n",
      "Attempting SAM for 'Right Axillary Region' with original bbox: (130, 100, 40, 40)\n",
      "  Original bbox SAM: conf=0.892, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Right Axillary Region': original_bbox (bbox_success), Final best conf: 0.892\n",
      "  Generating useful heatmap for 'Right Axillary Region' (Image: ImageCLEFmedical_Caption_2025_test_368, Conf: 0.89)\n",
      " Error generating 'useful heatmap analysis' for Right Axillary Region on ImageCLEFmedical_Caption_2025_test_368: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Axillary Region': Strategy='original_bbox (bbox_success)', Confidence=0.892\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_368/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_368_Right_Axillary_Region.png\n",
      "\n",
      "  Processing label group: 'Lymph Nodes' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Lymph Nodes' from BBox: (180, 100, 60, 60)\n",
      "Attempting SAM for 'Lymph Nodes' with original bbox: (180, 100, 60, 60)\n",
      "  Original bbox SAM: conf=0.763, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Lymph Nodes' still potentially low (0.763). Trying keypoint strategies from bbox: (180, 100, 60, 60)\n",
      "    Trying SAM with 'sift_points' (10 points) for 'Lymph Nodes'\n",
      "      SAM with 'sift_points': conf=0.783\n",
      "      Selected keypoint strategy 'sift_points' for 'Lymph Nodes' with new conf: 0.783\n",
      "    Trying SAM with 'log_blobs' (5 points) for 'Lymph Nodes'\n",
      "      SAM with 'log_blobs': conf=0.869\n",
      "      Selected keypoint strategy 'log_blobs' for 'Lymph Nodes' with new conf: 0.869\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Lymph Nodes'\n",
      "      SAM with 'fast_corners': conf=0.865\n",
      "    Trying SAM with 'horizontal_lines_midpoints' (2 points) for 'Lymph Nodes'\n",
      "      SAM with 'horizontal_lines_midpoints': conf=0.895\n",
      "      Selected keypoint strategy 'horizontal_lines_midpoints' for 'Lymph Nodes' with new conf: 0.895\n",
      "  Keypoint strategy improved mask for 'Lymph Nodes'.\n",
      "  Final best strategy for 'Lymph Nodes': keypoints_horizontal_lines_midpoints, Final best conf: 0.895\n",
      "  Generating useful heatmap for 'Lymph Nodes' (Image: ImageCLEFmedical_Caption_2025_test_368, Conf: 0.90)\n",
      " Error generating 'useful heatmap analysis' for Lymph Nodes on ImageCLEFmedical_Caption_2025_test_368: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Lymph Nodes': Strategy='keypoints_horizontal_lines_midpoints', Confidence=0.895\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_368/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_368_Lymph_Nodes.png\n",
      "\n",
      "  Processing label group: 'hypermetabolic mass' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Hypermetabolic Mass' from BBox: (240, 100, 80, 80)\n",
      "Attempting SAM for 'Hypermetabolic Mass' with original bbox: (240, 100, 80, 80)\n",
      "  Original bbox SAM: conf=0.757, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Hypermetabolic Mass' still potentially low (0.757). Trying keypoint strategies from bbox: (240, 100, 80, 80)\n",
      "    Trying SAM with 'sift_points' (10 points) for 'Hypermetabolic Mass'\n",
      "      SAM with 'sift_points': conf=0.921\n",
      "      Selected keypoint strategy 'sift_points' for 'Hypermetabolic Mass' with new conf: 0.921\n",
      "    Trying SAM with 'log_blobs' (5 points) for 'Hypermetabolic Mass'\n",
      "      SAM with 'log_blobs': conf=0.910\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Hypermetabolic Mass'\n",
      "      SAM with 'fast_corners': conf=0.924\n",
      "      Selected keypoint strategy 'fast_corners' for 'Hypermetabolic Mass' with new conf: 0.924\n",
      "    Trying SAM with 'horizontal_lines_midpoints' (2 points) for 'Hypermetabolic Mass'\n",
      "      SAM with 'horizontal_lines_midpoints': conf=0.862\n",
      "  Keypoint strategy improved mask for 'Hypermetabolic Mass'.\n",
      "  Final best strategy for 'Hypermetabolic Mass': keypoints_fast_corners, Final best conf: 0.924\n",
      "  Generating useful heatmap for 'Hypermetabolic Mass' (Image: ImageCLEFmedical_Caption_2025_test_368, Conf: 0.92)\n",
      " Error generating 'useful heatmap analysis' for Hypermetabolic Mass on ImageCLEFmedical_Caption_2025_test_368: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Hypermetabolic Mass': Strategy='keypoints_fast_corners', Confidence=0.924\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_368/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_368_Hypermetabolic_Mass.png\n",
      "\n",
      "  Processing label group: 'left axillary region' (1 initial bbox(es))\n",
      " Directional label correction: 'Left Axillary Region' -> 'Right Axillary Region' (bbox on image left, implies patient right)\n",
      "    Cleaned/Corrected Label: 'Right Axillary Region' from BBox: (210, 140, 40, 40)\n",
      "Attempting SAM for 'Right Axillary Region' with original bbox: (210, 140, 40, 40)\n",
      "  Original bbox SAM: conf=0.903, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Right Axillary Region': original_bbox (bbox_success), Final best conf: 0.903\n",
      "  Generating useful heatmap for 'Right Axillary Region' (Image: ImageCLEFmedical_Caption_2025_test_368, Conf: 0.90)\n",
      " Error generating 'useful heatmap analysis' for Right Axillary Region on ImageCLEFmedical_Caption_2025_test_368: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Axillary Region': Strategy='original_bbox (bbox_success)', Confidence=0.903\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_368/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_368_Right_Axillary_Region.png\n",
      "\n",
      "  Processing label group: 'left upper lobe' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Left Upper Lobe' from BBox: (250, 100, 40, 40)\n",
      "Attempting SAM for 'Left Upper Lobe' with original bbox: (250, 100, 40, 40)\n",
      "  Original bbox SAM: conf=0.906, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Left Upper Lobe': original_bbox (bbox_success), Final best conf: 0.906\n",
      "  Generating useful heatmap for 'Left Upper Lobe' (Image: ImageCLEFmedical_Caption_2025_test_368, Conf: 0.91)\n",
      " Error generating 'useful heatmap analysis' for Left Upper Lobe on ImageCLEFmedical_Caption_2025_test_368: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Left Upper Lobe': Strategy='original_bbox (bbox_success)', Confidence=0.906\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_368/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_368_Left_Upper_Lobe.png\n",
      "\n",
      "  Processing label group: 'lymphadenopathy' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Lymphadenopathy' from BBox: (200, 150, 60, 60)\n",
      "Attempting SAM for 'Lymphadenopathy' with original bbox: (200, 150, 60, 60)\n",
      "  Original bbox SAM: conf=0.893, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Lymphadenopathy': original_bbox (bbox_success), Final best conf: 0.893\n",
      "  Generating useful heatmap for 'Lymphadenopathy' (Image: ImageCLEFmedical_Caption_2025_test_368, Conf: 0.89)\n",
      " Error generating 'useful heatmap analysis' for Lymphadenopathy on ImageCLEFmedical_Caption_2025_test_368: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Lymphadenopathy': Strategy='original_bbox (bbox_success)', Confidence=0.893\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_368/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_368_Lymphadenopathy.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_368...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_368_main_analysis_20250523_082133.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_368 ---\n",
      "Data Source                Content Summary                                                             \\\n",
      "          Medical Concepts Positron-Emission Tomography;Structure\n",
      "of left axillary region;lymph nodes   \n",
      "      Image Caption (File)                         PET/CT scan showing a hypermetabolic\n",
      "mass in [...]   \n",
      "Medical Explanation/Report                                Positron-Emission Tomography/Computed\n",
      "[...]   \n",
      "\n",
      "Details                                                                                                                                                                                                                                                         \n",
      "                                                                                                                                                                              CUIs: Positron-Emission Tomography;Structure of left\n",
      "axillary region;lymph nodes  \n",
      "                                                                                                                                                                         PET/CT scan showing a hypermetabolic mass in the left upper\n",
      "lobe of the lung (arrow).  \n",
      "Positron-Emission Tomography/Computed Tomography (PET/CT)\n",
      "scan of the thorax reveals a hypermetabolic mass in the left\n",
      "upper lobe of the lung (arrow), with associated\n",
      "lymphadenopathy in the left axillary region, indicating\n",
      "involvement of the lymph nodes.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_368 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_368 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 13/16: ImageCLEFmedical_Caption_2025_test_3880 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_3880 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_3880' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_3880: 4\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_3880: 4 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Right Middle Cerebral Artery' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Right Middle Cerebral Artery' from BBox: (130, 105, 40, 20)\n",
      "Attempting SAM for 'Right Middle Cerebral Artery' with original bbox: (130, 105, 40, 20)\n",
      "  Original bbox SAM: conf=0.632, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.632) for 'Right Middle Cerebral Artery'. Trying arrow detection from bbox: (130, 105, 40, 20)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (130, 105, 40, 20), Target bbox: (163, 82, 20, 20), Conf: 0.40\n",
      "  Arrow found for 'Right Middle Cerebral Artery', method: line_detection_heuristic. New target bbox: (163, 82, 20, 20)\n",
      "    SAM on arrow target: conf=0.790 (adjusted: 0.854)\n",
      "    Selected arrow strategy for 'Right Middle Cerebral Artery' with new conf: 0.854\n",
      "  Final best strategy for 'Right Middle Cerebral Artery': arrow_followed_line_detection_heuristic_bbox_success, Final best conf: 0.854\n",
      "  Generating useful heatmap for 'Right Middle Cerebral Artery' (Image: ImageCLEFmedical_Caption_2025_test_3880, Conf: 0.85)\n",
      " Error generating 'useful heatmap analysis' for Right Middle Cerebral Artery on ImageCLEFmedical_Caption_2025_test_3880: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Middle Cerebral Artery': Strategy='arrow_followed_line_detection_heuristic_bbox_success', Confidence=0.854\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_3880/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_3880_Right_Middle_Cerebral_Artery.png\n",
      "\n",
      "  Processing label group: 'brain' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Brain' from BBox: (50, 50, 150, 150)\n",
      "Attempting SAM for 'Brain' with original bbox: (50, 50, 150, 150)\n",
      "  Original bbox SAM: conf=0.839, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Brain': original_bbox (bbox_success), Final best conf: 0.839\n",
      "  Generating useful heatmap for 'Brain' (Image: ImageCLEFmedical_Caption_2025_test_3880, Conf: 0.84)\n",
      " Error generating 'useful heatmap analysis' for Brain on ImageCLEFmedical_Caption_2025_test_3880: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Brain': Strategy='original_bbox (bbox_success)', Confidence=0.839\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_3880/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_3880_Brain.png\n",
      "\n",
      "  Processing label group: 'hematoma' (2 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Hematoma' from BBox: (140, 100, 60, 60)\n",
      "Attempting SAM for 'Hematoma' with original bbox: (140, 100, 60, 60)\n",
      "  Original bbox SAM: conf=0.637, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.637) for 'Hematoma'. Trying arrow detection from bbox: (140, 100, 60, 60)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (140, 100, 60, 60), Target bbox: (188, 46, 30, 30), Conf: 0.86\n",
      "  Arrow found for 'Hematoma', method: line_detection_heuristic. New target bbox: (188, 46, 30, 30)\n",
      "    SAM on arrow target: conf=0.698 (adjusted: 0.819)\n",
      "    Selected arrow strategy for 'Hematoma' with new conf: 0.819\n",
      "  Final best strategy for 'Hematoma': arrow_followed_line_detection_heuristic_bbox_success, Final best conf: 0.819\n",
      "  Generating useful heatmap for 'Hematoma' (Image: ImageCLEFmedical_Caption_2025_test_3880, Conf: 0.82)\n",
      " Error generating 'useful heatmap analysis' for Hematoma on ImageCLEFmedical_Caption_2025_test_3880: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Hematoma': Strategy='arrow_followed_line_detection_heuristic_bbox_success', Confidence=0.819\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_3880/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_3880_Hematoma.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_3880...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_3880_main_analysis_20250523_082207.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_3880 ---\n",
      "Data Source                Content Summary                                                                     \\\n",
      "          Medical Concepts X-Ray Computed\n",
      "Tomography;Brain;Hematoma;Structure of\n",
      "right middle cerebral artery   \n",
      "      Image Caption (File)                                  CT scan of the brain showing a large\n",
      "right- [...]   \n",
      "Medical Explanation/Report                                       X-Ray Computed Tomography of the brain\n",
      "[...]   \n",
      "\n",
      "Details                                                                                                                                                                                        \n",
      "                                                                                                     CUIs: X-Ray Computed Tomography;Brain;Hematoma;Structure of\n",
      "right middle cerebral artery  \n",
      "                                                                                                                          CT scan of the brain showing a large right-sided subdural\n",
      "hematoma.  \n",
      "X-Ray Computed Tomography of the brain reveals a large\n",
      "right-sided subdural hematoma adjacent to the structure of\n",
      "the right middle cerebral artery, which appears compressed\n",
      "by the hematoma.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_3880 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_3880 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 14/16: ImageCLEFmedical_Caption_2025_test_4346 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_4346 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_4346' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_4346: 5\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_4346: 5 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Hypoechoic Mass' (2 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Hypoechoic Mass' from BBox: (180, 60, 40, 40)\n",
      "Attempting SAM for 'Hypoechoic Mass' with original bbox: (180, 60, 40, 40)\n",
      "  Original bbox SAM: conf=0.772, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Hypoechoic Mass' still potentially low (0.772). Trying keypoint strategies from bbox: (180, 60, 40, 40)\n",
      "    Trying SAM with 'sift_points' (6 points) for 'Hypoechoic Mass'\n",
      "      SAM with 'sift_points': conf=0.980\n",
      "      Selected keypoint strategy 'sift_points' for 'Hypoechoic Mass' with new conf: 0.980\n",
      "    Trying SAM with 'log_blobs' (2 points) for 'Hypoechoic Mass'\n",
      "      SAM with 'log_blobs': conf=0.985\n",
      "      Selected keypoint strategy 'log_blobs' for 'Hypoechoic Mass' with new conf: 0.985\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Hypoechoic Mass'\n",
      "      SAM with 'fast_corners': conf=0.986\n",
      "      Selected keypoint strategy 'fast_corners' for 'Hypoechoic Mass' with new conf: 0.986\n",
      "    Trying SAM with 'horizontal_lines_midpoints' (3 points) for 'Hypoechoic Mass'\n",
      "      SAM with 'horizontal_lines_midpoints': conf=0.996\n",
      "      Selected keypoint strategy 'horizontal_lines_midpoints' for 'Hypoechoic Mass' with new conf: 0.996\n",
      "  Keypoint strategy improved mask for 'Hypoechoic Mass'.\n",
      "  Final best strategy for 'Hypoechoic Mass': keypoints_horizontal_lines_midpoints, Final best conf: 0.996\n",
      "  Generating useful heatmap for 'Hypoechoic Mass' (Image: ImageCLEFmedical_Caption_2025_test_4346, Conf: 1.00)\n",
      " Error generating 'useful heatmap analysis' for Hypoechoic Mass on ImageCLEFmedical_Caption_2025_test_4346: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Hypoechoic Mass': Strategy='keypoints_horizontal_lines_midpoints', Confidence=0.996\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_4346/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_4346_Hypoechoic_Mass.png\n",
      "\n",
      "  Processing label group: 'Right Breast' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Right Breast' from BBox: (50, 50, 150, 150)\n",
      "Attempting SAM for 'Right Breast' with original bbox: (50, 50, 150, 150)\n",
      "  Original bbox SAM: conf=0.779, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Right Breast' still potentially low (0.779). Trying keypoint strategies from bbox: (50, 50, 150, 150)\n",
      "    Trying SAM with 'sift_points' (10 points) for 'Right Breast'\n",
      "      SAM with 'sift_points': conf=0.978\n",
      "      Selected keypoint strategy 'sift_points' for 'Right Breast' with new conf: 0.978\n",
      "    Trying SAM with 'log_blobs' (5 points) for 'Right Breast'\n",
      "      SAM with 'log_blobs': conf=0.984\n",
      "      Selected keypoint strategy 'log_blobs' for 'Right Breast' with new conf: 0.984\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Right Breast'\n",
      "      SAM with 'fast_corners': conf=0.987\n",
      "      Selected keypoint strategy 'fast_corners' for 'Right Breast' with new conf: 0.987\n",
      "  Keypoint strategy improved mask for 'Right Breast'.\n",
      "  Final best strategy for 'Right Breast': keypoints_fast_corners, Final best conf: 0.987\n",
      "  Generating useful heatmap for 'Right Breast' (Image: ImageCLEFmedical_Caption_2025_test_4346, Conf: 0.99)\n",
      " Error generating 'useful heatmap analysis' for Right Breast on ImageCLEFmedical_Caption_2025_test_4346: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Breast': Strategy='keypoints_fast_corners', Confidence=0.987\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_4346/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_4346_Right_Breast.png\n",
      "\n",
      "  Processing label group: 'Right Testis' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Right Testis' from BBox: (10, 200, 100, 250)\n",
      "Attempting SAM for 'Right Testis' with original bbox: (10, 200, 100, 250)\n",
      "  Original bbox SAM: conf=0.847, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Right Testis': original_bbox (bbox_success), Final best conf: 0.847\n",
      "  Generating useful heatmap for 'Right Testis' (Image: ImageCLEFmedical_Caption_2025_test_4346, Conf: 0.85)\n",
      " Error generating 'useful heatmap analysis' for Right Testis on ImageCLEFmedical_Caption_2025_test_4346: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Testis': Strategy='original_bbox (bbox_success)', Confidence=0.847\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_4346/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_4346_Right_Testis.png\n",
      "\n",
      "  Processing label group: 'cystic' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Cystic' from BBox: (255, 160, 40, 40)\n",
      "Attempting SAM for 'Cystic' with original bbox: (255, 160, 40, 40)\n",
      "  Original bbox SAM: conf=0.767, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Cystic' still potentially low (0.767). Trying keypoint strategies from bbox: (255, 160, 40, 40)\n",
      "    Trying SAM with 'sift_points' (1 points) for 'Cystic'\n",
      "      SAM with 'sift_points': conf=1.002\n",
      "      Selected keypoint strategy 'sift_points' for 'Cystic' with new conf: 1.002\n",
      "    Trying SAM with 'log_blobs' (2 points) for 'Cystic'\n",
      "      SAM with 'log_blobs': conf=1.004\n",
      "      Selected keypoint strategy 'log_blobs' for 'Cystic' with new conf: 1.004\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Cystic'\n",
      "      SAM with 'fast_corners': conf=0.932\n",
      "  Keypoint strategy improved mask for 'Cystic'.\n",
      "  Final best strategy for 'Cystic': keypoints_log_blobs, Final best conf: 1.004\n",
      "  Generating useful heatmap for 'Cystic' (Image: ImageCLEFmedical_Caption_2025_test_4346, Conf: 1.00)\n",
      " Error generating 'useful heatmap analysis' for Cystic on ImageCLEFmedical_Caption_2025_test_4346: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Cystic': Strategy='keypoints_log_blobs', Confidence=1.004\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_4346/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_4346_Cystic.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_4346...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_4346_main_analysis_20250523_082302.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_4346 ---\n",
      "Data Source                Content Summary                                     \\\n",
      "          Medical Concepts   Ultrasonography;Cystic;Structure of\n",
      "right testis   \n",
      "      Image Caption (File) Ultrasound image of the right breast\n",
      "showing [...]   \n",
      "Medical Explanation/Report          Ultrasonography of the right breast\n",
      "[...]   \n",
      "\n",
      "Details                                                                                                                                                                                                      \n",
      "                                                                                                                                                     CUIs: Ultrasonography;Cystic;Structure of right testis  \n",
      "                                                                                                         Ultrasound image of the right breast showing a 1.5 cm\n",
      "hypoechoic mass (arrow) in the right breast.  \n",
      "Ultrasonography of the right breast demonstrates a 1.5 cm\n",
      "hypoechoic mass (arrow) with cystic characteristics in the\n",
      "right breast, distinct from the normal ultrasonographic\n",
      "structure of the right testis.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_4346 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_4346 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 15/16: ImageCLEFmedical_Caption_2025_test_5522 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_5522 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_5522' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_5522: 5\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "✓ YOLO detection complete. Found 1 new, non-overlapping objects.\n",
      "✓ Added 1 new detections from YOLO to ImageID ImageCLEFmedical_Caption_2025_test_5522.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_5522: 6 (1 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Left Internal Carotid Artery' (1 initial bbox(es))\n",
      " Directional label correction: 'Left Internal Carotid Artery' -> 'Right Internal Carotid Artery' (bbox on image left, implies patient right)\n",
      "    Cleaned/Corrected Label: 'Right Internal Carotid Artery' from BBox: (100, 180, 20, 60)\n",
      "Attempting SAM for 'Right Internal Carotid Artery' with original bbox: (100, 180, 20, 60)\n",
      "  Original bbox SAM: conf=0.861, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Right Internal Carotid Artery': original_bbox (bbox_success), Final best conf: 0.861\n",
      "  Generating useful heatmap for 'Right Internal Carotid Artery' (Image: ImageCLEFmedical_Caption_2025_test_5522, Conf: 0.86)\n",
      " Error generating 'useful heatmap analysis' for Right Internal Carotid Artery on ImageCLEFmedical_Caption_2025_test_5522: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Internal Carotid Artery': Strategy='original_bbox (bbox_success)', Confidence=0.861\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_5522/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_5522_Right_Internal_Carotid_Artery.png\n",
      "\n",
      "  Processing label group: 'Left Middle Cerebral Artery' (1 initial bbox(es))\n",
      " Directional label correction: 'Left Middle Cerebral Artery' -> 'Right Middle Cerebral Artery' (bbox on image left, implies patient right)\n",
      "    Cleaned/Corrected Label: 'Right Middle Cerebral Artery' from BBox: (60, 100, 60, 40)\n",
      "Attempting SAM for 'Right Middle Cerebral Artery' with original bbox: (60, 100, 60, 40)\n",
      "  Original bbox SAM: conf=0.932, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Right Middle Cerebral Artery': original_bbox (bbox_success), Final best conf: 0.932\n",
      "  Generating useful heatmap for 'Right Middle Cerebral Artery' (Image: ImageCLEFmedical_Caption_2025_test_5522, Conf: 0.93)\n",
      " Error generating 'useful heatmap analysis' for Right Middle Cerebral Artery on ImageCLEFmedical_Caption_2025_test_5522: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Middle Cerebral Artery': Strategy='original_bbox (bbox_success)', Confidence=0.932\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_5522/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_5522_Right_Middle_Cerebral_Artery.png\n",
      "\n",
      "  Processing label group: 'Middle Cerebral Artery' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Middle Cerebral Artery' from BBox: (160, 120, 120, 40)\n",
      "Attempting SAM for 'Middle Cerebral Artery' with original bbox: (160, 120, 120, 40)\n",
      "  Original bbox SAM: conf=0.536, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.536) for 'Middle Cerebral Artery'. Trying arrow detection from bbox: (160, 120, 120, 40)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (160, 120, 120, 40), Target bbox: (219, 182, 20, 20), Conf: 0.32\n",
      "  Arrow found for 'Middle Cerebral Artery', method: line_detection_heuristic. New target bbox: (219, 182, 20, 20)\n",
      "    SAM on arrow target: conf=0.644 (adjusted: 0.684)\n",
      "    Selected arrow strategy for 'Middle Cerebral Artery' with new conf: 0.684\n",
      "  Confidence for 'Middle Cerebral Artery' still potentially low (0.684). Trying keypoint strategies from bbox: (160, 120, 120, 40)\n",
      "    Trying SAM with 'sift_points' (4 points) for 'Middle Cerebral Artery'\n",
      "      SAM with 'sift_points': conf=0.984\n",
      "      Selected keypoint strategy 'sift_points' for 'Middle Cerebral Artery' with new conf: 0.984\n",
      "    Trying SAM with 'log_blobs' (3 points) for 'Middle Cerebral Artery'\n",
      "      SAM with 'log_blobs': conf=0.994\n",
      "      Selected keypoint strategy 'log_blobs' for 'Middle Cerebral Artery' with new conf: 0.994\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Middle Cerebral Artery'\n",
      "      SAM with 'fast_corners': conf=0.916\n",
      "  Keypoint strategy improved mask for 'Middle Cerebral Artery'.\n",
      "  Final best strategy for 'Middle Cerebral Artery': keypoints_log_blobs, Final best conf: 0.994\n",
      "  Generating useful heatmap for 'Middle Cerebral Artery' (Image: ImageCLEFmedical_Caption_2025_test_5522, Conf: 0.99)\n",
      " Error generating 'useful heatmap analysis' for Middle Cerebral Artery on ImageCLEFmedical_Caption_2025_test_5522: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Middle Cerebral Artery': Strategy='keypoints_log_blobs', Confidence=0.994\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_5522/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_5522_Middle_Cerebral_Artery.png\n",
      "\n",
      "  Processing label group: 'Right Internal Carotid Artery' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Right Internal Carotid Artery' from BBox: (220, 180, 20, 60)\n",
      "Attempting SAM for 'Right Internal Carotid Artery' with original bbox: (220, 180, 20, 60)\n",
      "  Original bbox SAM: conf=0.590, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.590) for 'Right Internal Carotid Artery'. Trying arrow detection from bbox: (220, 180, 20, 60)\n",
      "✓ Arrow detected by line heuristic. Original bbox: (220, 180, 20, 60), Target bbox: (244, 238, 20, 20), Conf: 0.35\n",
      "  Arrow found for 'Right Internal Carotid Artery', method: line_detection_heuristic. New target bbox: (244, 238, 20, 20)\n",
      "    SAM on arrow target: conf=0.767 (adjusted: 0.821)\n",
      "    Selected arrow strategy for 'Right Internal Carotid Artery' with new conf: 0.821\n",
      "  Final best strategy for 'Right Internal Carotid Artery': arrow_followed_line_detection_heuristic_bbox_success, Final best conf: 0.821\n",
      "  Generating useful heatmap for 'Right Internal Carotid Artery' (Image: ImageCLEFmedical_Caption_2025_test_5522, Conf: 0.82)\n",
      " Error generating 'useful heatmap analysis' for Right Internal Carotid Artery on ImageCLEFmedical_Caption_2025_test_5522: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Right Internal Carotid Artery': Strategy='arrow_followed_line_detection_heuristic_bbox_success', Confidence=0.821\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_5522/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_5522_Right_Internal_Carotid_Artery.png\n",
      "\n",
      "  Processing label group: 'Right Middle Cerebral Artery' (1 initial bbox(es))\n",
      "Directional label correction: 'Right Middle Cerebral Artery' -> 'Left Middle Cerebral Artery' (bbox on image right, implies patient left)\n",
      "    Cleaned/Corrected Label: 'Left Middle Cerebral Artery' from BBox: (240, 100, 60, 40)\n",
      "Attempting SAM for 'Left Middle Cerebral Artery' with original bbox: (240, 100, 60, 40)\n",
      "  Original bbox SAM: conf=0.713, strategy='original_bbox (bbox_success)'\n",
      "  Low confidence (0.713) for 'Left Middle Cerebral Artery'. Trying arrow detection from bbox: (240, 100, 60, 40)\n",
      "  Confidence for 'Left Middle Cerebral Artery' still potentially low (0.713). Trying keypoint strategies from bbox: (240, 100, 60, 40)\n",
      "    Trying SAM with 'sift_points' (1 points) for 'Left Middle Cerebral Artery'\n",
      "      SAM with 'sift_points': conf=0.996\n",
      "      Selected keypoint strategy 'sift_points' for 'Left Middle Cerebral Artery' with new conf: 0.996\n",
      "    Trying SAM with 'fast_corners' (2 points) for 'Left Middle Cerebral Artery'\n",
      "      SAM with 'fast_corners': conf=0.997\n",
      "      Selected keypoint strategy 'fast_corners' for 'Left Middle Cerebral Artery' with new conf: 0.997\n",
      "  Keypoint strategy improved mask for 'Left Middle Cerebral Artery'.\n",
      "  Final best strategy for 'Left Middle Cerebral Artery': keypoints_fast_corners, Final best conf: 0.997\n",
      "  Generating useful heatmap for 'Left Middle Cerebral Artery' (Image: ImageCLEFmedical_Caption_2025_test_5522, Conf: 1.00)\n",
      " Error generating 'useful heatmap analysis' for Left Middle Cerebral Artery on ImageCLEFmedical_Caption_2025_test_5522: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Left Middle Cerebral Artery': Strategy='keypoints_fast_corners', Confidence=0.997\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_5522/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_5522_Left_Middle_Cerebral_Artery.png\n",
      "\n",
      "  Processing label group: 'YOLO_scissors' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Yolo_Scissors' from BBox: (31, 257, 148, 226)\n",
      "Attempting SAM for 'Yolo_Scissors' with original bbox: (31, 257, 148, 226)\n",
      "  Original bbox SAM: conf=0.768, strategy='original_bbox (bbox_success)'\n",
      "  Confidence for 'Yolo_Scissors' still potentially low (0.768). Trying keypoint strategies from bbox: (31, 257, 148, 226)\n",
      "    Trying SAM with 'sift_points' (10 points) for 'Yolo_Scissors'\n",
      "      SAM with 'sift_points': conf=0.923\n",
      "      Selected keypoint strategy 'sift_points' for 'Yolo_Scissors' with new conf: 0.923\n",
      "    Trying SAM with 'log_blobs' (5 points) for 'Yolo_Scissors'\n",
      "      SAM with 'log_blobs': conf=0.982\n",
      "      Selected keypoint strategy 'log_blobs' for 'Yolo_Scissors' with new conf: 0.982\n",
      "    Trying SAM with 'fast_corners' (8 points) for 'Yolo_Scissors'\n",
      "      SAM with 'fast_corners': conf=0.907\n",
      "  Keypoint strategy improved mask for 'Yolo_Scissors'.\n",
      "  Final best strategy for 'Yolo_Scissors': keypoints_log_blobs, Final best conf: 0.982\n",
      "  Generating useful heatmap for 'Yolo_Scissors' (Image: ImageCLEFmedical_Caption_2025_test_5522, Conf: 0.98)\n",
      " Error generating 'useful heatmap analysis' for Yolo_Scissors on ImageCLEFmedical_Caption_2025_test_5522: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Yolo_Scissors': Strategy='keypoints_log_blobs', Confidence=0.982\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_5522/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_5522_Yolo_Scissors.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_5522...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_5522_main_analysis_20250523_082405.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_5522 ---\n",
      "Data Source                 \\\n",
      "          Medical Concepts   \n",
      "      Image Caption (File)   \n",
      "Medical Explanation/Report   \n",
      "\n",
      "Content Summary                                                                                                                                                                                                        \\\n",
      "angiogram;Structure of left internal\n",
      "carotid artery;Structure of right\n",
      "internal carotid artery;Structure of\n",
      "middle cerebral artery;Structure of left\n",
      "middle cerebral artery;Structure of\n",
      "right middle cerebral artery   \n",
      "                                                                                                                                                                           Cerebral angiogram showing the right\n",
      "[...]   \n",
      "                                                                                                                                                                     Computed Tomography angiogram of the\n",
      "brain [...]   \n",
      "\n",
      "Details                                                                                                                                                                                                                                                                                          \n",
      "                                                                    CUIs: angiogram;Structure of left internal carotid\n",
      "artery;Structure of right internal carotid artery;Structure\n",
      "of middle cerebral artery;Structure of left middle cerebral\n",
      "artery;Structure of right middle cerebral artery  \n",
      "                                                                                                                                                                                                                          Cerebral angiogram showing the right vertebral artery\n",
      "(yellow arrows)  \n",
      "Computed Tomography angiogram of the brain showing the right\n",
      "vertebral artery (yellow arrows) and demonstrating the\n",
      "normal structure of the left internal carotid artery, right\n",
      "internal carotid artery, middle cerebral artery, left middle\n",
      "cerebral artery, and right middle cerebral artery.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_5522 \n",
      "\n",
      "--- Inter-Image Recess & Cleanup (ImageCLEFmedical_Caption_2025_test_5522 done) ---\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "Offloading SAM predictor to CPU during recess (if on CUDA)...\n",
      "Pausing for 15 seconds...\n",
      "Restoring SAM predictor to CUDA (if applicable)...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "------------------------- PROCESSING IMAGE 16/16: ImageCLEFmedical_Caption_2025_test_8779 -------------------------\n",
      "\n",
      " Starting Analysis for Image ID: ImageCLEFmedical_Caption_2025_test_8779 \n",
      "✓ Image 'ImageCLEFmedical_Caption_2025_test_8779' loaded (512x512).\n",
      "  Initial SAM bboxes for image ImageCLEFmedical_Caption_2025_test_8779: 4\n",
      "✓ YOLO model 'yolov8n.pt' loaded for CPU detection.\n",
      "  Total detections after YOLO for image ImageCLEFmedical_Caption_2025_test_8779: 4 (0 added by YOLO).\n",
      "\n",
      "  Processing label group: 'Lymph Nodes' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Lymph Nodes' from BBox: (180, 250, 50, 50)\n",
      "Attempting SAM for 'Lymph Nodes' with original bbox: (180, 250, 50, 50)\n",
      "  Original bbox SAM: conf=0.917, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Lymph Nodes': original_bbox (bbox_success), Final best conf: 0.917\n",
      "  Generating useful heatmap for 'Lymph Nodes' (Image: ImageCLEFmedical_Caption_2025_test_8779, Conf: 0.92)\n",
      " Error generating 'useful heatmap analysis' for Lymph Nodes on ImageCLEFmedical_Caption_2025_test_8779: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Lymph Nodes': Strategy='original_bbox (bbox_success)', Confidence=0.917\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_8779/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_8779_Lymph_Nodes.png\n",
      "\n",
      "  Processing label group: 'hypermetabolic mass' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Hypermetabolic Mass' from BBox: (200, 300, 40, 40)\n",
      "Attempting SAM for 'Hypermetabolic Mass' with original bbox: (200, 300, 40, 40)\n",
      "  Original bbox SAM: conf=0.912, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Hypermetabolic Mass': original_bbox (bbox_success), Final best conf: 0.912\n",
      "  Generating useful heatmap for 'Hypermetabolic Mass' (Image: ImageCLEFmedical_Caption_2025_test_8779, Conf: 0.91)\n",
      " Error generating 'useful heatmap analysis' for Hypermetabolic Mass on ImageCLEFmedical_Caption_2025_test_8779: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Hypermetabolic Mass': Strategy='original_bbox (bbox_success)', Confidence=0.912\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_8779/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_8779_Hypermetabolic_Mass.png\n",
      "\n",
      "  Processing label group: 'lymph nodes' (1 initial bbox(es))\n",
      "    Cleaned/Corrected Label: 'Lymph Nodes' from BBox: (280, 420, 100, 100)\n",
      "Attempting SAM for 'Lymph Nodes' with original bbox: (280, 420, 100, 100)\n",
      " Bbox (280, 420, 100, 100) partially outside image bounds (512x512). Clamping not implemented here, might lead to errors.\n",
      "  Original bbox SAM: conf=0.850, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Lymph Nodes': original_bbox (bbox_success), Final best conf: 0.850\n",
      "  Generating useful heatmap for 'Lymph Nodes' (Image: ImageCLEFmedical_Caption_2025_test_8779, Conf: 0.85)\n",
      " Error generating 'useful heatmap analysis' for Lymph Nodes on ImageCLEFmedical_Caption_2025_test_8779: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Lymph Nodes': Strategy='original_bbox (bbox_success)', Confidence=0.850\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_8779/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_8779_Lymph_Nodes.png\n",
      "\n",
      "  Processing label group: 'right breast' (1 initial bbox(es))\n",
      "Directional label correction: 'Right Breast' -> 'Left Breast' (bbox on image right, implies patient left)\n",
      "    Cleaned/Corrected Label: 'Left Breast' from BBox: (250, 300, 150, 150)\n",
      "Attempting SAM for 'Left Breast' with original bbox: (250, 300, 150, 150)\n",
      "  Original bbox SAM: conf=0.849, strategy='original_bbox (bbox_success)'\n",
      "  Final best strategy for 'Left Breast': original_bbox (bbox_success), Final best conf: 0.849\n",
      "  Generating useful heatmap for 'Left Breast' (Image: ImageCLEFmedical_Caption_2025_test_8779, Conf: 0.85)\n",
      " Error generating 'useful heatmap analysis' for Left Breast on ImageCLEFmedical_Caption_2025_test_8779: OpenCV(4.10.0) /io/opencv/modules/core/src/arithm.cpp:658: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
      "\n",
      "    ✓ Result for 'Left Breast': Strategy='original_bbox (bbox_success)', Confidence=0.849\n",
      "  ✓ Saved detailed heatmap display: ./result_explain-3/sam_deduplicated/detailed_heatmaps/ImageCLEFmedical_Caption_2025_test_8779/detailed_heatmap_display_ImageCLEFmedical_Caption_2025_test_8779_Left_Breast.png\n",
      "\n",
      "  Generating main visualization for ImageCLEFmedical_Caption_2025_test_8779...\n",
      "✓ Main visualization saved: ./result_explain-3/sam_deduplicated/main_visualizations/ImageCLEFmedical_Caption_2025_test_8779_main_analysis_20250523_082439.png\n",
      "\n",
      "--- Data Summary Table for Image: ImageCLEFmedical_Caption_2025_test_8779 ---\n",
      "Data Source                Content Summary                              \\\n",
      "          Medical Concepts    Positron-Emission Tomography;lymph nodes   \n",
      "      Image Caption (File) Positron emission tomography-computed\n",
      "[...]   \n",
      "Medical Explanation/Report Positron-Emission Tomography-Computed\n",
      "[...]   \n",
      "\n",
      "Details                                                                                                                                                                                                                                      \n",
      "                                                                                                                                                                                             CUIs: Positron-Emission Tomography;lymph nodes  \n",
      "                                                                                                                  Positron emission tomography-computed tomography (PET-CT)\n",
      "scan showing a hypermetabolic mass in the right breast\n",
      "(arrow).  \n",
      "Positron-Emission Tomography-Computed Tomography (PET-CT)\n",
      "scan of the chest demonstrating a hypermetabolic mass in the\n",
      "right breast (arrow), with corresponding lymph nodes showing\n",
      "increased metabolic activity, suggestive of malignancy.  \n",
      "--------------------------------------------------\n",
      " Analysis Completed for Image ID: ImageCLEFmedical_Caption_2025_test_8779 \n",
      "\n",
      "--- Phase 3: Final Reporting & Cleanup ---\n",
      "Generating final summary reports and CSVs...\n",
      "--- Exporting Analysis Metrics to: ./result_explain-3/sam_deduplicated/analysis_metrics ---\n",
      "✓ Detailed confidence scores exported: ./result_explain-3/sam_deduplicated/analysis_metrics/detailed_confidence_scores.csv\n",
      "✓ Image-level analysis summary exported: ./result_explain-3/sam_deduplicated/analysis_metrics/image_level_analysis_summary.csv\n",
      "✓ Strategy performance summary exported: ./result_explain-3/sam_deduplicated/analysis_metrics/processing_strategy_performance.csv\n",
      "\n",
      "======================================================================\n",
      " COMPREHENSIVE FINAL ANALYSIS REPORT (OVERALL)\n",
      "======================================================================\n",
      "\n",
      " --- OVERALL STATISTICS ---\n",
      "  Total Images Processed: 16\n",
      "  Total Medical Structures Identified (sum over images): 71\n",
      "  Total Bounding Boxes Analyzed (sum over images): 76\n",
      "  Avg. Structures per Image: 4.4\n",
      "  Total YOLO Detections Added Across All Images: 4\n",
      "\n",
      " --- CONFIDENCE ANALYSIS (ACROSS ALL STRUCTURES) ---\n",
      "  Overall Average Confidence: 0.901\n",
      "  Confidence Range: 0.660 - 1.042\n",
      "  Confidence Std. Deviation: 0.079\n",
      "\n",
      "   Confidence Distribution:\n",
      "    High Confidence (≥0.8): 67 (94.4%)\n",
      "    Medium Confidence (0.5-0.8): 4 (5.6%)\n",
      "    Low Confidence (<0.5): 0 (0.0%)\n",
      "\n",
      " --- TOP PERFORMING IMAGES (BY AVG. CONFIDENCE) ---\n",
      "  - Image 'ImageCLEFmedical_Caption_2025_test_4346': Avg. Conf 0.958 (4 structures)\n",
      "  - Image 'ImageCLEFmedical_Caption_2025_test_15167': Avg. Conf 0.946 (6 structures)\n",
      "  - Image 'ImageCLEFmedical_Caption_2025_test_5522': Avg. Conf 0.945 (5 structures)\n",
      "  - Image 'ImageCLEFmedical_Caption_2025_test_1251': Avg. Conf 0.944 (8 structures)\n",
      "  - Image 'ImageCLEFmedical_Caption_2025_test_283': Avg. Conf 0.944 (3 structures)\n",
      "\n",
      " --- IMAGES POTENTIALLY NEEDING REVIEW (LOWEST AVG. CONFIDENCE) ---\n",
      "  All processed images have average confidence ≥ 0.6 or no images processed.\n",
      "\n",
      " --- PROCESSING STRATEGY PERFORMANCE ---\n",
      "  - Strategy 'keypoints_log_blobs': Used 11 times, Avg. Conf 0.991, Success (>0.6) 100.0%\n",
      "  - Strategy 'keypoints_fast_corners': Used 8 times, Avg. Conf 0.947, Success (>0.6) 100.0%\n",
      "  - Strategy 'keypoints_horizontal_lines_midpoints': Used 2 times, Avg. Conf 0.945, Success (>0.6) 100.0%\n",
      "  - Strategy 'arrow_followed_line_detection_heuristic_bbox_success': Used 10 times, Avg. Conf 0.897, Success (>0.6) 100.0%\n",
      "  - Strategy 'original_bbox (bbox_success)': Used 40 times, Avg. Conf 0.866, Success (>0.6) 100.0%\n",
      "\n",
      " --- RECOMMENDATIONS & NOTES ---\n",
      "   Overall performance appears strong with an average confidence of 0.901.\n",
      "   YOLO enhancement contributed 4 additional detections. Consider fine-tuning YOLO on specific medical entities if not already done.\n",
      "\n",
      " Output files (CSVs, heatmaps, visualizations) are saved in subdirectories within: ./result_explain-3/sam_deduplicated\n",
      "======================================================================\n",
      "Performing final cleanup of SAM model...\n",
      " Clearing CUDA cache...\n",
      "✓ CUDA cache cleared and garbage collected.\n",
      "\n",
      "======================================================================\n",
      "✅✅✅ MEDICAL IMAGE ANALYSIS PIPELINE COMPLETED ✅✅✅\n",
      "Processed 16 images. Results in: ./result_explain-3/sam_deduplicated\n",
      "======================================================================\n",
      "\n",
      "Script execution finished.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SECTION I: IMPORTS, CONFIGURATION, AND INITIAL SETUP\n",
    "# ==============================================================================\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"SECTION I: INITIALIZING LIBRARIES, CONFIGURATION, AND CUDA\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import gc # Garbage collection\n",
    "import time # For adding pauses\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "import urllib.request\n",
    "from collections import defaultdict\n",
    "import csv # Though pandas is used more for CSVs later\n",
    "import logging # For more structured logging if desired\n",
    "\n",
    "# Data Handling & Numerics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Image Processing\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from skimage.measure import label as skimage_label, regionprops\n",
    "from scipy.spatial.distance import euclidean\n",
    "try:\n",
    "    from skimage import feature\n",
    "    SKIMAGE_AVAILABLE = True\n",
    "    print(\"✓ Scikit-image (skimage) available.\")\n",
    "except ImportError:\n",
    "    SKIMAGE_AVAILABLE = False\n",
    "    print(\" Scikit-image (skimage) not available. Some keypoint features will be disabled.\")\n",
    "\n",
    "# Plotting & Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.mplot3d import Axes3D # For 3D heatmap\n",
    "import textwrap # For wrapping text in visualizations\n",
    "\n",
    "# Machine Learning & Deep Learning - PyTorch & Transformers\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "# from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline # Commented out as not used in the final logic provided\n",
    "try:\n",
    "    import ultralytics\n",
    "    YOLO_AVAILABLE = True\n",
    "    print(\"✓ Ultralytics YOLO available.\")\n",
    "except ImportError:\n",
    "    YOLO_AVAILABLE = False\n",
    "    print(\" Ultralytics YOLO not available. YOLO enhancement will be disabled.\")\n",
    "\n",
    "# IPython/Jupyter specific (useful for notebooks, might not be needed for pure scripts)\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "# --- Configuration ---\n",
    "print(\"\\n--- Loading Configuration ---\")\n",
    "SAM_COORD_PATH = './sam_coord.csv'\n",
    "CAPTIONS_PATH = './3_submission_explainability.csv' # This seems to be the 'explanations_df' in create_image_data_table\n",
    "CONCEPTS_PATH = './ref_mini_concepts_natural_.csv'\n",
    "CAPTION_FILE_PATH = './caption.csv' # This seems to be the 'caption_file_df' in create_image_data_table\n",
    "IMAGES_DIR = './data/test_set_explain'\n",
    "OUTPUT_DIR = './result_explain-3/sam_deduplicated' # Changed to avoid overwriting original results\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"✓ Output directory set to: {OUTPUT_DIR}\")\n",
    "\n",
    "# Color palette for consistency (using the second, more vibrant palette you provided)\n",
    "COLORS = [\n",
    "    '#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FF8C00',\n",
    "    '#DDA0DD', '#98D8C8', '#F7DC6F', '#BB8FCE', '#85C1E9',\n",
    "    '#F8C471', '#82E0AA', '#F1948A', '#85C1E9', '#D5DBDB'\n",
    "]\n",
    "print(f\"✓ Color palette loaded with {len(COLORS)} colors.\")\n",
    "\n",
    "# Warnings behavior\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"✓ Warnings are suppressed (set to 'ignore').\")\n",
    "\n",
    "# --- CUDA Memory Management Utility ---\n",
    "def clear_cuda_cache():\n",
    "    \"\"\"\n",
    "    Clears CUDA cache and runs garbage collection to free up GPU memory.\n",
    "    Essential for processing multiple large images/models sequentially.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(\" Clearing CUDA cache...\")\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()  # Wait for all CUDA operations to complete\n",
    "        gc.collect() # Python's garbage collection\n",
    "        print(\"✓ CUDA cache cleared and garbage collected.\")\n",
    "    else:\n",
    "        print(\" CUDA not available, skipping cache clear.\")\n",
    "\n",
    "# Initial clear at the start of the script\n",
    "clear_cuda_cache()\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION II: CORE UTILITIES\n",
    "# ==============================================================================\n",
    "print(\"\\n----------------------------------------------------------------------\")\n",
    "print(\"SECTION II: DEFINING CORE UTILITY FUNCTIONS\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    \"\"\"Convert hexadecimal color string to a list of RGB values (0-1 range).\"\"\"\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    return [int(hex_color[i:i+2], 16) / 255.0 for i in (0, 2, 4)]\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load all necessary CSV data files (SAM coordinates, captions, concepts, explanations).\n",
    "    Handles potential file not found errors.\n",
    "    \"\"\"\n",
    "    print(\"--- Loading CSV Data Files ---\")\n",
    "    data_loaded_successfully = True\n",
    "    try:\n",
    "        sam_df = pd.read_csv(SAM_COORD_PATH)\n",
    "        print(f\"✓ SAM coordinates loaded: {len(sam_df)} records from {SAM_COORD_PATH}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ERROR: SAM coordinates file not found at {SAM_COORD_PATH}\")\n",
    "        sam_df = pd.DataFrame() # Return empty DataFrame\n",
    "        data_loaded_successfully = False\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR loading SAM coordinates from {SAM_COORD_PATH}: {e}\")\n",
    "        sam_df = pd.DataFrame()\n",
    "        data_loaded_successfully = False\n",
    "\n",
    "    try:\n",
    "        # This was referred to as captions_df, but seems to hold 'explanations' for create_image_data_table\n",
    "        # and 'caption' for the main visualization. Let's call it explanations_df for clarity based on its use.\n",
    "        explanations_df = pd.read_csv(CAPTIONS_PATH)\n",
    "        print(f\"✓ Explanations/Captions (for main vis) loaded: {len(explanations_df)} records from {CAPTIONS_PATH}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ERROR: Explanations file not found at {CAPTIONS_PATH}\")\n",
    "        explanations_df = pd.DataFrame()\n",
    "        data_loaded_successfully = False\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR loading explanations from {CAPTIONS_PATH}: {e}\")\n",
    "        explanations_df = pd.DataFrame()\n",
    "        data_loaded_successfully = False\n",
    "\n",
    "    if os.path.exists(CONCEPTS_PATH):\n",
    "        try:\n",
    "            concepts_df = pd.read_csv(CONCEPTS_PATH)\n",
    "            print(f\"✓ Concepts loaded: {len(concepts_df)} records from {CONCEPTS_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR loading concepts from {CONCEPTS_PATH}: {e}\")\n",
    "            concepts_df = pd.DataFrame() # Return empty if error\n",
    "            data_loaded_successfully = False\n",
    "    else:\n",
    "        print(f\" Concepts file not found (optional): {CONCEPTS_PATH}\")\n",
    "        concepts_df = pd.DataFrame() # Optional, so return empty DataFrame\n",
    "\n",
    "    if os.path.exists(CAPTION_FILE_PATH):\n",
    "        try:\n",
    "            # This seems to be distinct from CAPTIONS_PATH, used for table display\n",
    "            caption_file_df = pd.read_csv(CAPTION_FILE_PATH)\n",
    "            print(f\"✓ Caption file (for table) loaded: {len(caption_file_df)} records from {CAPTION_FILE_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR loading caption file from {CAPTION_FILE_PATH}: {e}\")\n",
    "            caption_file_df = pd.DataFrame() # Return empty if error\n",
    "            data_loaded_successfully = False\n",
    "    else:\n",
    "        print(f\" Caption file not found (optional): {CAPTION_FILE_PATH}\")\n",
    "        caption_file_df = pd.DataFrame() # Optional, so return empty DataFrame\n",
    "\n",
    "    if data_loaded_successfully:\n",
    "        print(\"✓ All available data files loaded.\")\n",
    "    else:\n",
    "        print(\" Some data files failed to load. Functionality might be affected.\")\n",
    "    return sam_df, explanations_df, concepts_df, caption_file_df\n",
    "\n",
    "def find_image_file(image_id, images_dir):\n",
    "    \"\"\"Find image file corresponding to an ID within a directory, checking common extensions.\"\"\"\n",
    "    extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
    "    base_image_id = str(image_id).split('.')[0] # Handle if image_id has an extension\n",
    "\n",
    "    for ext in extensions:\n",
    "        full_path = os.path.join(images_dir, f\"{base_image_id}{ext}\")\n",
    "        if os.path.exists(full_path):\n",
    "            return full_path\n",
    "\n",
    "    # Fallback: Walk through the directory if direct match fails (more exhaustive)\n",
    "    for root, _, files in os.walk(images_dir):\n",
    "        for file in files:\n",
    "            file_base_name = os.path.splitext(file)[0]\n",
    "            if base_image_id == file_base_name:\n",
    "                return os.path.join(root, file)\n",
    "    print(f\"Could not find image for ID: {image_id} in {images_dir}\")\n",
    "    return None\n",
    "\n",
    "def clean_label_text(label):\n",
    "    \"\"\"Clean and simplify label text by removing predefined terms and title-casing.\"\"\"\n",
    "    if not isinstance(label, str): # Ensure label is a string\n",
    "        label = str(label)\n",
    "\n",
    "    remove_terms = [\n",
    "        \"Structure of\", \"structure of\", \"Bone structure of\", \"bone structure of\",\n",
    "        \"Entire\", \"entire\", \"Complete\", \"complete\"\n",
    "    ]\n",
    "    cleaned = label\n",
    "    for term in remove_terms:\n",
    "        cleaned = cleaned.replace(term + \" \", \"\").replace(term, \"\")\n",
    "    return cleaned.strip().title()\n",
    "\n",
    "print(\"✓ Core utility functions defined.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION III: SEGMENT ANYTHING MODEL (SAM) SETUP\n",
    "# ==============================================================================\n",
    "print(\"\\n----------------------------------------------------------------------\")\n",
    "print(\"SECTION III: SETTING UP SEGMENT ANYTHING MODEL (SAM)\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "def setup_sam():\n",
    "    \"\"\"\n",
    "    Sets up the SAM model (ViT-H), downloads checkpoint if needed,\n",
    "    and initializes the SamPredictor.\n",
    "    This version is based on your `setup_sam_fixed` for robustness.\n",
    "    \"\"\"\n",
    "    print(\"--- Initializing SAM ---\")\n",
    "    try:\n",
    "        # Ensure model directory exists\n",
    "        os.makedirs('sam_models', exist_ok=True)\n",
    "        sam_checkpoint = \"sam_models/sam_vit_h_4b8939.pth\"\n",
    "        model_type = \"vit_h\" # Hardcoded to ViT-H as in your script\n",
    "\n",
    "        if not os.path.exists(sam_checkpoint):\n",
    "            print(f\"SAM checkpoint not found at {sam_checkpoint}. Downloading (this may take a few minutes)...\")\n",
    "            urllib.request.urlretrieve(\n",
    "                \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\",\n",
    "                sam_checkpoint\n",
    "            )\n",
    "            print(\"✓ SAM model downloaded successfully!\")\n",
    "\n",
    "        device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Attempting to load SAM model on device: {device_type}\")\n",
    "\n",
    "        # Load SAM model with error handling\n",
    "        try:\n",
    "            sam_model = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "            sam_model.to(device=device_type)\n",
    "            # Test the model with a simple operation by creating a predictor\n",
    "            predictor = SamPredictor(sam_model)\n",
    "            print(f\"✓ SAM model ({model_type}) loaded and predictor initialized successfully on {device_type}!\")\n",
    "            # Note: SamAutomaticMaskGenerator is configured differently and separately if needed.\n",
    "            # Your main loop uses SamPredictor, which is what we're returning.\n",
    "            return predictor, device_type, sam_model # Return sam_model for potential explicit deletion\n",
    "        except Exception as e:\n",
    "            print(f\" CUDA SAM loading failed: {e}. Falling back to CPU for SAM.\")\n",
    "            if device_type == \"cuda\": # Only try CPU if CUDA failed\n",
    "                device_type = \"cpu\"\n",
    "                sam_model = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "                sam_model.to(device=device_type)\n",
    "                predictor = SamPredictor(sam_model)\n",
    "                print(f\"✓ SAM model ({model_type}) loaded and predictor initialized successfully on CPU (fallback)!\")\n",
    "                return predictor, device_type, sam_model\n",
    "            else: # If initial device was CPU and it failed\n",
    "                print(f\"  SAM model loading failed on CPU as well: {e}\")\n",
    "                return None, \"cpu\", None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" SAM setup failed completely: {e}\")\n",
    "        return None, \"cpu\", None\n",
    "\n",
    "# Initialize SAM globally if you intend to use the same instance throughout.\n",
    "# However, your `run_ultimate_analysis_fixed` calls `setup_sam_fixed` (now `setup_sam`)\n",
    "# inside, which is fine if you want to re-initialize or handle setup per run.\n",
    "# For a script processing many images, initializing once is usually better.\n",
    "# Let's initialize it here for the script's scope.\n",
    "# The main loop will receive this predictor.\n",
    "\n",
    "# SAM_PREDICTOR, SAM_DEVICE, SAM_MODEL_INSTANCE = setup_sam()\n",
    "# The main loop will call setup_sam() to get these.\n",
    "\n",
    "print(\"✓ SAM setup function defined.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION IV: SAM MASKING FUNCTIONS\n",
    "# (Leveraging SamPredictor for more controlled segmentation based on prompts)\n",
    "# ==============================================================================\n",
    "print(\"\\n----------------------------------------------------------------------\")\n",
    "print(\"SECTION IV: DEFINING SAM MASKING LOGIC\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "def get_sam_mask_from_bbox(image_rgb, bbox_coords, predictor):\n",
    "    \"\"\"\n",
    "    Generates a segmentation mask using SAM based on a bounding box prompt.\n",
    "    Args:\n",
    "        image_rgb (np.ndarray): The input image in RGB format.\n",
    "        bbox_coords (tuple): (x, y, w, h) for the bounding box.\n",
    "        predictor (SamPredictor): The initialized SAM predictor instance.\n",
    "    Returns:\n",
    "        mask (np.ndarray): Boolean mask, or zeros if failed.\n",
    "        confidence (float): Confidence score of the best mask.\n",
    "        status (str): Status message (\"bbox_success\", \"invalid_bbox\", etc.).\n",
    "    \"\"\"\n",
    "    if predictor is None:\n",
    "        print(\" SAM predictor not available in get_sam_mask_from_bbox.\")\n",
    "        return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0, \"predictor_unavailable\"\n",
    "\n",
    "    # It's good practice to clear cache before potentially large GPU operations,\n",
    "    # though this will be called more broadly between images.\n",
    "    # clear_cuda_cache() # Potentially too frequent if called for every bbox. Manage at image level.\n",
    "\n",
    "    x, y, w, h = bbox_coords\n",
    "\n",
    "    # Validate bbox\n",
    "    if x < 0 or y < 0 or w <= 0 or h <= 0:\n",
    "        print(f\" Invalid bbox: {bbox_coords}\")\n",
    "        return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0, \"invalid_bbox\"\n",
    "    if x + w > image_rgb.shape[1] or y + h > image_rgb.shape[0]:\n",
    "        # Clamp bbox to image dimensions if slightly out, or reject if too far\n",
    "        # For simplicity, let's reject if the starting point is okay but extent is too large\n",
    "        print(f\" Bbox {bbox_coords} partially outside image bounds ({image_rgb.shape[1]}x{image_rgb.shape[0]}). Clamping not implemented here, might lead to errors.\")\n",
    "        # A more robust way would be to clamp:\n",
    "        # x2 = min(x + w, image_rgb.shape[1])\n",
    "        # y2 = min(y + h, image_rgb.shape[0])\n",
    "        # w = x2 - x\n",
    "        # h = y2 - y\n",
    "        # if w <= 0 or h <= 0: return ... \"bbox_out_of_bounds_after_clamping\"\n",
    "        # For now, proceed with caution or return error for out of bounds.\n",
    "        # Let's return an error state for this case to be safe.\n",
    "        # return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0, \"bbox_out_of_bounds\"\n",
    "\n",
    "    try:\n",
    "        predictor.set_image(image_rgb)\n",
    "    except Exception as e:\n",
    "        print(f\" SAM predictor.set_image failed: {e}\")\n",
    "        # Attempt to reset predictor or re-initialize SAM if this becomes a recurring issue\n",
    "        return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0, \"set_image_failed\"\n",
    "\n",
    "    input_box = np.array([x, y, x + w, y + h])\n",
    "\n",
    "    try:\n",
    "        # multimask_output=True gives 3 masks. The first one is usually the best.\n",
    "        # Scores are IOU predictions for each mask.\n",
    "        masks, scores, logits = predictor.predict(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            box=input_box[None, :],  # SAM expects a batch of boxes\n",
    "            multimask_output=True,\n",
    "        )\n",
    "        \n",
    "        if masks is not None and len(masks) > 0 and scores is not None and len(scores) > 0:\n",
    "            best_idx = np.argmax(scores)\n",
    "            return masks[best_idx], float(scores[best_idx]), \"bbox_success\"\n",
    "        else:\n",
    "            print(\" SAM predictor.predict returned no masks/scores for bbox.\")\n",
    "            return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0, \"no_masks_from_bbox\"\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(f\" CUDA Out of Memory during SAM bbox prediction! Bbox: {bbox_coords}\")\n",
    "            clear_cuda_cache() # Attempt to clear for next operations\n",
    "            # Consider more drastic recovery or skipping if OOM is frequent\n",
    "        else:\n",
    "            print(f\" SAM bbox prediction runtime error: {e}\")\n",
    "        return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0, \"prediction_failed_runtime_error\"\n",
    "    except Exception as e:\n",
    "        print(f\" SAM bbox prediction failed with unknown error: {e}\")\n",
    "        return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0, \"prediction_failed_unknown_error\"\n",
    "\n",
    "def get_sam_mask_from_points(image_rgb, points_coords, predictor, point_labels=None):\n",
    "    \"\"\"\n",
    "    Generates a segmentation mask using SAM based on point prompts.\n",
    "    Args:\n",
    "        image_rgb (np.ndarray): The input image in RGB format.\n",
    "        points_coords (np.ndarray): Nx2 array of (x,y) point coordinates.\n",
    "        predictor (SamPredictor): The initialized SAM predictor instance.\n",
    "        point_labels (np.ndarray, optional): Nx1 array of labels (1 for foreground, 0 for background). Defaults to all foreground.\n",
    "    Returns:\n",
    "        mask (np.ndarray): Boolean mask, or zeros if failed.\n",
    "        confidence (float): Confidence score of the best mask.\n",
    "    \"\"\"\n",
    "    if predictor is None:\n",
    "        print(\" SAM predictor not available in get_sam_mask_from_points.\")\n",
    "        return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0\n",
    "\n",
    "    if point_labels is None:\n",
    "        point_labels = np.ones(len(points_coords)) # Assume all points are foreground\n",
    "\n",
    "    try:\n",
    "        predictor.set_image(image_rgb)\n",
    "    except Exception as e:\n",
    "        print(f\" SAM predictor.set_image failed in point prediction: {e}\")\n",
    "        return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0\n",
    "\n",
    "    try:\n",
    "        masks, scores, logits = predictor.predict(\n",
    "            point_coords=np.array(points_coords),\n",
    "            point_labels=np.array(point_labels),\n",
    "            box=None,\n",
    "            multimask_output=True,\n",
    "        )\n",
    "\n",
    "        if masks is not None and len(masks) > 0 and scores is not None and len(scores) > 0:\n",
    "            best_idx = np.argmax(scores)\n",
    "            return masks[best_idx], float(scores[best_idx])\n",
    "        else:\n",
    "            print(\"⚠️ SAM predictor.predict returned no masks/scores for points.\")\n",
    "            return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(f\" CUDA Out of Memory during SAM point prediction! Points: {points_coords[:3]}\") # Log first few points\n",
    "            clear_cuda_cache()\n",
    "        else:\n",
    "            print(f\" SAM point prediction runtime error: {e}\")\n",
    "        return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0\n",
    "    except Exception as e:\n",
    "        print(f\" SAM point prediction failed: {e}\")\n",
    "        return np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=bool), 0.0\n",
    "\n",
    "print(\"✓ SAM masking functions defined.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION V: KEYPOINT & ARROW DETECTION\n",
    "# (Functions for advanced prompting strategies for SAM)\n",
    "# ==============================================================================\n",
    "print(\"\\n----------------------------------------------------------------------\")\n",
    "print(\"SECTION V: DEFINING KEYPOINT AND ARROW DETECTION LOGIC\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "def detect_keypoints_and_regions(image_rgb, bbox_coords):\n",
    "    \"\"\"\n",
    "    Detects keypoints (SIFT, FAST, LoG Blobs) and horizontal lines within a given ROI.\n",
    "    Args:\n",
    "        image_rgb (np.ndarray): Full image in RGB.\n",
    "        bbox_coords (tuple): (x, y, w, h) defining the Region of Interest.\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple is (region_type_str, points_array).\n",
    "    \"\"\"\n",
    "    x, y, w, h = map(int, bbox_coords) # Ensure integer coordinates\n",
    "\n",
    "    # Validate ROI coordinates against image dimensions\n",
    "    img_h, img_w = image_rgb.shape[:2]\n",
    "    if x < 0 or y < 0 or w <= 0 or h <= 0 or x + w > img_w or y + h > img_h:\n",
    "        print(f\" Invalid ROI {bbox_coords} for keypoint detection in image of shape {image_rgb.shape}. Skipping.\")\n",
    "        return []\n",
    "\n",
    "    roi = image_rgb[y:y+h, x:x+w]\n",
    "    if roi.size == 0:\n",
    "        print(f\" Empty ROI extracted for keypoint detection with bbox {bbox_coords}. Skipping.\")\n",
    "        return []\n",
    "        \n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n",
    "    detected_regions = []\n",
    "\n",
    "    # 1. SIFT for distinctive points\n",
    "    try:\n",
    "        sift = cv2.SIFT_create()\n",
    "        keypoints_sift = sift.detect(gray_roi, None) # No need for descriptors here\n",
    "        if keypoints_sift:\n",
    "            sift_points = np.array([[kp.pt[0] + x, kp.pt[1] + y] for kp in keypoints_sift[:10]], dtype=int) # Top 10\n",
    "            if sift_points.size > 0:\n",
    "                 detected_regions.append(('sift_points', sift_points))\n",
    "    except Exception as e:\n",
    "        print(f\"SIFT detection failed or unavailable: {e}\")\n",
    "\n",
    "    # 2. LoG blobs (Laplacian of Gaussian) - if scikit-image is available\n",
    "    if SKIMAGE_AVAILABLE:\n",
    "        try:\n",
    "            # Adjust parameters for medical images: may need larger sigma or different threshold\n",
    "            blobs_log = feature.blob_log(gray_roi, max_sigma=20, min_sigma=5, num_sigma=5, threshold=0.05) # Tweaked params\n",
    "            if len(blobs_log) > 0:\n",
    "                # blobs_log returns (y, x, sigma)\n",
    "                blob_points = np.array([[blob[1] + x, blob[0] + y] for blob in blobs_log[:5]], dtype=int) # Top 5\n",
    "                if blob_points.size > 0:\n",
    "                    detected_regions.append(('log_blobs', blob_points))\n",
    "        except Exception as e:\n",
    "            print(f\"ℹ️ LoG Blob detection failed: {e}\")\n",
    "    \n",
    "    # 3. FAST for corners\n",
    "    try:\n",
    "        fast = cv2.FastFeatureDetector_create(threshold=10, nonmaxSuppression=True) # Standard params\n",
    "        keypoints_fast = fast.detect(gray_roi, None)\n",
    "        if keypoints_fast:\n",
    "            fast_points = np.array([[kp.pt[0] + x, kp.pt[1] + y] for kp in keypoints_fast[:8]], dtype=int) # Top 8\n",
    "            if fast_points.size > 0:\n",
    "                detected_regions.append(('fast_corners', fast_points))\n",
    "    except Exception as e:\n",
    "        print(f\" FAST corner detection failed: {e}\")\n",
    "\n",
    "    # 4. Detect horizontal lines (e.g., for fluid levels or flat structures)\n",
    "    try:\n",
    "        edges = cv2.Canny(gray_roi, 50, 150)\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=20, minLineLength=w // 4, maxLineGap=5) # Adjusted threshold & length\n",
    "        if lines is not None:\n",
    "            horizontal_points = []\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "                angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "                if angle < 10 or angle > 170: # More strictly horizontal\n",
    "                    mid_x = (x1 + x2) // 2 + x\n",
    "                    mid_y = (y1 + y2) // 2 + y\n",
    "                    horizontal_points.append([mid_x, mid_y])\n",
    "            if horizontal_points:\n",
    "                detected_regions.append(('horizontal_lines_midpoints', np.array(horizontal_points, dtype=int)))\n",
    "    except Exception as e:\n",
    "        print(f\" Horizontal line detection failed: {e}\")\n",
    "        \n",
    "    # print(f\"Detected regions for bbox {bbox_coords}: {[r[0] for r in detected_regions]}\")\n",
    "    return detected_regions\n",
    "\n",
    "\n",
    "def advanced_arrow_detection(image_rgb, bbox_coords, debug=False):\n",
    "    \"\"\"\n",
    "    Detects arrows within an ROI and estimates their target.\n",
    "    Args:\n",
    "        image_rgb (np.ndarray): Full image in RGB.\n",
    "        bbox_coords (tuple): (x, y, w, h) for the ROI potentially containing an arrow.\n",
    "    Returns:\n",
    "        dict: Information about detected arrow, including 'found', 'target_bbox'.\n",
    "    \"\"\"\n",
    "    x, y, w, h = map(int, bbox_coords)\n",
    "    img_h, img_w = image_rgb.shape[:2]\n",
    "\n",
    "    arrow_info = {\n",
    "        'found': False, 'direction': None, 'target_bbox': bbox_coords, # Default to original bbox\n",
    "        'confidence': 0.0, 'method': 'none'\n",
    "    }\n",
    "\n",
    "    if x < 0 or y < 0 or w <= 0 or h <= 0 or x + w > img_w or y + h > img_h:\n",
    "        if debug: print(f\" Invalid ROI {bbox_coords} for arrow detection. Using original bbox as target.\")\n",
    "        arrow_info['method'] = 'invalid_roi_coords'\n",
    "        return arrow_info\n",
    "        \n",
    "    roi = image_rgb[y:y+h, x:x+w]\n",
    "    if roi.size == 0:\n",
    "        if debug: print(f\" Empty ROI for arrow detection with bbox {bbox_coords}.\")\n",
    "        arrow_info['method'] = 'empty_roi'\n",
    "        return arrow_info\n",
    "\n",
    "    gray_roi = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    try:\n",
    "        # Using Canny and HoughLinesP for line detection\n",
    "        edges = cv2.Canny(gray_roi, 50, 150, apertureSize=3)\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=15, # Threshold for line detection\n",
    "                                minLineLength=max(10, min(w, h) // 4), # Min length relative to ROI size\n",
    "                                maxLineGap=max(5, min(w,h) // 10))     # Max gap relative to ROI size\n",
    "\n",
    "        if lines is not None and len(lines) > 0:\n",
    "            potential_arrows = []\n",
    "            for line_segment in lines:\n",
    "                x1, y1, x2, y2 = line_segment[0]\n",
    "                length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "                # Heuristic: a line is a potential arrow shaft if it's reasonably long within the ROI\n",
    "                if length > min(w, h) * 0.25: # Must be at least 25% of the smaller dimension of ROI\n",
    "                    line_direction = np.array([x2 - x1, y2 - y1]) / length # Normalized direction\n",
    "                    potential_arrows.append({\n",
    "                        'line': (x1, y1, x2, y2), 'length': length, 'direction': line_direction,\n",
    "                        'midpoint': ((x1+x2)/2, (y1+y2)/2)\n",
    "                    })\n",
    "            \n",
    "            if potential_arrows:\n",
    "                # Select the longest line as the primary candidate for an arrow shaft\n",
    "                main_arrow_candidate = max(potential_arrows, key=lambda p: p['length'])\n",
    "                ax1, ay1, ax2, ay2 = main_arrow_candidate['line']\n",
    "                arrow_direction = main_arrow_candidate['direction'] # From (ax1,ay1) to (ax2,ay2)\n",
    "                \n",
    "                # Determine arrow tip: check intensity or structure around line ends (ax2, ay2)\n",
    "                # This part can be complex. For a simpler heuristic:\n",
    "                # Assume (ax2,ay2) is the tip if it's 'sharper' or points towards a change.\n",
    "                # For now, we'll just use the line direction and extend from one end.\n",
    "                # Let's assume the end further from ROI center is part of the shaft, pointing away.\n",
    "                \n",
    "                # Estimate target: extend the line beyond the ROI to find where it points\n",
    "                # The 'target_bbox' should be outside the current 'arrow' bbox.\n",
    "                extension_factor = 1.0 * main_arrow_candidate['length'] # Extend by its own length\n",
    "                \n",
    "                # Tip of the arrow within ROI (local coordinates)\n",
    "                tip_local_x, tip_local_y = ax2, ay2\n",
    "\n",
    "                # Projected point in global image coordinates\n",
    "                target_global_x = x + tip_local_x + arrow_direction[0] * extension_factor\n",
    "                target_global_y = y + tip_local_y + arrow_direction[1] * extension_factor\n",
    "\n",
    "                # Create a new small bounding box around this projected target point\n",
    "                target_box_size = max(20, int(min(w, h) * 0.5)) # Size of the target bbox\n",
    "                \n",
    "                new_target_x = int(target_global_x - target_box_size // 2)\n",
    "                new_target_y = int(target_global_y - target_box_size // 2)\n",
    "                \n",
    "                # Clamp new_target_bbox to image boundaries\n",
    "                new_target_x = max(0, min(new_target_x, img_w - target_box_size))\n",
    "                new_target_y = max(0, min(new_target_y, img_h - target_box_size))\n",
    "                \n",
    "                new_target_bbox = (new_target_x, new_target_y, target_box_size, target_box_size)\n",
    "\n",
    "                arrow_info.update({\n",
    "                    'found': True,\n",
    "                    'direction': arrow_direction.tolist(), # Convert numpy array for JSON serializability if needed\n",
    "                    'target_bbox': new_target_bbox,\n",
    "                    'confidence': min(main_arrow_candidate['length'] / max(1,max(w, h)), 1.0), # Confidence based on relative length\n",
    "                    'method': 'line_detection_heuristic'\n",
    "                })\n",
    "                if debug: print(f\"✓ Arrow detected by line heuristic. Original bbox: {bbox_coords}, Target bbox: {new_target_bbox}, Conf: {arrow_info['confidence']:.2f}\")\n",
    "    except Exception as e:\n",
    "        if debug: print(f\"Arrow detection (line method) failed for bbox {bbox_coords}: {e}\")\n",
    "        arrow_info['method'] = 'line_detection_exception'\n",
    "\n",
    "    return arrow_info\n",
    "\n",
    "\n",
    "def correct_directional_labels(label_text, bbox_coords, image_width):\n",
    "    \"\"\"\n",
    "    Corrects directional terms (left/right) in labels based on the bbox's horizontal position.\n",
    "    Assumes standard anatomical view (image left is patient's right).\n",
    "    \"\"\"\n",
    "    x, _, w, _ = bbox_coords\n",
    "    center_x = x + w / 2.0\n",
    "    \n",
    "    # Determine if the bbox is on the image's left or right side\n",
    "    # This corresponds to patient's right or left side respectively.\n",
    "    image_side_is_left = center_x < image_width / 2.0 # Bbox is on the left side of the image\n",
    "\n",
    "    corrected_label = label_text # Start with original label\n",
    "    label_lower = label_text.lower()\n",
    "\n",
    "    # If label says \"right\" but bbox is on image's left side (patient's right) -> No change needed for 'right'\n",
    "    # If label says \"left\" but bbox is on image's right side (patient's left) -> No change needed for 'left'\n",
    "\n",
    "    # Corrections are needed if label mismatches anatomical position relative to image sides\n",
    "    if \"right\" in label_lower and not image_side_is_left: # Label \"right\", bbox on image's right (patient's left)\n",
    "        corrected_label = label_text.replace(\"right\", \"left\").replace(\"Right\", \"Left\")\n",
    "        print(f\"Directional label correction: '{label_text}' -> '{corrected_label}' (bbox on image right, implies patient left)\")\n",
    "    elif \"left\" in label_lower and image_side_is_left: # Label \"left\", bbox on image's left (patient's right)\n",
    "        corrected_label = label_text.replace(\"left\", \"right\").replace(\"Left\", \"Right\")\n",
    "        print(f\" Directional label correction: '{label_text}' -> '{corrected_label}' (bbox on image left, implies patient right)\")\n",
    "    # Similar logic for other languages if needed (e.g., \"derecha\", \"izquierda\")\n",
    "\n",
    "    return corrected_label.title() # Return title-cased\n",
    "\n",
    "\n",
    "# This is the refined SAM mask selection logic from your original PART 6\n",
    "def sam_with_intelligent_arrow_following(image_rgb, bbox_coords, predictor, label_text, debug=False):\n",
    "    \"\"\"\n",
    "    Enhanced SAM processing: Tries direct bbox, then arrow following if confidence is low,\n",
    "    then keypoint-based prompting. Returns the best mask found.\n",
    "    \"\"\"\n",
    "    # 1. Try SAM with the original bounding box\n",
    "    if debug: print(f\"Attempting SAM for '{label_text}' with original bbox: {bbox_coords}\")\n",
    "    original_mask, original_conf, strategy_msg = get_sam_mask_from_bbox(image_rgb, bbox_coords, predictor)\n",
    "    \n",
    "    best_mask = original_mask\n",
    "    best_conf = original_conf\n",
    "    best_strategy = f\"original_bbox ({strategy_msg})\"\n",
    "\n",
    "    if debug: print(f\"  Original bbox SAM: conf={original_conf:.3f}, strategy='{best_strategy}'\")\n",
    "\n",
    "    # 2. If confidence is low, try arrow detection and follow-up SAM\n",
    "    # Threshold for \"low confidence\" can be tuned.\n",
    "    arrow_strategy_applied = False\n",
    "    if best_conf < 0.75: # Confidence threshold to trigger arrow/keypoint strategies\n",
    "        if debug: print(f\"  Low confidence ({best_conf:.3f}) for '{label_text}'. Trying arrow detection from bbox: {bbox_coords}\")\n",
    "        arrow_info = advanced_arrow_detection(image_rgb, bbox_coords, debug=debug)\n",
    "        \n",
    "        if arrow_info['found'] and arrow_info['target_bbox'] != bbox_coords: # Ensure target is different\n",
    "            arrow_strategy_applied = True\n",
    "            if debug: print(f\"  Arrow found for '{label_text}', method: {arrow_info['method']}. New target bbox: {arrow_info['target_bbox']}\")\n",
    "            \n",
    "            arrow_target_mask, arrow_target_conf, arrow_strategy_msg = get_sam_mask_from_bbox(image_rgb, arrow_info['target_bbox'], predictor)\n",
    "            \n",
    "            # Boost confidence slightly if arrow logic was successful in finding a plausible target\n",
    "            adjusted_arrow_conf = arrow_target_conf * (1.0 + arrow_info['confidence'] * 0.2) # Modest boost\n",
    "            \n",
    "            if debug: print(f\"    SAM on arrow target: conf={arrow_target_conf:.3f} (adjusted: {adjusted_arrow_conf:.3f})\")\n",
    "            if adjusted_arrow_conf > best_conf:\n",
    "                best_mask = arrow_target_mask\n",
    "                best_conf = adjusted_arrow_conf\n",
    "                best_strategy = f\"arrow_followed_{arrow_info['method']}_{arrow_strategy_msg}\"\n",
    "                if debug: print(f\"    Selected arrow strategy for '{label_text}' with new conf: {best_conf:.3f}\")\n",
    "\n",
    "    # 3. Try keypoint-based SAM prompting, regardless of arrow outcome if initial conf was low, or if arrow didn't improve much\n",
    "    # Only try keypoints if initial confidence is still not great\n",
    "    if best_conf < 0.80: # If still not highly confident\n",
    "        if debug: print(f\"  Confidence for '{label_text}' still potentially low ({best_conf:.3f}). Trying keypoint strategies from bbox: {bbox_coords}\")\n",
    "        detected_keypoint_regions = detect_keypoints_and_regions(image_rgb, bbox_coords)\n",
    "        \n",
    "        keypoint_strategy_applied_successfully = False\n",
    "        for region_type, points_array in detected_keypoint_regions:\n",
    "            if points_array.ndim == 2 and points_array.shape[0] > 0: # Ensure valid points\n",
    "                if debug: print(f\"    Trying SAM with '{region_type}' ({len(points_array)} points) for '{label_text}'\")\n",
    "                try:\n",
    "                    # Using points requires predictor instance\n",
    "                    keypoint_mask, keypoint_conf = get_sam_mask_from_points(image_rgb, points_array, predictor)\n",
    "                    if debug: print(f\"      SAM with '{region_type}': conf={keypoint_conf:.3f}\")\n",
    "                    \n",
    "                    if keypoint_conf > best_conf:\n",
    "                        best_mask = keypoint_mask\n",
    "                        best_conf = keypoint_conf\n",
    "                        best_strategy = f\"keypoints_{region_type}\"\n",
    "                        keypoint_strategy_applied_successfully = True\n",
    "                        if debug: print(f\"      Selected keypoint strategy '{region_type}' for '{label_text}' with new conf: {best_conf:.3f}\")\n",
    "                except Exception as e_kp:\n",
    "                    if debug: print(f\"      Error during SAM with '{region_type}' points: {e_kp}\")\n",
    "            else:\n",
    "                if debug: print(f\"    Skipping '{region_type}' for '{label_text}' due to no/invalid points.\")\n",
    "        if keypoint_strategy_applied_successfully and debug:\n",
    "             print(f\"  Keypoint strategy improved mask for '{label_text}'.\")\n",
    "\n",
    "\n",
    "    if debug: print(f\"  Final best strategy for '{label_text}': {best_strategy}, Final best conf: {best_conf:.3f}\")\n",
    "    return best_mask, best_conf, best_strategy\n",
    "\n",
    "\n",
    "# This is the main mask selection function from your original PART 6, renamed slightly for clarity.\n",
    "def select_best_mask_for_label_advanced(image_rgb, bbox_coords, predictor, label_text, image_id_for_heatmaps=None, export_heatmaps_flag=True):\n",
    "    \"\"\"\n",
    "    Selects the best SAM mask using intelligent strategies (direct bbox, arrow following, keypoints).\n",
    "    Optionally generates and saves heatmaps for good detections.\n",
    "    Args:\n",
    "        image_id_for_heatmaps: If provided, used in naming saved heatmaps.\n",
    "        export_heatmaps_flag: Boolean to control heatmap generation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mask, confidence, strategy = sam_with_intelligent_arrow_following(\n",
    "            image_rgb, bbox_coords, predictor, label_text, debug=True # Enable debug for detailed logs\n",
    "        )\n",
    "        \n",
    "        # Generate and save heatmaps only for masks with reasonable confidence\n",
    "        if export_heatmaps_flag and confidence > 0.6 and image_id_for_heatmaps is not None:\n",
    "            print(f\"  Generating useful heatmap for '{label_text}' (Image: {image_id_for_heatmaps}, Conf: {confidence:.2f})\")\n",
    "            # Ensure generate_useful_heatmap_analysis is defined and works as intended.\n",
    "            # This function was in your PART 6.\n",
    "            generate_useful_heatmap_analysis(image_rgb, bbox_coords, mask, confidence, label_text, image_id_for_heatmaps, OUTPUT_DIR)\n",
    "        \n",
    "        return mask, confidence, strategy\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error in advanced mask selection for '{label_text}': {e}\")\n",
    "        # Fallback to basic SAM if advanced fails catastrophically\n",
    "        try:\n",
    "            print(f\"  Falling back to basic bbox SAM for '{label_text}' due to error.\")\n",
    "            mask, confidence, strategy_msg = get_sam_mask_from_bbox(image_rgb, bbox_coords, predictor)\n",
    "            return mask, confidence, f\"fallback_basic_bbox ({strategy_msg})\"\n",
    "        except Exception as e2:\n",
    "            print(f\" Basic fallback SAM also failed for '{label_text}': {e2}\")\n",
    "            h_img, w_img = image_rgb.shape[:2]\n",
    "            return np.zeros((h_img, w_img), dtype=bool), 0.0, \"error_no_mask_generated\"\n",
    "\n",
    "print(\"✓ Keypoint, Arrow Detection, and Advanced Mask Selection functions defined.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION VI: YOLO ENHANCEMENT FUNCTIONS\n",
    "# (Using YOLO for object detection, currently runs on CPU)\n",
    "# ==============================================================================\n",
    "print(\"\\n----------------------------------------------------------------------\")\n",
    "print(\"SECTION VI: DEFINING YOLO ENHANCEMENT LOGIC\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "# --- Heatmap Generation ---\n",
    "def generate_useful_heatmap_analysis(image_rgb, bbox_coords, mask_array, confidence_score, label_text, image_id_str, base_output_dir):\n",
    "    \"\"\"\n",
    "    Generates and SAVES a 4-panel analysis image: Original+BBox, Detected Mask, Mask Overlay, ROI.\n",
    "    This version is for saving analysis, not immediate display.\n",
    "    Args:\n",
    "        base_output_dir: The main output directory for the script. Heatmaps go into a subfolder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x, y, w, h = map(int, bbox_coords) # Ensure integer coordinates\n",
    "\n",
    "        # Create a dedicated heatmap directory if it doesn't exist\n",
    "        heatmap_output_dir = os.path.join(base_output_dir, \"heatmaps_and_masks\", str(image_id_str))\n",
    "        os.makedirs(heatmap_output_dir, exist_ok=True)\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10)) # Slightly smaller for individual saves\n",
    "        fig.suptitle(f'Mask Analysis: {image_id_str} - {label_text}\\n(Conf: {confidence_score:.3f})', fontsize=14)\n",
    "\n",
    "        # 1. Original image with BBox\n",
    "        axes[0, 0].imshow(image_rgb)\n",
    "        rect_patch = Rectangle((x, y), w, h, linewidth=2, edgecolor='red', facecolor='none')\n",
    "        axes[0, 0].add_patch(rect_patch)\n",
    "        axes[0, 0].set_title('Original Image + BBox')\n",
    "        axes[0, 0].axis('off')\n",
    "\n",
    "        # 2. Detected Mask\n",
    "        axes[0, 1].imshow(mask_array, cmap='viridis') # 'viridis' is often good for masks\n",
    "        axes[0, 1].set_title(f'Detected Mask')\n",
    "        axes[0, 1].axis('off')\n",
    "\n",
    "        # 3. Mask Overlay on image\n",
    "        overlay_img = image_rgb.copy()\n",
    "        # Ensure mask_array is boolean for indexing\n",
    "        boolean_mask = mask_array.astype(bool)\n",
    "        # Apply a distinct color to the mask region, e.g., semi-transparent red\n",
    "        overlay_color = np.array([255, 0, 0], dtype=np.uint8) # Red\n",
    "        # Blend where mask is true\n",
    "        overlay_img[boolean_mask] = cv2.addWeighted(overlay_img[boolean_mask], 0.5, overlay_color, 0.5, 0)\n",
    "        axes[1, 0].imshow(overlay_img)\n",
    "        axes[1, 0].set_title('Mask Overlay')\n",
    "        axes[1, 0].axis('off')\n",
    "\n",
    "        # 4. Region of Interest (ROI) from original image\n",
    "        # Clamp ROI coordinates to be within image bounds\n",
    "        roi_x_end = min(x + w, image_rgb.shape[1])\n",
    "        roi_y_end = min(y + h, image_rgb.shape[0])\n",
    "        roi_x_start = max(0, x)\n",
    "        roi_y_start = max(0, y)\n",
    "\n",
    "        if roi_x_end > roi_x_start and roi_y_end > roi_y_start:\n",
    "             roi_img = image_rgb[roi_y_start:roi_y_end, roi_x_start:roi_x_end]\n",
    "             axes[1, 1].imshow(roi_img)\n",
    "        else:\n",
    "            axes[1,1].text(0.5, 0.5, \"Invalid ROI dims\", ha='center', va='center')\n",
    "        axes[1, 1].set_title('Region of Interest')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust for suptitle\n",
    "        \n",
    "        # Sanitize label_text for filename\n",
    "        safe_label_text = \"\".join(c if c.isalnum() else \"_\" for c in label_text)\n",
    "        heatmap_filename = f\"mask_analysis_{image_id_str}_{safe_label_text}.png\"\n",
    "        heatmap_save_path = os.path.join(heatmap_output_dir, heatmap_filename)\n",
    "        \n",
    "        plt.savefig(heatmap_save_path, dpi=100) # Lower DPI for individual diagnostic images\n",
    "        plt.close(fig) # Close the figure to free memory and prevent display\n",
    "        # print(f\"  ✓ Saved mask analysis: {heatmap_save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error generating 'useful heatmap analysis' for {label_text} on {image_id_str}: {e}\")\n",
    "        if 'fig' in locals() and fig is not None: # Ensure figure is closed on error\n",
    "            plt.close(fig)\n",
    "\n",
    "def calculate_bbox_iou(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two bounding boxes.\n",
    "    Assumes box format: [x1, y1, x2, y2] or can be adapted for (x,y,w,h)\n",
    "    Let's assume input dicts like {'x': x, 'y': y, 'width': w, 'height': h} as used later.\n",
    "    \"\"\"\n",
    "    # Convert to (x1, y1, x2, y2)\n",
    "    b1_x1, b1_y1 = boxA['x'], boxA['y']\n",
    "    b1_x2, b1_y2 = boxA['x'] + boxA['width'], boxA['y'] + boxA['height']\n",
    "    \n",
    "    b2_x1, b2_y1 = boxB['x'], boxB['y']\n",
    "    b2_x2, b2_y2 = boxB['x'] + boxB['width'], boxB['y'] + boxB['height']\n",
    "\n",
    "    # Determine the (x, y)-coordinates of the intersection rectangle\n",
    "    x_A = max(b1_x1, b2_x1)\n",
    "    y_A = max(b1_y1, b2_y1)\n",
    "    x_B = min(b1_x2, b2_x2)\n",
    "    y_B = min(b1_y2, b2_y2)\n",
    "\n",
    "    # Compute the area of intersection rectangle\n",
    "    interArea = max(0, x_B - x_A) * max(0, y_B - y_A)\n",
    "\n",
    "    # Compute the area of both the prediction and ground-truth rectangles\n",
    "    boxAArea = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
    "    boxBArea = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
    "    \n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea + 1e-6) # Add epsilon for stability\n",
    "    return iou\n",
    "\n",
    "def enhanced_yolo_detection(image_rgb, existing_sam_bboxes_list, confidence_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Performs object detection using YOLOv8n on CPU.\n",
    "    Filters detections based on confidence and non-overlap with existing SAM bboxes.\n",
    "    Args:\n",
    "        image_rgb (np.ndarray): Input image.\n",
    "        existing_sam_bboxes_list (list of dicts): List of bboxes from SAM, \n",
    "                                                  each dict like {'x': x, 'y': y, 'width': w, 'height': h, 'label': label}.\n",
    "        confidence_threshold (float): Minimum confidence for YOLO detections.\n",
    "    Returns:\n",
    "        list: List of new bounding boxes detected by YOLO.\n",
    "    \"\"\"\n",
    "    if not YOLO_AVAILABLE:\n",
    "        print(\" YOLO not available, skipping YOLO detection.\")\n",
    "        return []\n",
    "\n",
    "    # clear_cuda_cache() # YOLO is on CPU, so less critical here, but good if other GPU ops preceded.\n",
    "    \n",
    "    yolo_model_name = 'yolov8n.pt' # Nano model, good for speed/CPU\n",
    "    newly_detected_bboxes_by_yolo = []\n",
    "\n",
    "    try:\n",
    "        model = ultralytics.YOLO(yolo_model_name)\n",
    "        print(f\"✓ YOLO model '{yolo_model_name}' loaded for CPU detection.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to load YOLO model '{yolo_model_name}': {e}\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        # Perform detection on CPU as per your original script\n",
    "        # Using with torch.no_grad() is good practice for any PyTorch inference\n",
    "        with torch.no_grad():\n",
    "            results = model(image_rgb, conf=confidence_threshold, verbose=False, device='cpu')\n",
    "        \n",
    "        if results and results[0].boxes is not None:\n",
    "            yolo_boxes = results[0].boxes.xywh.cpu().numpy() # x_center, y_center, width, height\n",
    "            yolo_confs = results[0].boxes.conf.cpu().numpy()\n",
    "            yolo_classes = results[0].boxes.cls.cpu().numpy()\n",
    "            class_names = results[0].names # Dictionary of class_id: class_name\n",
    "\n",
    "            for i in range(len(yolo_boxes)):\n",
    "                if yolo_confs[i] >= confidence_threshold:\n",
    "                    xc, yc, w, h = yolo_boxes[i]\n",
    "                    x1 = int(xc - w / 2)\n",
    "                    y1 = int(yc - h / 2)\n",
    "                    w = int(w)\n",
    "                    h = int(h)\n",
    "                    \n",
    "                    yolo_bbox_dict = {\n",
    "                        'x': x1, 'y': y1, 'width': w, 'height': h,\n",
    "                        'confidence': float(yolo_confs[i]),\n",
    "                        'class_id': int(yolo_classes[i]),\n",
    "                        'label': class_names[int(yolo_classes[i])] # Get class name\n",
    "                    }\n",
    "\n",
    "                    # Check for significant overlap with any existing SAM bbox\n",
    "                    is_new_detection = True\n",
    "                    if existing_sam_bboxes_list: # Only check if there are SAM bboxes\n",
    "                        for sam_bbox in existing_sam_bboxes_list:\n",
    "                            # Ensure sam_bbox has width and height keys\n",
    "                            if 'width' in sam_bbox and 'height' in sam_bbox :\n",
    "                                if calculate_bbox_iou(yolo_bbox_dict, sam_bbox) > 0.5: # IoU threshold for \"overlap\"\n",
    "                                    is_new_detection = False\n",
    "                                    break\n",
    "                            else:\n",
    "                                print(f\"Warning: SAM bbox missing width/height: {sam_bbox.get('label', 'Unknown Label')}\")\n",
    "\n",
    "\n",
    "                    if is_new_detection:\n",
    "                        newly_detected_bboxes_by_yolo.append(yolo_bbox_dict)\n",
    "                        # print(f\"  ✓ YOLO found new object: {yolo_bbox_dict['label']} (Conf: {yolo_bbox_dict['confidence']:.2f})\")\n",
    "            if newly_detected_bboxes_by_yolo:\n",
    "                 print(f\"✓ YOLO detection complete. Found {len(newly_detected_bboxes_by_yolo)} new, non-overlapping objects.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error during YOLO detection process: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return newly_detected_bboxes_by_yolo\n",
    "\n",
    "\n",
    "def refine_sam_data_with_yolo(image_id, image_rgb, current_sam_data_df):\n",
    "    \"\"\"\n",
    "    Takes SAM detections (as a DataFrame) for an image, runs YOLO,\n",
    "    and adds new, non-overlapping YOLO detections to the DataFrame.\n",
    "    Args:\n",
    "        image_id (str/int): The ID of the image.\n",
    "        image_rgb (np.ndarray): The image.\n",
    "        current_sam_data_df (pd.DataFrame): DataFrame of SAM detections for this image.\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with SAM + new YOLO detections.\n",
    "    \"\"\"\n",
    "    if not YOLO_AVAILABLE:\n",
    "        # print(\" YOLO not available, returning original SAM data.\")\n",
    "        return current_sam_data_df.copy() # Return a copy to avoid modifying original df outside\n",
    "\n",
    "    # Convert SAM DataFrame rows to list of dicts for overlap checking\n",
    "    existing_sam_bboxes_list = []\n",
    "    if not current_sam_data_df.empty:\n",
    "        for _, row in current_sam_data_df.iterrows():\n",
    "            existing_sam_bboxes_list.append({\n",
    "                'x': int(row['x']), 'y': int(row['y']),\n",
    "                'width': int(row['width']), 'height': int(row['height']),\n",
    "                'label': row['Label'] # For potential debugging\n",
    "            })\n",
    "    \n",
    "    yolo_added_detections = enhanced_yolo_detection(image_rgb, existing_sam_bboxes_list)\n",
    "    \n",
    "    if not yolo_added_detections:\n",
    "        return current_sam_data_df.copy()\n",
    "\n",
    "    yolo_rows_to_add = []\n",
    "    for det in yolo_added_detections:\n",
    "        new_row = {\n",
    "            'ImageID': image_id, # Ensure consistent ImageID\n",
    "            'Label': f\"YOLO_{det['label']}\", # Prefix to distinguish from SAM labels\n",
    "            'x': det['x'], 'y': det['y'],\n",
    "            'width': det['width'], 'height': det['height'],\n",
    "            # Optionally add YOLO confidence or class_id if your DataFrame schema supports it\n",
    "            # 'confidence': det['confidence'] \n",
    "        }\n",
    "        yolo_rows_to_add.append(new_row)\n",
    "    \n",
    "    if yolo_rows_to_add:\n",
    "        yolo_df_to_add = pd.DataFrame(yolo_rows_to_add)\n",
    "        updated_df = pd.concat([current_sam_data_df, yolo_df_to_add], ignore_index=True)\n",
    "        print(f\"✓ Added {len(yolo_added_detections)} new detections from YOLO to ImageID {image_id}.\")\n",
    "        return updated_df\n",
    "    else:\n",
    "        return current_sam_data_df.copy()\n",
    "\n",
    "print(\"✓ YOLO Enhancement functions defined.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION VII: VISUALIZATION & REPORTING UTILITIES\n",
    "# ==============================================================================\n",
    "print(\"\\n----------------------------------------------------------------------\")\n",
    "print(\"SECTION VII: DEFINING VISUALIZATION AND REPORTING UTILITIES\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This is the 4-panel display function from \"Headmaps Visualization\" (original script)\n",
    "# It is for *showing* a detailed heatmap, potentially interactively in a notebook.\n",
    "def generate_comprehensive_heatmap_display(image_rgb, bbox_coords, mask_array, confidence_score, label_text, image_id_str, base_output_dir, show_plot=False):\n",
    "    \"\"\"\n",
    "    Generates and optionally SHOWS/SAVES a comprehensive 4-panel heatmap (Original+BBox, Probability-like Heatmap, Overlay, 3D Surface).\n",
    "    Note: The \"probability-like heatmap\" and \"3D surface\" are derived from confidence and bbox, not directly from SAM's internal heatmaps.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x, y, w, h = map(int, bbox_coords)\n",
    "        heatmap_output_dir = os.path.join(base_output_dir, \"detailed_heatmaps\", str(image_id_str))\n",
    "        os.makedirs(heatmap_output_dir, exist_ok=True)\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 12)) # Larger figure for detailed display\n",
    "        fig.suptitle(f'Detailed Heatmap Analysis: {image_id_str} - {label_text}\\n(Confidence: {confidence_score:.3f})', fontsize=16, fontweight='bold')\n",
    "\n",
    "        # Panel 1: Original image with BBox\n",
    "        ax1 = fig.add_subplot(2, 2, 1)\n",
    "        ax1.imshow(image_rgb)\n",
    "        rect1 = Rectangle((x, y), w, h, linewidth=3, edgecolor='red', facecolor='none')\n",
    "        ax1.add_patch(rect1)\n",
    "        ax1.set_title('Original Image with BBox', fontsize=12)\n",
    "        ax1.axis('off')\n",
    "\n",
    "        # Panel 2: \"Probability\" Heatmap (Gaussian-like based on bbox and confidence)\n",
    "        ax2 = fig.add_subplot(2, 2, 2)\n",
    "        # Create a simple heatmap centered on the bbox, scaled by confidence\n",
    "        prob_heatmap = np.zeros((image_rgb.shape[0], image_rgb.shape[1]))\n",
    "        center_x, center_y = x + w // 2, y + h // 2\n",
    "        # Create a grid of coordinates\n",
    "        yy, xx = np.mgrid[0:image_rgb.shape[0], 0:image_rgb.shape[1]]\n",
    "        # Calculate squared distance from center, apply Gaussian-like decay\n",
    "        # Sigma can be a fraction of bbox size\n",
    "        sigma_x = max(1, w / 4.0)\n",
    "        sigma_y = max(1, h / 4.0)\n",
    "        dist_sq = ((xx - center_x) / sigma_x)**2 + ((yy - center_y) / sigma_y)**2\n",
    "        prob_heatmap = confidence_score * np.exp(-dist_sq / 2.0)\n",
    "        # Ensure it's zero outside a slightly larger bbox area for clarity\n",
    "        mask_area = np.zeros_like(prob_heatmap, dtype=bool)\n",
    "        ext_x, ext_y, ext_w, ext_h = x - w//2, y - h//2, w*2, h*2 # Extended area\n",
    "        mask_area[max(0,ext_y):min(image_rgb.shape[0],ext_y+ext_h), max(0,ext_x):min(image_rgb.shape[1],ext_x+ext_w)] = True\n",
    "        prob_heatmap[~mask_area] = 0\n",
    "\n",
    "\n",
    "        im = ax2.imshow(prob_heatmap, cmap='hot', vmin=0, vmax=max(0.01, confidence_score)) # Ensure vmax is not 0\n",
    "        ax2.set_title('Conceptual Probability Heatmap', fontsize=12)\n",
    "        ax2.axis('off')\n",
    "        cbar = plt.colorbar(im, ax=ax2, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Conceptual \"Probability\"', rotation=270, labelpad=15)\n",
    "\n",
    "        # Panel 3: Heatmap Overlay\n",
    "        ax3 = fig.add_subplot(2, 2, 3)\n",
    "        overlay_img_detailed = image_rgb.astype(float) / 255.0 # Normalize for blending\n",
    "        hot_cmap = plt.get_cmap('hot')\n",
    "        # Blend the conceptual heatmap onto the image\n",
    "        for i in range(3): # For R, G, B channels\n",
    "            overlay_img_detailed[:,:,i] = overlay_img_detailed[:,:,i] * (1 - prob_heatmap*0.7) + hot_cmap(prob_heatmap)[:,:,i] * prob_heatmap*0.7\n",
    "        overlay_img_detailed = np.clip(overlay_img_detailed, 0, 1)\n",
    "        ax3.imshow(overlay_img_detailed)\n",
    "        ax3.set_title('Heatmap Overlay (Conceptual)', fontsize=12)\n",
    "        ax3.axis('off')\n",
    "\n",
    "        # Panel 4: 3D Heatmap Surface (of the conceptual heatmap)\n",
    "        ax4 = fig.add_subplot(2, 2, 4, projection='3d')\n",
    "        # Create a meshgrid for the ROI to plot\n",
    "        roi_x_coords = np.arange(max(0, x - w//2), min(image_rgb.shape[1], x + w + w//2))\n",
    "        roi_y_coords = np.arange(max(0, y - h//2), min(image_rgb.shape[0], y + h + h//2))\n",
    "\n",
    "        if len(roi_x_coords) > 1 and len(roi_y_coords) > 1:\n",
    "            X_3d, Y_3d = np.meshgrid(roi_x_coords, roi_y_coords)\n",
    "            # Z_3d is the conceptual heatmap values in this ROI\n",
    "            Z_3d = prob_heatmap[Y_3d, X_3d] # Indexing: Y_3d gives row indices, X_3d column indices\n",
    "            ax4.plot_surface(X_3d, Y_3d, Z_3d, cmap='hot', edgecolor='none', alpha=0.8)\n",
    "            ax4.set_title('3D Heatmap Surface (Conceptual)', fontsize=10)\n",
    "            ax4.set_xlabel('X', fontsize=8); ax4.set_ylabel('Y', fontsize=8); ax4.set_zlabel('Prob', fontsize=8)\n",
    "            ax4.tick_params(axis='both', which='major', labelsize=6)\n",
    "        else:\n",
    "            ax4.text(0.5,0.5,0.5, \"ROI too small for 3D plot\", ha='center', va='center')\n",
    "\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95]) # Adjust for suptitle\n",
    "\n",
    "        safe_label_text = \"\".join(c if c.isalnum() else \"_\" for c in label_text)\n",
    "        detailed_heatmap_filename = f\"detailed_heatmap_display_{image_id_str}_{safe_label_text}.png\"\n",
    "        detailed_heatmap_save_path = os.path.join(heatmap_output_dir, detailed_heatmap_filename)\n",
    "        plt.savefig(detailed_heatmap_save_path, dpi=150) # Higher DPI for this one\n",
    "        \n",
    "        if show_plot:\n",
    "            plt.show() # Display if requested\n",
    "        \n",
    "        plt.close(fig) # Always close to free memory\n",
    "        print(f\"  ✓ Saved detailed heatmap display: {detailed_heatmap_save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error generating comprehensive heatmap display for {label_text} on {image_id_str}: {e}\")\n",
    "        if 'fig' in locals() and fig is not None:\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "# --- Main Result Visualization ---\n",
    "def create_legend_for_main_plot(label_colors_dict, ax_to_add_legend):\n",
    "    \"\"\"Creates a legend for anatomical labels on the main visualization plot.\"\"\"\n",
    "    legend_elements = []\n",
    "    sorted_labels = sorted(label_colors_dict.keys()) # Sort for consistent legend order\n",
    "\n",
    "    for label in sorted_labels:\n",
    "        color_hex = label_colors_dict[label]\n",
    "        color_rgb_mpl = hex_to_rgb(color_hex) # For Matplotlib (0-1 range)\n",
    "        legend_elements.append(\n",
    "            Rectangle((0, 0), 1, 1, facecolor=color_rgb_mpl, edgecolor='black', linewidth=0.5, label=label)\n",
    "        )\n",
    "    \n",
    "    if legend_elements:\n",
    "        ax_to_add_legend.legend(\n",
    "            handles=legend_elements, loc='upper left', bbox_to_anchor=(1.01, 1.0), # Place outside plot area\n",
    "            fontsize=8, frameon=True, fancybox=True, shadow=False, title=\"Detected Structures\", title_fontsize=10\n",
    "        )\n",
    "\n",
    "def create_clean_visualization_with_labels(image_rgb_original, sam_data_df_for_image, label_colors_map, confidence_scores_map):\n",
    "    \"\"\"\n",
    "    Creates a clean visualization with bounding boxes and labels (including confidence).\n",
    "    Returns an image with annotations drawn using OpenCV.\n",
    "    \"\"\"\n",
    "    display_image_cv = image_rgb_original.copy() # Work on a copy\n",
    "    \n",
    "    # Group by label to handle multiple bboxes for the same structure if any (e.g. from YOLO vs SAM)\n",
    "    # However, the logic in process_medical_analysis_ultimate seems to consolidate this to one best per label.\n",
    "    # This function will draw all bboxes present in sam_data_df_for_image for the given labels.\n",
    "    \n",
    "    if sam_data_df_for_image.empty:\n",
    "        return display_image_cv # Return original if no data\n",
    "\n",
    "    unique_labels_in_data = sam_data_df_for_image['Label'].unique()\n",
    "\n",
    "    for original_label_from_df in unique_labels_in_data:\n",
    "        # The label in label_colors_map and confidence_scores_map might be the 'cleaned_label'\n",
    "        # We need to ensure we map correctly. Assuming the sam_data_df_for_image already has the final labels\n",
    "        # that match keys in label_colors_map and confidence_scores_map.\n",
    "        # If not, we might need to clean original_label_from_df here too. For now, assume direct match.\n",
    "        \n",
    "        label_to_use = original_label_from_df # This should be the key for colors/scores\n",
    "\n",
    "        if label_to_use in label_colors_map and label_to_use in confidence_scores_map:\n",
    "            color_hex = label_colors_map[label_to_use]\n",
    "            # Convert hex to BGR for OpenCV (matplotlib uses RGB 0-1, OpenCV BGR 0-255)\n",
    "            color_bgr_cv = [int(c * 255) for c in reversed(hex_to_rgb(color_hex))] # Reversed for BGR\n",
    "            confidence = confidence_scores_map[label_to_use]\n",
    "\n",
    "            # Get all bboxes for this label from the DataFrame\n",
    "            bboxes_for_label_df = sam_data_df_for_image[sam_data_df_for_image['Label'] == original_label_from_df]\n",
    "\n",
    "            for _, row_bbox in bboxes_for_label_df.iterrows():\n",
    "                x, y, w, h = int(row_bbox['x']), int(row_bbox['y']), int(row_bbox['width']), int(row_bbox['height'])\n",
    "\n",
    "                # Clamp bbox to image dimensions before drawing to avoid OpenCV errors\n",
    "                img_h_cv, img_w_cv = display_image_cv.shape[:2]\n",
    "                x1_cv = max(0, x)\n",
    "                y1_cv = max(0, y)\n",
    "                x2_cv = min(img_w_cv -1 , x + w)\n",
    "                y2_cv = min(img_h_cv -1 , y + h)\n",
    "\n",
    "                if x2_cv <= x1_cv or y2_cv <= y1_cv: continue # Skip if bbox is invalid after clamping\n",
    "\n",
    "\n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(display_image_cv, (x1_cv, y1_cv), (x2_cv, y2_cv), color_bgr_cv, 2) # Thickness 2\n",
    "\n",
    "                # Prepare text for label\n",
    "                label_text_cv = f\"{label_to_use}\"\n",
    "                font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.45\n",
    "                font_thickness = 1\n",
    "\n",
    "                (text_w, text_h), baseline = cv2.getTextSize(label_text_cv, font_face, font_scale, font_thickness)\n",
    "                \n",
    "                # Position for text background and text\n",
    "                text_bg_y1 = y1_cv - text_h - 10 if y1_cv > text_h + 15 else y2_cv + baseline + 5\n",
    "                text_bg_y2 = text_bg_y1 + text_h + baseline + 5\n",
    "                text_x_cv = x1_cv\n",
    "                text_y_cv = text_bg_y1 + text_h + baseline // 2 # Centered vertically in bg\n",
    "\n",
    "                # Draw text background rectangle (slightly transparent if possible, or solid)\n",
    "                # For solid background:\n",
    "                cv2.rectangle(display_image_cv, (text_x_cv - 2, text_bg_y1 -2), (text_x_cv + text_w + 2, text_bg_y2 +2 ), color_bgr_cv, -1)\n",
    "                # Draw text\n",
    "                cv2.putText(display_image_cv, label_text_cv, (text_x_cv, text_y_cv),\n",
    "                            font_face, font_scale, (255, 255, 255), font_thickness, cv2.LINE_AA) # White text\n",
    "    return display_image_cv\n",
    "\n",
    "\n",
    "def create_improved_caption_subplot(fig_main, caption_text_main, label_colors_for_caption, grid_spec_rows=12):\n",
    "    \"\"\"\n",
    "    Creates a dedicated subplot on the main figure for displaying an explainable caption\n",
    "    and detected medical structures.\n",
    "    Args:\n",
    "        fig_main: The main matplotlib Figure object.\n",
    "        caption_text_main: The primary caption string.\n",
    "        label_colors_for_caption: Dict of {label_name: hex_color}.\n",
    "        grid_spec_rows: Total rows in the GridSpec for positioning.\n",
    "    \"\"\"\n",
    "    # This assumes fig_main uses a GridSpec. If not, plt.subplot or fig.add_axes might be used.\n",
    "    # Example positioning: occupies bottom part of a 12-row grid.\n",
    "    # caption_ax = fig_main.add_subplot(grid_spec_rows, 1, (grid_spec_rows - 3, grid_spec_rows)) # Last 3 rows\n",
    "    # Using add_axes for more direct control relative to figure [left, bottom, width, height]\n",
    "    caption_ax = fig_main.add_axes([0.05, 0.02, 0.9, 0.15]) # Adjust these ratios as needed\n",
    "    caption_ax.axis('off')\n",
    "\n",
    "    # Title for the caption section\n",
    "    caption_ax.text(0.01, 0.90, \"Explainable Medical Image Report\", transform=caption_ax.transAxes,\n",
    "                    fontsize=14, weight='bold', color='navy')\n",
    "\n",
    "    # Main Caption Text (wrapped)\n",
    "    wrapped_caption = textwrap.fill(caption_text_main if caption_text_main else \"No caption available.\", width=120) # Adjust width\n",
    "    caption_ax.text(0.01, 0.45, wrapped_caption, transform=caption_ax.transAxes, fontsize=10,\n",
    "                    verticalalignment='top', horizontalalignment='left',\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', facecolor='aliceblue', alpha=0.7, edgecolor='lightgrey'),\n",
    "                    wrap=True)\n",
    "\n",
    "    # Detected Medical Structures (if any)\n",
    "    if label_colors_for_caption:\n",
    "        struct_text_y_start = 0.25 # Position below caption\n",
    "        max_struct_per_line = 4\n",
    "        current_struct_count = 0\n",
    "        line_height = 0.08 # Approximate height for each structure line text\n",
    "\n",
    "        struct_str_list = []\n",
    "        for i, (structure_name, hex_color) in enumerate(label_colors_for_caption.items()):\n",
    "            # Matplotlib text doesn't directly support rich text like HTML for individual word colors.\n",
    "            # So, we list them, possibly with a colored square marker if using a legend approach.\n",
    "            # Here, we just list names. The main plot will have colored bboxes.\n",
    "            struct_str_list.append(structure_name)\n",
    "            if (i + 1) % max_struct_per_line == 0 :\n",
    "                struct_str_list.append(\"\\n\") # Newline\n",
    "\n",
    "        detected_structures_text = \"Detected Structures: \" + \", \".join(s for s in struct_str_list if s != \"\\n\")\n",
    "        detected_structures_text = detected_structures_text.replace(\", \\n, \", \"\\n\") # Clean up newlines\n",
    "\n",
    "        caption_ax.text(0.01, struct_text_y_start, textwrap.fill(detected_structures_text,width=70),\n",
    "                        transform=caption_ax.transAxes, fontsize=9, weight='normal', color='darkgreen',\n",
    "                        verticalalignment='top')\n",
    "                        \n",
    "    # Pipeline Info\n",
    "    pipeline_info = \"Processing: Input Data -> SAM/YOLO -> Advanced Masking -> Visualization\"\n",
    "    caption_ax.text(0.01, 0.05, pipeline_info, transform=caption_ax.transAxes,\n",
    "                    fontsize=8, style='italic', color='grey')\n",
    "\n",
    "\n",
    "# --- Data Table for Reports ---\n",
    "def create_image_data_table_df(image_id_str, concepts_data_df, caption_file_data_df, explanations_data_df_main):\n",
    "    \"\"\"\n",
    "    Creates a Pandas DataFrame summarizing data from various sources for a specific image.\n",
    "    Args:\n",
    "        image_id_str: The image ID.\n",
    "        concepts_data_df: DataFrame from CONCEPTS_PATH.\n",
    "        caption_file_data_df: DataFrame from CAPTION_FILE_PATH.\n",
    "        explanations_data_df_main: DataFrame from CAPTIONS_PATH (used for explanations/main caption).\n",
    "    \"\"\"\n",
    "    image_data_summary = { 'Data Source': [], 'Content Summary': [], 'Details': [] }\n",
    "    id_cols_to_check = ['ImageID', 'ID', 'id', 'image_id'] # Common ID column names\n",
    "\n",
    "    def find_matching_row(df, id_val, id_columns_list):\n",
    "        if df is None or df.empty: return None\n",
    "        for col_name in id_columns_list:\n",
    "            if col_name in df.columns:\n",
    "                # Ensure type consistency for comparison if image_id_str is numeric string\n",
    "                try:\n",
    "                    df_id_col_type = df[col_name].dtype\n",
    "                    if pd.api.types.is_numeric_dtype(df_id_col_type) and isinstance(id_val, str) and id_val.isnumeric():\n",
    "                        id_val_comp = int(id_val)\n",
    "                    elif pd.api.types.is_string_dtype(df_id_col_type) and not isinstance(id_val, str):\n",
    "                         id_val_comp = str(id_val)\n",
    "                    else:\n",
    "                        id_val_comp = id_val\n",
    "\n",
    "                    match = df[df[col_name] == id_val_comp]\n",
    "                    if not match.empty: return match.iloc[0] # Return first match\n",
    "                except TypeError: # In case of comparison error\n",
    "                    continue # Try next column\n",
    "        return None\n",
    "\n",
    "    # A) Concepts Data\n",
    "    concept_row = find_matching_row(concepts_data_df, image_id_str, id_cols_to_check)\n",
    "    if concept_row is not None:\n",
    "        # Try to find columns named 'concept' or starting with 'C'\n",
    "        concept_cols = [col for col in concept_row.index if 'concept' in col.lower() or col.startswith('C')]\n",
    "        concept_details = [f\"{col}: {concept_row[col]}\" for col in concept_cols if pd.notna(concept_row[col])]\n",
    "        if not concept_details: # Fallback to first few non-ID columns\n",
    "            non_id_cols = [c for c in concept_row.index if c not in id_cols_to_check][:3]\n",
    "            concept_details = [f\"{col}: {concept_row[col]}\" for col in non_id_cols if pd.notna(concept_row[col])]\n",
    "        image_data_summary['Data Source'].append('Medical Concepts')\n",
    "        image_data_summary['Content Summary'].append(', '.join([str(concept_row[col]) for col in concept_cols if pd.notna(concept_row[col])][:3]))\n",
    "        image_data_summary['Details'].append(' | '.join(concept_details) if concept_details else \"No specific concept details found.\")\n",
    "    else:\n",
    "        image_data_summary['Data Source'].append('Medical Concepts')\n",
    "        image_data_summary['Content Summary'].append('N/A')\n",
    "        image_data_summary['Details'].append('Image ID not found in concepts data or concepts data unavailable.')\n",
    "\n",
    "    # B) Captions from caption_file_df (CAPTION_FILE_PATH)\n",
    "    caption_row = find_matching_row(caption_file_data_df, image_id_str, id_cols_to_check)\n",
    "    if caption_row is not None:\n",
    "        caption_text_cols = [col for col in caption_row.index if 'caption' in col.lower()]\n",
    "        caption_text = caption_row[caption_text_cols[0]] if caption_text_cols and pd.notna(caption_row[caption_text_cols[0]]) else \"No caption text.\"\n",
    "        image_data_summary['Data Source'].append('Image Caption (File)')\n",
    "        image_data_summary['Content Summary'].append(textwrap.shorten(str(caption_text), width=50))\n",
    "        image_data_summary['Details'].append(str(caption_text))\n",
    "    else:\n",
    "        image_data_summary['Data Source'].append('Image Caption (File)')\n",
    "        image_data_summary['Content Summary'].append('N/A')\n",
    "        image_data_summary['Details'].append('Image ID not found in caption file data or data unavailable.')\n",
    "\n",
    "    # C) Explanations/Main Caption from explanations_data_df_main (CAPTIONS_PATH)\n",
    "    explanation_row = find_matching_row(explanations_data_df_main, image_id_str, id_cols_to_check)\n",
    "    if explanation_row is not None:\n",
    "        # Try to find columns related to explanation or text\n",
    "        expl_text_cols = [col for col in explanation_row.index if any(k in col.lower() for k in ['explanation', 'caption', 'text', 'description'])]\n",
    "        expl_text = explanation_row[expl_text_cols[0]] if expl_text_cols and pd.notna(explanation_row[expl_text_cols[0]]) else \"No explanation text.\"\n",
    "        image_data_summary['Data Source'].append('Medical Explanation/Report')\n",
    "        image_data_summary['Content Summary'].append(textwrap.shorten(str(expl_text), width=50))\n",
    "        image_data_summary['Details'].append(str(expl_text))\n",
    "    else:\n",
    "        image_data_summary['Data Source'].append('Medical Explanation/Report')\n",
    "        image_data_summary['Content Summary'].append('N/A')\n",
    "        image_data_summary['Details'].append('Image ID not found in explanations data or data unavailable.')\n",
    "        \n",
    "    return pd.DataFrame(image_data_summary)\n",
    "\n",
    "def display_formatted_data_table(image_id_str, data_table_df):\n",
    "    \"\"\"Prints a formatted version of the image data summary table.\"\"\"\n",
    "    print(f\"\\n--- Data Summary Table for Image: {image_id_str} ---\")\n",
    "    if data_table_df.empty:\n",
    "        print(\"No data to display.\")\n",
    "        return\n",
    "        \n",
    "    with pd.option_context('display.max_colwidth', 70, 'display.width', 120, 'display.colheader_justify', 'left'):\n",
    "        # Using to_string for better control in script output than just print(df)\n",
    "        print(data_table_df.to_string(index=False, line_width=120, formatters={\n",
    "            'Content Summary': lambda x: textwrap.fill(x, width=40),\n",
    "            'Details': lambda x: textwrap.fill(x, width=60)\n",
    "        }))\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- Comprehensive Reporting ---\n",
    "# These are the de-duplicated versions from your original PART 9\n",
    "\n",
    "def export_analysis_metrics_to_csv(all_images_analysis_stats_dict, base_output_dir):\n",
    "    \"\"\"Exports detailed confidence scores, image summaries, and strategy performance to CSV files.\"\"\"\n",
    "    if not all_images_analysis_stats_dict:\n",
    "        print(\" No analysis stats provided to export_analysis_metrics_to_csv.\")\n",
    "        return {}\n",
    "\n",
    "    metrics_output_dir = os.path.join(base_output_dir, 'analysis_metrics')\n",
    "    os.makedirs(metrics_output_dir, exist_ok=True)\n",
    "    print(f\"--- Exporting Analysis Metrics to: {metrics_output_dir} ---\")\n",
    "\n",
    "    # 1. Detailed confidence scores per structure per image\n",
    "    confidence_records_list = []\n",
    "    for img_id, stats_per_image in all_images_analysis_stats_dict.items():\n",
    "        if 'confidence_scores' in stats_per_image and 'processing_details' in stats_per_image:\n",
    "            for structure_name, conf_score in stats_per_image['confidence_scores'].items():\n",
    "                confidence_records_list.append({\n",
    "                    'image_id': img_id,\n",
    "                    'structure': structure_name,\n",
    "                    'confidence_score': conf_score,\n",
    "                    'confidence_category': 'High' if conf_score >= 0.8 else 'Medium' if conf_score >= 0.5 else 'Low',\n",
    "                    'processing_strategy': stats_per_image['processing_details'].get(structure_name, 'unknown_strategy')\n",
    "                })\n",
    "    \n",
    "    confidence_df = pd.DataFrame(confidence_records_list)\n",
    "    confidence_csv_path = os.path.join(metrics_output_dir, 'detailed_confidence_scores.csv')\n",
    "    if not confidence_df.empty:\n",
    "        confidence_df.to_csv(confidence_csv_path, index=False)\n",
    "        print(f\"✓ Detailed confidence scores exported: {confidence_csv_path}\")\n",
    "    else:\n",
    "        print(\" No detailed confidence records to export.\")\n",
    "\n",
    "\n",
    "    # 2. Summary statistics per image\n",
    "    image_summary_records_list = []\n",
    "    for img_id, stats_per_image in all_images_analysis_stats_dict.items():\n",
    "        yolo_stats = stats_per_image.get('yolo_stats', {'yolo_additions': 0}) # Handle if yolo_stats is missing\n",
    "        image_summary_records_list.append({\n",
    "            'image_id': img_id,\n",
    "            'total_structures': stats_per_image.get('structures_count', 0),\n",
    "            'total_bboxes_processed': stats_per_image.get('bbox_count', 0),\n",
    "            'avg_confidence': stats_per_image.get('avg_confidence', 0.0),\n",
    "            'yolo_enhancements_added': yolo_stats.get('yolo_additions',0),\n",
    "            'high_confidence_count': len([c for c in stats_per_image.get('confidence_scores', {}).values() if c >= 0.8]),\n",
    "            'medium_confidence_count': len([c for c in stats_per_image.get('confidence_scores', {}).values() if 0.5 <= c < 0.8]),\n",
    "            'low_confidence_count': len([c for c in stats_per_image.get('confidence_scores', {}).values() if c < 0.5]),\n",
    "            'max_confidence': max(stats_per_image.get('confidence_scores', {0:0}).values()) if stats_per_image.get('confidence_scores') else 0.0,\n",
    "            'min_confidence': min(stats_per_image.get('confidence_scores', {0:0}).values()) if stats_per_image.get('confidence_scores') else 0.0\n",
    "        })\n",
    "\n",
    "    image_summary_df = pd.DataFrame(image_summary_records_list)\n",
    "    summary_csv_path = os.path.join(metrics_output_dir, 'image_level_analysis_summary.csv')\n",
    "    if not image_summary_df.empty:\n",
    "        image_summary_df.to_csv(summary_csv_path, index=False)\n",
    "        print(f\"✓ Image-level analysis summary exported: {summary_csv_path}\")\n",
    "    else:\n",
    "        print(\" No image summary records to export.\")\n",
    "\n",
    "\n",
    "    # 3. Performance of different processing strategies\n",
    "    strategy_performance_stats = defaultdict(lambda: {'count': 0, 'confidences': []})\n",
    "    for img_id, stats_per_image in all_images_analysis_stats_dict.items():\n",
    "        if 'processing_details' in stats_per_image and 'confidence_scores' in stats_per_image:\n",
    "            for structure_name, strategy_name in stats_per_image['processing_details'].items():\n",
    "                conf = stats_per_image['confidence_scores'].get(structure_name, 0.0)\n",
    "                strategy_performance_stats[strategy_name]['count'] += 1\n",
    "                strategy_performance_stats[strategy_name]['confidences'].append(conf)\n",
    "    \n",
    "    strategy_summary_list = []\n",
    "    for strategy_name, data in strategy_performance_stats.items():\n",
    "        confs = data['confidences']\n",
    "        if confs:\n",
    "            strategy_summary_list.append({\n",
    "                'strategy_name': strategy_name,\n",
    "                'usage_count': data['count'],\n",
    "                'avg_confidence': np.mean(confs) if confs else 0.0,\n",
    "                'std_dev_confidence': np.std(confs) if confs else 0.0,\n",
    "                'success_rate_gt_0.6': len([c for c in confs if c > 0.6]) / len(confs) if confs else 0.0\n",
    "            })\n",
    "            \n",
    "    strategy_df = pd.DataFrame(strategy_summary_list)\n",
    "    strategy_csv_path = os.path.join(metrics_output_dir, 'processing_strategy_performance.csv')\n",
    "    if not strategy_df.empty:\n",
    "        strategy_df.to_csv(strategy_csv_path, index=False)\n",
    "        print(f\"✓ Strategy performance summary exported: {strategy_csv_path}\")\n",
    "    else:\n",
    "        print(\" No strategy performance data to export.\")\n",
    "\n",
    "    return {\n",
    "        'confidence_data_df': confidence_df, 'summary_data_df': image_summary_df, 'strategy_data_df': strategy_df,\n",
    "        'confidence_csv_path': confidence_csv_path, 'summary_csv_path': summary_csv_path, 'strategy_csv_path': strategy_csv_path\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_overall_final_report_text(all_images_stats_dict, exported_data_dfs):\n",
    "    \"\"\"Generates a text-based comprehensive final report summarizing the entire analysis run.\"\"\"\n",
    "    print(\"\\n======================================================================\")\n",
    "    print(\" COMPREHENSIVE FINAL ANALYSIS REPORT (OVERALL)\")\n",
    "    print(\"======================================================================\")\n",
    "\n",
    "    if not all_images_stats_dict:\n",
    "        print(\"No analysis data available to generate a final report.\")\n",
    "        return {}\n",
    "\n",
    "    total_images_processed = len(all_images_stats_dict)\n",
    "    total_structures_identified = sum(stats.get('structures_count', 0) for stats in all_images_stats_dict.values())\n",
    "    total_bboxes_analyzed = sum(stats.get('bbox_count', 0) for stats in all_images_stats_dict.values())\n",
    "    \n",
    "    all_conf_scores_flat = []\n",
    "    for stats in all_images_stats_dict.values():\n",
    "        if 'confidence_scores' in stats:\n",
    "            all_conf_scores_flat.extend(stats['confidence_scores'].values())\n",
    "    \n",
    "    avg_overall_confidence = np.mean(all_conf_scores_flat) if all_conf_scores_flat else 0.0\n",
    "    num_high_conf = len([c for c in all_conf_scores_flat if c >= 0.8])\n",
    "    num_med_conf = len([c for c in all_conf_scores_flat if 0.5 <= c < 0.8])\n",
    "    num_low_conf = len([c for c in all_conf_scores_flat if c < 0.5])\n",
    "\n",
    "    total_yolo_added = sum(stats.get('yolo_stats',{}).get('yolo_additions',0) for stats in all_images_stats_dict.values())\n",
    "\n",
    "    print(f\"\\n --- OVERALL STATISTICS ---\")\n",
    "    print(f\"  Total Images Processed: {total_images_processed}\")\n",
    "    print(f\"  Total Medical Structures Identified (sum over images): {total_structures_identified}\")\n",
    "    print(f\"  Total Bounding Boxes Analyzed (sum over images): {total_bboxes_analyzed}\")\n",
    "    if total_images_processed > 0:\n",
    "        print(f\"  Avg. Structures per Image: {total_structures_identified / total_images_processed:.1f}\")\n",
    "    if YOLO_AVAILABLE:\n",
    "         print(f\"  Total YOLO Detections Added Across All Images: {total_yolo_added}\")\n",
    "\n",
    "\n",
    "    print(f\"\\n --- CONFIDENCE ANALYSIS (ACROSS ALL STRUCTURES) ---\")\n",
    "    if all_conf_scores_flat:\n",
    "        print(f\"  Overall Average Confidence: {avg_overall_confidence:.3f}\")\n",
    "        print(f\"  Confidence Range: {np.min(all_conf_scores_flat):.3f} - {np.max(all_conf_scores_flat):.3f}\")\n",
    "        print(f\"  Confidence Std. Deviation: {np.std(all_conf_scores_flat):.3f}\")\n",
    "        print(f\"\\n   Confidence Distribution:\")\n",
    "        total_conf_scores = len(all_conf_scores_flat)\n",
    "        print(f\"    High Confidence (≥0.8): {num_high_conf} ({num_high_conf / total_conf_scores * 100:.1f}%)\")\n",
    "        print(f\"    Medium Confidence (0.5-0.8): {num_med_conf} ({num_med_conf / total_conf_scores * 100:.1f}%)\")\n",
    "        print(f\"    Low Confidence (<0.5): {num_low_conf} ({num_low_conf / total_conf_scores * 100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"  No confidence scores recorded.\")\n",
    "\n",
    "    summary_df = exported_data_dfs.get('summary_data_df', pd.DataFrame())\n",
    "    if not summary_df.empty:\n",
    "        print(f\"\\n --- TOP PERFORMING IMAGES (BY AVG. CONFIDENCE) ---\")\n",
    "        top_images_df = summary_df.nlargest(min(5, len(summary_df)), 'avg_confidence')\n",
    "        for _, row in top_images_df.iterrows():\n",
    "            print(f\"  - Image '{row['image_id']}': Avg. Conf {row['avg_confidence']:.3f} ({row['total_structures']} structures)\")\n",
    "\n",
    "        print(f\"\\n --- IMAGES POTENTIALLY NEEDING REVIEW (LOWEST AVG. CONFIDENCE) ---\")\n",
    "        # Define \"needing review\" threshold, e.g., avg_confidence < 0.6\n",
    "        attention_images_df = summary_df[summary_df['avg_confidence'] < 0.6].nsmallest(min(5, len(summary_df)), 'avg_confidence')\n",
    "        if not attention_images_df.empty:\n",
    "            for _, row in attention_images_df.iterrows():\n",
    "                print(f\"  - Image '{row['image_id']}': Avg. Conf {row['avg_confidence']:.3f} ({row['low_confidence_count']} low-conf structures)\")\n",
    "        else:\n",
    "            print(\"  All processed images have average confidence ≥ 0.6 or no images processed.\")\n",
    "    \n",
    "    strategy_df = exported_data_dfs.get('strategy_data_df', pd.DataFrame())\n",
    "    if not strategy_df.empty:\n",
    "        print(f\"\\n --- PROCESSING STRATEGY PERFORMANCE ---\")\n",
    "        sorted_strategy_df = strategy_df.sort_values('avg_confidence', ascending=False)\n",
    "        for _, row in sorted_strategy_df.iterrows():\n",
    "            print(f\"  - Strategy '{row['strategy_name']}': Used {row['usage_count']} times, Avg. Conf {row['avg_confidence']:.3f}, Success (>0.6) {row['success_rate_gt_0.6']:.1%}\")\n",
    "\n",
    "    print(f\"\\n --- RECOMMENDATIONS & NOTES ---\")\n",
    "    if avg_overall_confidence >= 0.75:\n",
    "        print(f\"   Overall performance appears strong with an average confidence of {avg_overall_confidence:.3f}.\")\n",
    "    elif avg_overall_confidence >= 0.5:\n",
    "        print(f\"   Overall performance is moderate. Review strategies for low-confidence detections.\")\n",
    "    else:\n",
    "        print(f\"   Overall performance may need improvement. Focus on enhancing low-confidence scenarios and data quality.\")\n",
    "    \n",
    "    if total_yolo_added > 0 and YOLO_AVAILABLE:\n",
    "        print(f\"   YOLO enhancement contributed {total_yolo_added} additional detections. Consider fine-tuning YOLO on specific medical entities if not already done.\")\n",
    "    elif YOLO_AVAILABLE:\n",
    "        print(f\"  ℹ YOLO was available but did not add new detections, or was not triggered significantly. Review YOLO confidence thresholds and overlap criteria.\")\n",
    "\n",
    "    print(f\"\\n Output files (CSVs, heatmaps, visualizations) are saved in subdirectories within: {OUTPUT_DIR}\")\n",
    "    print(\"======================================================================\")\n",
    "\n",
    "    return { # Return key overall metrics for potential further use\n",
    "        'total_images_processed': total_images_processed, 'avg_overall_confidence': avg_overall_confidence,\n",
    "        'num_high_conf': num_high_conf, 'num_med_conf': num_med_conf, 'num_low_conf': num_low_conf,\n",
    "        'total_yolo_added': total_yolo_added\n",
    "    }\n",
    "\n",
    "print(\"✓ Visualization and Reporting utilities defined.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION VIII: MAIN ANALYSIS FUNCTION PER IMAGE\n",
    "# (This is the refined version of your original `process_medical_analysis_ultimate` from PART 10)\n",
    "# ==============================================================================\n",
    "print(\"\\n----------------------------------------------------------------------\")\n",
    "print(\"SECTION VIII: DEFINING MAIN PER-IMAGE ANALYSIS LOGIC\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "def process_single_image_analysis(\n",
    "    image_id_str,\n",
    "    sam_data_for_image_df,   # DataFrame of initial SAM coordinates for this specific image\n",
    "    explanations_data_for_image_df, # DataFrame containing the main caption/explanation for this image\n",
    "    concepts_full_df,        # Full DataFrame for all concepts\n",
    "    caption_file_full_df,    # Full DataFrame for all captions (from caption.csv)\n",
    "    sam_predictor_instance,\n",
    "    base_output_dir\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a single medical image: loads, enhances with YOLO, applies advanced SAM,\n",
    "    generates visualizations, and collects statistics.\n",
    "    \"\"\"\n",
    "    print(f\"\\n Starting Analysis for Image ID: {image_id_str} \")\n",
    "    \n",
    "    # 0. Initial clear_cuda_cache before loading image and model processing for this image\n",
    "    # clear_cuda_cache() # This is now handled in the main loop BEFORE calling this function.\n",
    "\n",
    "    # 1. Load Image\n",
    "    image_path = find_image_file(str(image_id_str), IMAGES_DIR) # IMAGES_DIR is global config\n",
    "    if not image_path:\n",
    "        print(f\" Image file not found for ID {image_id_str} in {IMAGES_DIR}. Skipping this image.\")\n",
    "        return None, {} # Return None for path, empty dict for stats\n",
    "\n",
    "    image_bgr = cv2.imread(image_path)\n",
    "    if image_bgr is None:\n",
    "        print(f\" Could not load image from path: {image_path}. Skipping this image.\")\n",
    "        return None, {}\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_height, img_width = image_rgb.shape[:2]\n",
    "    print(f\"✓ Image '{image_id_str}' loaded ({img_width}x{img_height}).\")\n",
    "\n",
    "    # 2. Initial SAM Data & YOLO Enhancement\n",
    "    # `sam_data_for_image_df` are the initial bboxes for this image\n",
    "    # `refine_sam_data_with_yolo` adds new, non-overlapping YOLO detections.\n",
    "    print(f\"  Initial SAM bboxes for image {image_id_str}: {len(sam_data_for_image_df)}\")\n",
    "    enhanced_detections_df = refine_sam_data_with_yolo(image_id_str, image_rgb, sam_data_for_image_df)\n",
    "    yolo_additions_count = len(enhanced_detections_df) - len(sam_data_for_image_df)\n",
    "    print(f\"  Total detections after YOLO for image {image_id_str}: {len(enhanced_detections_df)} ({yolo_additions_count} added by YOLO).\")\n",
    "\n",
    "\n",
    "    # 3. Process each detected structure/label with advanced SAM\n",
    "    # `grouped_data` will iterate over unique labels in the `enhanced_detections_df`\n",
    "    # For each label, it will take the bbox(es) and apply advanced SAM.\n",
    "    \n",
    "    processed_label_colors = {} # Stores {final_label_name: color_hex}\n",
    "    final_confidence_scores = {} # Stores {final_label_name: confidence_float}\n",
    "    final_processing_strategies = {} # Stores {final_label_name: strategy_string}\n",
    "    # DataFrame to store the final bboxes that are kept after processing all strategies\n",
    "    # This will be used for the clean visualization.\n",
    "    # It might contain multiple bboxes if YOLO added some that SAM didn't refine, or if a label has multiple distinct instances.\n",
    "    # However, the current `select_best_mask_for_label_advanced` processes one bbox at a time.\n",
    "    # The visualization `create_clean_visualization_with_labels` will draw based on the labels in `processed_label_colors`.\n",
    "    # Let's build a list of dicts for the final chosen bboxes to create a new DataFrame for visualization.\n",
    "    final_bboxes_for_visualization_list = []\n",
    "\n",
    "\n",
    "    total_initial_bboxes_to_process = len(enhanced_detections_df)\n",
    "    processed_bbox_count_for_stats = 0 # Count of bboxes actually processed by SAM\n",
    "\n",
    "    # Group by 'Label' column which contains original SAM labels and YOLO prefixed labels\n",
    "    if not enhanced_detections_df.empty:\n",
    "        grouped_initial_detections = enhanced_detections_df.groupby('Label')\n",
    "        \n",
    "        for original_label_from_df, group_df in grouped_initial_detections:\n",
    "            print(f\"\\n  Processing label group: '{original_label_from_df}' ({len(group_df)} initial bbox(es))\")\n",
    "            \n",
    "            # For each original label, we might have one or more bboxes (e.g. if SAM generated multiple for a concept)\n",
    "            # We should pick the \"best\" initial bbox from the group if there are multiple, or process all.\n",
    "            # The current structure of your script seems to imply processing each bbox row from the input CSVs.\n",
    "            # Let's assume we process each row in `group_df` if they are distinct enough,\n",
    "            # or select one representative one. For simplicity and to match `select_best_mask_for_label_advanced`\n",
    "            # which takes one bbox, let's process the first bbox in the group as representative for this label.\n",
    "            # A more advanced approach might iterate all, or merge/NMS bboxes for the same label.\n",
    "            \n",
    "            # Take the first row of the group as the representative for this label's initial bbox\n",
    "            representative_row = group_df.iloc[0]\n",
    "            initial_bbox_coords = (\n",
    "                int(representative_row['x']), int(representative_row['y']),\n",
    "                int(representative_row['width']), int(representative_row['height'])\n",
    "            )\n",
    "            processed_bbox_count_for_stats += 1 # Count this as one bbox processed by SAM\n",
    "\n",
    "            # Clean and correct the label name\n",
    "            cleaned_label_base = clean_label_text(original_label_from_df)\n",
    "            # Directional correction needs the *initial* bbox for context\n",
    "            final_label_name = correct_directional_labels(cleaned_label_base, initial_bbox_coords, img_width)\n",
    "            \n",
    "            print(f\"    Cleaned/Corrected Label: '{final_label_name}' from BBox: {initial_bbox_coords}\")\n",
    "\n",
    "            # Assign color if new label\n",
    "            if final_label_name not in processed_label_colors:\n",
    "                color_idx = len(processed_label_colors) % len(COLORS) # COLORS is global\n",
    "                processed_label_colors[final_label_name] = COLORS[color_idx]\n",
    "\n",
    "            # Apply advanced SAM processing for this label and its representative bbox\n",
    "            mask_array, confidence, strategy = select_best_mask_for_label_advanced(\n",
    "                image_rgb, initial_bbox_coords, sam_predictor_instance, final_label_name,\n",
    "                image_id_str, export_heatmaps_flag=True # Heatmaps (mask analysis) saved by this function\n",
    "            )\n",
    "            \n",
    "            final_confidence_scores[final_label_name] = confidence\n",
    "            final_processing_strategies[final_label_name] = strategy\n",
    "            \n",
    "            # Store this chosen bbox and its final label for the main visualization\n",
    "            # Note: `initial_bbox_coords` is used here as the reference for drawing.\n",
    "            # SAM provides a mask; the bbox is the prompt.\n",
    "            final_bboxes_for_visualization_list.append({\n",
    "                'ImageID': image_id_str,\n",
    "                'Label': final_label_name, # Use the corrected label\n",
    "                'x': initial_bbox_coords[0], 'y': initial_bbox_coords[1],\n",
    "                'width': initial_bbox_coords[2], 'height': initial_bbox_coords[3],\n",
    "                'confidence_sam': confidence, # Store SAM's confidence for this mask\n",
    "                'strategy': strategy\n",
    "            })\n",
    "\n",
    "            print(f\"    ✓ Result for '{final_label_name}': Strategy='{strategy}', Confidence={confidence:.3f}\")\n",
    "\n",
    "            # Optionally, generate the very detailed 4-panel conceptual heatmap display\n",
    "            # This might be too much for every structure. Perhaps only for high-confidence ones or for debugging.\n",
    "            if confidence > 0.75: # Example: generate for high confidence results\n",
    "                 generate_comprehensive_heatmap_display(image_rgb, initial_bbox_coords, mask_array, confidence, final_label_name, image_id_str, base_output_dir, show_plot=False)\n",
    "\n",
    "\n",
    "    final_bboxes_for_visualization_df = pd.DataFrame(final_bboxes_for_visualization_list)\n",
    "\n",
    "    # 4. Create Main Visualization (Matplotlib figure with OpenCV drawn image and caption)\n",
    "    print(f\"\\n  Generating main visualization for {image_id_str}...\")\n",
    "    # The figure size needs to accommodate the image and the caption area\n",
    "    # Aspect ratio of image:\n",
    "    fig_aspect_ratio = img_width / img_height\n",
    "    fig_width_mpl = 12 # Base width in inches for Matplotlib figure\n",
    "    fig_height_mpl_image_area = fig_width_mpl / fig_aspect_ratio\n",
    "    fig_height_mpl_caption_area = 3 # Inches for caption area\n",
    "    total_fig_height_mpl = fig_height_mpl_image_area + fig_height_mpl_caption_area\n",
    "\n",
    "    main_fig = plt.figure(figsize=(fig_width_mpl, total_fig_height_mpl), constrained_layout=False) # Disable constrained_layout for add_axes\n",
    "    \n",
    "    # Create axes for the image using add_axes [left, bottom, width, height]\n",
    "    image_ax_height_ratio = fig_height_mpl_image_area / total_fig_height_mpl\n",
    "    image_ax = main_fig.add_axes([0.05, 1 - image_ax_height_ratio - 0.02, 0.9, image_ax_height_ratio]) # Top part for image\n",
    "\n",
    "\n",
    "    # Use OpenCV to draw bboxes and labels on the image\n",
    "    annotated_image_cv = create_clean_visualization_with_labels(\n",
    "        image_rgb, final_bboxes_for_visualization_df, processed_label_colors, final_confidence_scores\n",
    "    )\n",
    "    image_ax.imshow(annotated_image_cv)\n",
    "    image_ax.axis('off')\n",
    "    image_ax.set_title(f'Medical Image Analysis: {image_id_str}', fontsize=16, fontweight='bold', pad=10)\n",
    "    \n",
    "    # Add legend to the image axes\n",
    "    create_legend_for_main_plot(processed_label_colors, image_ax)\n",
    "\n",
    "    # Extract main caption/explanation for this image\n",
    "    main_caption_text = f\"Report for Image ID: {image_id_str}.\" # Default caption\n",
    "    if not explanations_data_for_image_df.empty:\n",
    "        # Try to find a 'caption' or 'explanation' column\n",
    "        cap_col_names = [col for col in explanations_data_for_image_df.columns if any(k in col.lower() for k in ['caption', 'explanation', 'text'])]\n",
    "        if cap_col_names:\n",
    "            main_caption_text = explanations_data_for_image_df.iloc[0][cap_col_names[0]]\n",
    "            if pd.isna(main_caption_text): main_caption_text = f\"No caption found for {image_id_str} in provided data.\"\n",
    "        else:\n",
    "            main_caption_text = f\"Caption/explanation column not found for {image_id_str}.\"\n",
    "    else:\n",
    "        main_caption_text = f\"No explanation/caption data provided for {image_id_str}.\"\n",
    "\n",
    "\n",
    "    # Add improved caption subplot to the main figure\n",
    "    create_improved_caption_subplot(main_fig, main_caption_text, processed_label_colors)\n",
    "\n",
    "    # Save the main visualization\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") # datetime needs to be imported\n",
    "    main_viz_filename = f\"{image_id_str}_main_analysis_{timestamp}.png\"\n",
    "    main_viz_path = os.path.join(base_output_dir, \"main_visualizations\")\n",
    "    os.makedirs(main_viz_path, exist_ok=True)\n",
    "    full_save_path = os.path.join(main_viz_path, main_viz_filename)\n",
    "    \n",
    "    try:\n",
    "        main_fig.savefig(full_save_path, dpi=150, bbox_inches='tight') # Adjust DPI as needed\n",
    "        print(f\"✓ Main visualization saved: {full_save_path}\")\n",
    "    except Exception as e_save:\n",
    "        print(f\" Error saving main visualization for {image_id_str}: {e_save}\")\n",
    "    plt.close(main_fig) # IMPORTANT: Close the figure to free memory\n",
    "\n",
    "\n",
    "    # 5. Generate and Display Data Table (console output)\n",
    "    data_summary_table_df = create_image_data_table_df(image_id_str, concepts_full_df, caption_file_full_df, explanations_data_for_image_df)\n",
    "    display_formatted_data_table(image_id_str, data_summary_table_df)\n",
    "    \n",
    "    # 6. Compile statistics for this image\n",
    "    avg_conf_this_image = np.mean(list(final_confidence_scores.values())) if final_confidence_scores else 0.0\n",
    "    \n",
    "    image_analysis_stats = {\n",
    "        'image_id': image_id_str,\n",
    "        'structures_count': len(final_confidence_scores),\n",
    "        'bbox_count': processed_bbox_count_for_stats, # Bboxes actually processed by SAM\n",
    "        'avg_confidence': avg_conf_this_image,\n",
    "        'confidence_scores': final_confidence_scores,    # Dict {label: score}\n",
    "        'processing_details': final_processing_strategies, # Dict {label: strategy}\n",
    "        'yolo_stats': {\n",
    "            'original_sam_bboxes_for_img': len(sam_data_for_image_df),\n",
    "            'yolo_additions': yolo_additions_count,\n",
    "            'total_detections_before_sam_adv': len(enhanced_detections_df)\n",
    "        },\n",
    "        'main_visualization_path': full_save_path\n",
    "    }\n",
    "    \n",
    "    print(f\" Analysis Completed for Image ID: {image_id_str} \")\n",
    "    return full_save_path, image_analysis_stats\n",
    "\n",
    "# Need to import datetime for the timestamp\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"✓ Main Per-Image Analysis function defined.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION IX: MAIN EXECUTION RUNNER / PIPELINE\n",
    "# ==============================================================================\n",
    "print(\"\\n----------------------------------------------------------------------\")\n",
    "print(\"SECTION IX: DEFINING MAIN EXECUTION PIPELINE\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "def run_full_analysis_pipeline(num_images_to_process=None, recess_time_seconds=10):\n",
    "    \"\"\"\n",
    "    Main pipeline to run the complete medical image analysis for multiple images.\n",
    "    Args:\n",
    "        num_images_to_process (int, optional): Limit the number of images to process. None for all.\n",
    "        recess_time_seconds (int): Pause duration in seconds between processing images for memory recovery.\n",
    "    \"\"\"\n",
    "    print(\"======================================================================\")\n",
    "    print(\" INITIATING FULL MEDICAL IMAGE ANALYSIS PIPELINE \")\n",
    "    print(\"======================================================================\")\n",
    "\n",
    "    # 1. Initial Setup: SAM, Load Data\n",
    "    # Clear CUDA cache thoroughly at the very beginning of the pipeline\n",
    "    print(\"\\n--- Phase 1: Initial Setup ---\")\n",
    "    clear_cuda_cache()\n",
    "    \n",
    "    global SAM_PREDICTOR, SAM_DEVICE, SAM_MODEL_INSTANCE # Make them global to manage their lifecycle\n",
    "    SAM_PREDICTOR, SAM_DEVICE, SAM_MODEL_INSTANCE = setup_sam() # Returns predictor, device, and model instance\n",
    "    if SAM_PREDICTOR is None:\n",
    "        print(\"CRITICAL ERROR: SAM Predictor setup failed. Aborting pipeline.\")\n",
    "        return\n",
    "\n",
    "    # Load all annotation/textual data\n",
    "    # These are full DataFrames, will be filtered per image inside process_single_image_analysis\n",
    "    sam_coords_full_df, explanations_full_df, concepts_full_df, caption_file_full_df = load_data()\n",
    "    if sam_coords_full_df.empty:\n",
    "        print(\"CRITICAL ERROR: Initial SAM coordinates data (sam_coord.csv) is empty or failed to load. Aborting.\")\n",
    "        # Clean up SAM model if it was loaded\n",
    "        if SAM_MODEL_INSTANCE is not None:\n",
    "            del SAM_MODEL_INSTANCE\n",
    "            SAM_MODEL_INSTANCE = None\n",
    "        if SAM_PREDICTOR is not None:\n",
    "            del SAM_PREDICTOR\n",
    "            SAM_PREDICTOR = None\n",
    "        clear_cuda_cache()\n",
    "        return\n",
    "\n",
    "    # Determine images to process\n",
    "    # Assuming 'ImageID' is the column in sam_coords_full_df\n",
    "    if 'ImageID' not in sam_coords_full_df.columns:\n",
    "        print(f\"CRITICAL ERROR: 'ImageID' column not found in {SAM_COORD_PATH}. Aborting.\")\n",
    "        # Clean up SAM model\n",
    "        if SAM_MODEL_INSTANCE is not None: del SAM_MODEL_INSTANCE; SAM_MODEL_INSTANCE = None\n",
    "        if SAM_PREDICTOR is not None: del SAM_PREDICTOR; SAM_PREDICTOR = None\n",
    "        clear_cuda_cache()\n",
    "        return\n",
    "        \n",
    "    unique_image_ids = sam_coords_full_df['ImageID'].unique().tolist()\n",
    "    if num_images_to_process is not None and num_images_to_process > 0:\n",
    "        unique_image_ids = unique_image_ids[:num_images_to_process]\n",
    "    \n",
    "    total_images = len(unique_image_ids)\n",
    "    if total_images == 0:\n",
    "        print(\"No images found to process based on SAM coordinates file. Exiting.\")\n",
    "        # Clean up SAM model\n",
    "        if SAM_MODEL_INSTANCE is not None: del SAM_MODEL_INSTANCE; SAM_MODEL_INSTANCE = None\n",
    "        if SAM_PREDICTOR is not None: del SAM_PREDICTOR; SAM_PREDICTOR = None\n",
    "        clear_cuda_cache()\n",
    "        return\n",
    "        \n",
    "    print(f\"Found {total_images} unique image IDs to process.\")\n",
    "    print(f\"Recess time between images: {recess_time_seconds} seconds.\")\n",
    "    print(f\"Output will be saved in: {OUTPUT_DIR}\") # OUTPUT_DIR is global\n",
    "\n",
    "    # 2. Per-Image Processing Loop\n",
    "    print(\"\\n--- Phase 2: Processing Images ---\")\n",
    "    all_results_paths = []\n",
    "    all_images_analysis_statistics = {} # Dict to store stats for each processed image\n",
    "\n",
    "    for i, current_image_id in enumerate(unique_image_ids):\n",
    "        print(f\"\\n------------------------- PROCESSING IMAGE {i+1}/{total_images}: {current_image_id} -------------------------\")\n",
    "        \n",
    "        # Prepare data for the current image\n",
    "        # Filter sam_coords_full_df for the current_image_id\n",
    "        current_sam_data_for_image_df = sam_coords_full_df[sam_coords_full_df['ImageID'] == current_image_id]\n",
    "        \n",
    "        # Filter explanations_full_df for the current_image_id\n",
    "        # Need to know the ID column in explanations_full_df (e.g., 'ImageID', 'ID')\n",
    "        # Assuming 'ImageID' for explanations_full_df as well, or adapt column name\n",
    "        id_col_expl = 'ImageID' # Default, check if this column exists\n",
    "        if explanations_full_df is not None and not explanations_full_df.empty:\n",
    "             if id_col_expl not in explanations_full_df.columns: # Try other common ID names\n",
    "                 common_ids = ['ID', 'id', 'image_id']\n",
    "                 for c_id in common_ids:\n",
    "                     if c_id in explanations_full_df.columns:\n",
    "                         id_col_expl = c_id\n",
    "                         break\n",
    "             current_explanations_for_image_df = explanations_full_df[explanations_full_df[id_col_expl] == current_image_id] if id_col_expl in explanations_full_df.columns else pd.DataFrame()\n",
    "        else:\n",
    "            current_explanations_for_image_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "        # Call the main processing function for this single image\n",
    "        try:\n",
    "            viz_path, image_stats = process_single_image_analysis(\n",
    "                current_image_id,\n",
    "                current_sam_data_for_image_df,\n",
    "                current_explanations_for_image_df,\n",
    "                concepts_full_df,\n",
    "                caption_file_full_df,\n",
    "                SAM_PREDICTOR, # Pass the globally initialized predictor\n",
    "                OUTPUT_DIR     # Pass the global output directory\n",
    "            )\n",
    "            if viz_path and image_stats: # If processing was successful\n",
    "                all_results_paths.append(viz_path)\n",
    "                all_images_analysis_statistics[current_image_id] = image_stats\n",
    "        except Exception as e_img_proc:\n",
    "            print(f\"Unhandled CRITICAL error during processing of image {current_image_id}: {e_img_proc}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            all_images_analysis_statistics[current_image_id] = {'error': str(e_img_proc), 'status': 'failed_critically'}\n",
    "\n",
    "\n",
    "        # Memory Management: Pause and Clear Cache\n",
    "        if i < total_images - 1: # Don't pause after the last image\n",
    "            print(f\"\\n--- Inter-Image Recess & Cleanup ({current_image_id} done) ---\")\n",
    "            clear_cuda_cache() # Clear CUDA cache thoroughly\n",
    "            if SAM_DEVICE == \"cuda\": # Only makes sense to offload if SAM is on CUDA\n",
    "                print(\"Offloading SAM predictor to CPU during recess (if on CUDA)...\")\n",
    "                if SAM_PREDICTOR is not None and hasattr(SAM_PREDICTOR.model, 'to'):\n",
    "                    SAM_PREDICTOR.model.to('cpu') # Move model to CPU\n",
    "                    # Note: If you move the model, you'll need to move it back to CUDA\n",
    "                    # before the next `predictor.set_image` call if `SAM_DEVICE` is 'cuda'.\n",
    "                    # This is handled by `setup_sam` if it re-checks device, or predictor needs re-init or model.to(SAM_DEVICE)\n",
    "\n",
    "            print(f\"Pausing for {recess_time_seconds} seconds...\")\n",
    "            time.sleep(recess_time_seconds)\n",
    "\n",
    "            if SAM_DEVICE == \"cuda\":\n",
    "                 print(\"Restoring SAM predictor to CUDA (if applicable)...\")\n",
    "                 if SAM_PREDICTOR is not None and hasattr(SAM_PREDICTOR.model, 'to'):\n",
    "                    SAM_PREDICTOR.model.to(SAM_DEVICE) # Move model back to original device\n",
    "                 clear_cuda_cache() # Clear again after moving model back\n",
    "\n",
    "    print(\"\\n--- Phase 3: Final Reporting & Cleanup ---\")\n",
    "    # Generate overall reports from all_images_analysis_statistics\n",
    "    if all_images_analysis_statistics:\n",
    "        print(\"Generating final summary reports and CSVs...\")\n",
    "        exported_dfs_and_paths = export_analysis_metrics_to_csv(all_images_analysis_statistics, OUTPUT_DIR)\n",
    "        generate_overall_final_report_text(all_images_analysis_statistics, exported_dfs_and_paths)\n",
    "    else:\n",
    "        print(\"No images were successfully processed, skipping final report generation.\")\n",
    "\n",
    "    # Final cleanup of SAM model from GPU memory\n",
    "    print(\"Performing final cleanup of SAM model...\")\n",
    "    if SAM_MODEL_INSTANCE is not None:\n",
    "        del SAM_MODEL_INSTANCE # Remove reference to model object\n",
    "        SAM_MODEL_INSTANCE = None\n",
    "    if SAM_PREDICTOR is not None:\n",
    "        del SAM_PREDICTOR # Remove reference to predictor object\n",
    "        SAM_PREDICTOR = None\n",
    "    clear_cuda_cache() # Final clear\n",
    "\n",
    "    print(\"\\n======================================================================\")\n",
    "    print(\"✅✅✅ MEDICAL IMAGE ANALYSIS PIPELINE COMPLETED ✅✅✅\")\n",
    "    print(f\"Processed {len(all_images_analysis_statistics)} images. Results in: {OUTPUT_DIR}\")\n",
    "    print(\"======================================================================\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION X: SCRIPT EXECUTION TRIGGER\n",
    "# ==============================================================================\n",
    "print(\"\\n----------------------------------------------------------------------\")\n",
    "print(\"SECTION X: TRIGGERING SCRIPT EXECUTION\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting the main execution block...\")\n",
    "    \n",
    "    # Configuration for the run:\n",
    "    NUMBER_OF_IMAGES_TO_RUN = None # Set to an integer to limit, e.g., 2 for testing, None for all\n",
    "    PAUSE_BETWEEN_IMAGES_SEC = 15  # Increase if OOM errors persist, decrease if memory is ample\n",
    "                                  # For an 8GB card with ViT-H, a longer pause might be beneficial.\n",
    "    \n",
    "    # Ensure global variables for SAM are initialized to None before the pipeline tries to use them\n",
    "    SAM_PREDICTOR = None\n",
    "    SAM_DEVICE = \"cpu\" # Default\n",
    "    SAM_MODEL_INSTANCE = None\n",
    "\n",
    "    try:\n",
    "        run_full_analysis_pipeline(\n",
    "            num_images_to_process=NUMBER_OF_IMAGES_TO_RUN,\n",
    "            recess_time_seconds=PAUSE_BETWEEN_IMAGES_SEC\n",
    "        )\n",
    "    except Exception as e_pipeline:\n",
    "        print(f\"CRITICAL FAILURE IN PIPELINE EXECUTION\")\n",
    "        print(f\"Error: {e_pipeline}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Attempt a final cleanup even on pipeline failure\n",
    "        if 'SAM_MODEL_INSTANCE' in globals() and SAM_MODEL_INSTANCE is not None: del SAM_MODEL_INSTANCE\n",
    "        if 'SAM_PREDICTOR' in globals() and SAM_PREDICTOR is not None: del SAM_PREDICTOR\n",
    "        clear_cuda_cache()\n",
    "    finally:\n",
    "        print(\"\\nScript execution finished.\")\n",
    "\t\t\n",
    "\t\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (grounding_env310)",
   "language": "python",
   "name": "grounding_env310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
